#!/bin/bash
#SBATCH -J testJob               # Job name
#SBATCH --partition test      # Job queue
#SBATCH -o job.%j.out         # Name of stdout output file (%j expands to jobId)
#SBATCH --nodes=1                   # Total number of nodes 
#SBATCH --time 0:50:00           # Run time (hh:mm:ss) - 1.5 hours
#SBATCH --ntasks-per-node=2     # Number of mpi tasks per node
#SBATCH --cpus-per-task=4     # Number of cores (threads) per task

module load mpich/3.3.1
# source /opt/ohpc/pub/oneAPI/setvars.sh


export OMP_PROC_BIND=true
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

export I_MPI_DEBUG=5 
export OMP_DISPLAY_AFFINITY=TRUE 
export OMP_DISPLAY_ENV=FALSE 
# unset MPI_DSM_OFF 
# export MPI_DSM_VERBOSE=1 
# export MPI_SHARED_VERBOSE=1 
# export MPI_MEMMAP_VERBOSE=1 

export  OMP_PROC_BIND=close # How I am going to bind omp threads on to those places 
export  OMP_PLACES=cores    # Where I am going to place omp threads on the hardware, here is to cores

echo "SLURM_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK  NODES=$SLURM_JOB_NUM_NODES SLURM_TASKS_PER_NODE=$SLURM_TASKS_PER_NODE"

srun ./hello

