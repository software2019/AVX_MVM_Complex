
[0] Code Region - double_MVM_macro

Iterations:        300
Instructions:      21600
Total Cycles:      6924
Total uOps:        23100

Dispatch Width:    4
uOps Per Cycle:    3.34
IPC:               3.12
Block RThroughput: 22.0


Instruction Info:
[1]: #uOps
[2]: Latency
[3]: RThroughput
[4]: MayLoad
[5]: MayStore
[6]: HasSideEffects (U)
[7]: Encoding Size

[1]    [2]    [3]    [4]    [5]    [6]    [7]    Encodings:                    Instructions:
 1      1     0.25                         2     ff c1                         incl	%ecx
 1      6     0.50    *                    6     c4 21 7d 10 1c 12             vmovupd	(%rdx,%r10), %ymm11
 1      6     0.50    *                    6     c4 a1 7d 10 14 08             vmovupd	(%rax,%r9), %ymm2
 1      6     0.50    *                    7     c4 a1 7d 10 7c 12 30          vmovupd	48(%rdx,%r10), %ymm7
 1      6     0.50    *                    7     c4 a1 7d 10 64 12 60          vmovupd	96(%rdx,%r10), %ymm4
 1      1     1.00                         5     c4 41 25 15 fb                vunpckhpd	%ymm11, %ymm11, %ymm15
 1      1     1.00                         5     c5 6d c6 c2 05                vshufpd	$5, %ymm2, %ymm2, %ymm8
 1      1     1.00                         4     c5 45 15 f7                   vunpckhpd	%ymm7, %ymm7, %ymm14
 1      3     0.50                         5     c4 c1 05 59 c0                vmulpd	%ymm8, %ymm15, %ymm0
 1      3     0.50                         5     c4 41 0d 59 e8                vmulpd	%ymm8, %ymm14, %ymm13
 1      6     0.50    *                    7     c4 a1 7d 10 7c 12 10          vmovupd	16(%rdx,%r10), %ymm7
 1      6     0.50    *                    6     c4 21 7f 12 14 12             vmovddup	(%rdx,%r10), %ymm10
 1      6     0.50    *                    7     c4 21 7f 12 4c 12 30          vmovddup	48(%rdx,%r10), %ymm9
 1      5     0.50                         5     c4 c2 ed b6 c2                vfmaddsub231pd	%ymm10, %ymm2, %ymm0
 1      5     0.50                         5     c4 42 ed b6 e9                vfmaddsub231pd	%ymm9, %ymm2, %ymm13
 1      1     1.00                         4     c5 dd 15 f4                   vunpckhpd	%ymm4, %ymm4, %ymm6
 1      6     0.50    *                    5     c5 fd 10 24 18                vmovupd	(%rax,%rbx), %ymm4
 1      3     0.50                         5     c4 41 4d 59 c0                vmulpd	%ymm8, %ymm6, %ymm8
 1      3     1.00                         6     c4 e3 7d 06 c8 01             vperm2f128	$1, %ymm0, %ymm0, %ymm1
 1      1     0.33                         6     c4 43 75 0d dd 0c             vblendpd	$12, %ymm13, %ymm1, %ymm11
 1      6     0.50    *                    7     c4 a1 7d 10 4c 08 10          vmovupd	16(%rax,%r9), %ymm1
 1      1     1.00                         5     c5 dd c6 dc 05                vshufpd	$5, %ymm4, %ymm4, %ymm3
 1      3     0.50                         4     c5 05 59 fb                   vmulpd	%ymm3, %ymm15, %ymm15
 1      3     0.50                         4     c5 0d 59 f3                   vmulpd	%ymm3, %ymm14, %ymm14
 1      5     0.50                         5     c4 42 dd a6 d7                vfmaddsub213pd	%ymm15, %ymm4, %ymm10
 1      5     0.50                         5     c4 42 dd a6 ce                vfmaddsub213pd	%ymm14, %ymm4, %ymm9
 1      3     1.00                         6     c4 63 15 06 e0 02             vperm2f128	$2, %ymm0, %ymm13, %ymm12
 1      3     1.00                         6     c4 e3 45 06 c7 01             vperm2f128	$1, %ymm7, %ymm7, %ymm0
 1      3     1.00                         6     c4 e3 75 06 f9 01             vperm2f128	$1, %ymm1, %ymm1, %ymm7
 1      3     1.00                         5     c4 41 1d 58 eb                vaddpd	%ymm11, %ymm12, %ymm13
 2      7     0.50    *                    8     c4 23 7d 0d 5c 12 40 0c       vblendpd	$12, 64(%rdx,%r10), %ymm0, %ymm11
 1      1     0.33                         6     c4 63 45 0d e1 0c             vblendpd	$12, %ymm1, %ymm7, %ymm12
 1      1     1.00                         5     c4 c1 7f 12 c3                vmovddup	%ymm11, %ymm0
 1      1     1.00                         5     c4 c1 25 15 cb                vunpckhpd	%ymm11, %ymm11, %ymm1
 1      1     1.00                         6     c4 41 1d c6 dc 05             vshufpd	$5, %ymm12, %ymm12, %ymm11
 1      3     0.50                         5     c4 41 75 59 db                vmulpd	%ymm11, %ymm1, %ymm11
 1      5     0.50                         5     c4 62 9d b6 d8                vfmaddsub231pd	%ymm0, %ymm12, %ymm11
 1      3     1.00                         6     c4 43 35 06 e2 02             vperm2f128	$2, %ymm10, %ymm9, %ymm12
 1      3     1.00                         6     c4 43 2d 06 d2 01             vperm2f128	$1, %ymm10, %ymm10, %ymm10
 1      1     0.33                         6     c4 43 2d 0d c9 0c             vblendpd	$12, %ymm9, %ymm10, %ymm9
 1      6     0.50    *                    6     c5 7d 10 54 18 10             vmovupd	16(%rax,%rbx), %ymm10
 1      3     1.00                         5     c4 41 25 58 dd                vaddpd	%ymm13, %ymm11, %ymm11
 1      3     1.00                         5     c4 41 1d 58 c9                vaddpd	%ymm9, %ymm12, %ymm9
 1      3     1.00                         6     c4 43 2d 06 ea 01             vperm2f128	$1, %ymm10, %ymm10, %ymm13
 1      1     0.33                         6     c4 43 15 0d fa 0c             vblendpd	$12, %ymm10, %ymm13, %ymm15
 1      1     1.00                         6     c4 41 05 c6 f7 05             vshufpd	$5, %ymm15, %ymm15, %ymm14
 1      3     0.50                         5     c4 c1 75 59 ce                vmulpd	%ymm14, %ymm1, %ymm1
 1      6     0.50    *                    7     c4 a1 7f 12 6c 12 60          vmovddup	96(%rdx,%r10), %ymm5
 1      5     0.50                         5     c4 62 ed b6 c5                vfmaddsub231pd	%ymm5, %ymm2, %ymm8
 1      3     0.50                         4     c5 cd 59 d3                   vmulpd	%ymm3, %ymm6, %ymm2
 1      5     0.50                         5     c4 e2 85 a6 c1                vfmaddsub213pd	%ymm1, %ymm15, %ymm0
 1      6     0.50    *                    7     c4 a1 7d 10 4c 12 70          vmovupd	112(%rdx,%r10), %ymm1
 2      1     1.00           *             6     c4 21 7d 11 1c 38             vmovupd	%ymm11, (%rax,%r15)
 1      5     0.50                         5     c4 e2 dd a6 ea                vfmaddsub213pd	%ymm2, %ymm4, %ymm5
 1      3     1.00                         5     c4 41 7d 58 c9                vaddpd	%ymm9, %ymm0, %ymm9
 1      3     1.00                         6     c4 e3 75 06 c1 01             vperm2f128	$1, %ymm1, %ymm1, %ymm0
 1      1     0.25                         7     48 81 c2 90 00 00 00          addq	$144, %rdx
 1      3     1.00                         6     c4 c3 3d 06 d8 01             vperm2f128	$1, %ymm8, %ymm8, %ymm3
 1      1     0.33                         6     c4 e3 7d 0d d1 0c             vblendpd	$12, %ymm1, %ymm0, %ymm2
 1      1     0.33                         6     c4 43 45 0d d2 0c             vblendpd	$12, %ymm10, %ymm7, %ymm10
 1      3     1.00                         6     c4 c3 55 06 f0 02             vperm2f128	$2, %ymm8, %ymm5, %ymm6
 1      1     0.33                         6     c4 e3 65 0d ed 0c             vblendpd	$12, %ymm5, %ymm3, %ymm5
 1      1     1.00                         4     c5 ed 15 da                   vunpckhpd	%ymm2, %ymm2, %ymm3
 1      1     1.00                         6     c4 c1 2d c6 fa 05             vshufpd	$5, %ymm10, %ymm10, %ymm7
 1      3     0.50                         4     c5 e5 59 e7                   vmulpd	%ymm7, %ymm3, %ymm4
 1      3     1.00                         4     c5 cd 58 ed                   vaddpd	%ymm5, %ymm6, %ymm5
 1      1     1.00                         4     c5 ff 12 f2                   vmovddup	%ymm2, %ymm6
 1      5     0.50                         5     c4 e2 ad a6 f4                vfmaddsub213pd	%ymm4, %ymm10, %ymm6
 1      3     1.00                         4     c5 4d 58 c5                   vaddpd	%ymm5, %ymm6, %ymm8
 2      1     1.00           *             7     c4 21 79 11 44 38 20          vmovupd	%xmm8, 32(%rax,%r15)
 2      1     1.00           *             6     c4 21 7d 11 0c 30             vmovupd	%ymm9, (%rax,%r14)
 2      1     1.00           *             8     c4 23 7d 19 44 30 20 01       vextractf128	$1, %ymm8, 32(%rax,%r14)


Resources:
[0]   - BWDivider
[1]   - BWFPDivider
[2]   - BWPort0
[3]   - BWPort1
[4]   - BWPort2
[5]   - BWPort3
[6]   - BWPort4
[7]   - BWPort5
[8]   - BWPort6
[9]   - BWPort7


Resource pressure per iteration:
[0]    [1]    [2]    [3]    [4]    [5]    [6]    [7]    [8]    [9]    
 -      -     14.99  16.01  7.00   7.00   4.00   23.00  2.00   3.00   

Resource pressure by instruction:
[0]    [1]    [2]    [3]    [4]    [5]    [6]    [7]    [8]    [9]    Instructions:
 -      -      -      -      -      -      -      -     1.00    -     incl	%ecx
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	(%rdx,%r10), %ymm11
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	(%rax,%r9), %ymm2
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	48(%rdx,%r10), %ymm7
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	96(%rdx,%r10), %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%ymm11, %ymm11, %ymm15
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$5, %ymm2, %ymm2, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%ymm7, %ymm7, %ymm14
 -      -     0.01   0.99    -      -      -      -      -      -     vmulpd	%ymm8, %ymm15, %ymm0
 -      -     0.99   0.01    -      -      -      -      -      -     vmulpd	%ymm8, %ymm14, %ymm13
 -      -      -      -     0.99   0.01    -      -      -      -     vmovupd	16(%rdx,%r10), %ymm7
 -      -      -      -     0.01   0.99    -      -      -      -     vmovddup	(%rdx,%r10), %ymm10
 -      -      -      -     0.99   0.01    -      -      -      -     vmovddup	48(%rdx,%r10), %ymm9
 -      -     0.01   0.99    -      -      -      -      -      -     vfmaddsub231pd	%ymm10, %ymm2, %ymm0
 -      -     0.01   0.99    -      -      -      -      -      -     vfmaddsub231pd	%ymm9, %ymm2, %ymm13
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%ymm4, %ymm4, %ymm6
 -      -      -      -     0.01   0.99    -      -      -      -     vmovupd	(%rax,%rbx), %ymm4
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm8, %ymm6, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$1, %ymm0, %ymm0, %ymm1
 -      -     0.99   0.01    -      -      -      -      -      -     vblendpd	$12, %ymm13, %ymm1, %ymm11
 -      -      -      -     0.99   0.01    -      -      -      -     vmovupd	16(%rax,%r9), %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$5, %ymm4, %ymm4, %ymm3
 -      -     0.99   0.01    -      -      -      -      -      -     vmulpd	%ymm3, %ymm15, %ymm15
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm14, %ymm14
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub213pd	%ymm15, %ymm4, %ymm10
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub213pd	%ymm14, %ymm4, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$2, %ymm0, %ymm13, %ymm12
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$1, %ymm7, %ymm7, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$1, %ymm1, %ymm1, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm11, %ymm12, %ymm13
 -      -     1.00    -     0.01   0.99    -      -      -      -     vblendpd	$12, 64(%rdx,%r10), %ymm0, %ymm11
 -      -     0.99    -      -      -      -      -      -      -     vblendpd	$12, %ymm1, %ymm7, %ymm12
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm11, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%ymm11, %ymm11, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$5, %ymm12, %ymm12, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm11, %ymm1, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm0, %ymm12, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$2, %ymm10, %ymm9, %ymm12
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$1, %ymm10, %ymm10, %ymm10
 -      -     0.01   0.99    -      -      -      -      -      -     vblendpd	$12, %ymm9, %ymm10, %ymm9
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%rax,%rbx), %ymm10
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm13, %ymm11, %ymm11
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm9, %ymm12, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$1, %ymm10, %ymm10, %ymm13
 -      -      -     1.00    -      -      -      -      -      -     vblendpd	$12, %ymm10, %ymm13, %ymm15
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$5, %ymm15, %ymm15, %ymm14
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm14, %ymm1, %ymm1
 -      -      -      -      -     1.00    -      -      -      -     vmovddup	96(%rdx,%r10), %ymm5
 -      -     0.99   0.01    -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm2, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm6, %ymm2
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub213pd	%ymm1, %ymm15, %ymm0
 -      -      -      -     0.99   0.01    -      -      -      -     vmovupd	112(%rdx,%r10), %ymm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm11, (%rax,%r15)
 -      -     0.01   0.99    -      -      -      -      -      -     vfmaddsub213pd	%ymm2, %ymm4, %ymm5
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm9, %ymm0, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$1, %ymm1, %ymm1, %ymm0
 -      -      -      -      -      -      -      -     1.00    -     addq	$144, %rdx
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$1, %ymm8, %ymm8, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vblendpd	$12, %ymm1, %ymm0, %ymm2
 -      -     0.01    -      -      -      -     0.99    -      -     vblendpd	$12, %ymm10, %ymm7, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$2, %ymm8, %ymm5, %ymm6
 -      -      -     1.00    -      -      -      -      -      -     vblendpd	$12, %ymm5, %ymm3, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%ymm2, %ymm2, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$5, %ymm10, %ymm10, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm3, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm5, %ymm6, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm2, %ymm6
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub213pd	%ymm4, %ymm10, %ymm6
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm5, %ymm6, %ymm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm8, 32(%rax,%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm9, (%rax,%r14)
 -      -      -      -      -     0.99   1.00    -      -     0.01   vextractf128	$1, %ymm8, 32(%rax,%r14)

[1] Code Region - _suNf_theta_T_multiply

Iterations:        300
Instructions:      43200
Total Cycles:      13223
Total uOps:        51000

Dispatch Width:    4
uOps Per Cycle:    3.86
IPC:               3.27
Block RThroughput: 42.5


Instruction Info:
[1]: #uOps
[2]: Latency
[3]: RThroughput
[4]: MayLoad
[5]: MayStore
[6]: HasSideEffects (U)
[7]: Encoding Size

[1]    [2]    [3]    [4]    [5]    [6]    [7]    Encodings:                    Instructions:
 1      1     0.25                         2     ff c1                         incl	%ecx
 1      5     0.50    *                    6     c4 21 79 10 14 10             vmovupd	(%rax,%r10), %xmm10
 1      5     0.50    *                    6     c4 21 79 10 04 0a             vmovupd	(%rdx,%r9), %xmm8
 1      5     0.50    *                    7     c4 a1 79 10 4c 10 10          vmovupd	16(%rax,%r10), %xmm1
 1      1     1.00                         5     c4 c1 39 15 f8                vunpckhpd	%xmm8, %xmm8, %xmm7
 1      1     1.00                         6     c4 41 29 c6 da 01             vshufpd	$1, %xmm10, %xmm10, %xmm11
 1      3     0.50                         5     c4 c1 41 59 f3                vmulpd	%xmm11, %xmm7, %xmm6
 1      5     0.50    *                    6     c4 a1 7b 12 14 0a             vmovddup	(%rdx,%r9), %xmm2
 1      5     0.50                         5     c4 e2 a9 a6 d6                vfmaddsub213pd	%xmm6, %xmm10, %xmm2
 1      1     1.00                         5     c5 f1 c6 c1 01                vshufpd	$1, %xmm1, %xmm1, %xmm0
 2      1     1.00           *             6     c4 a1 79 11 14 2a             vmovupd	%xmm2, (%rdx,%r13)
 1      5     0.50    *                    7     c4 a1 79 10 64 0a 10          vmovupd	16(%rdx,%r9), %xmm4
 1      1     1.00                         4     c5 d9 15 ec                   vunpckhpd	%xmm4, %xmm4, %xmm5
 1      3     0.50                         4     c5 d1 59 d8                   vmulpd	%xmm0, %xmm5, %xmm3
 1      5     0.50    *                    7     c4 a1 79 10 64 10 30          vmovupd	48(%rax,%r10), %xmm4
 1      5     0.50    *                    7     c4 21 7b 12 74 0a 10          vmovddup	16(%rdx,%r9), %xmm14
 1      5     0.50                         5     c4 62 f1 a6 f3                vfmaddsub213pd	%xmm3, %xmm1, %xmm14
 1      5     0.50    *                    7     c4 a1 79 10 5c 10 20          vmovupd	32(%rax,%r10), %xmm3
 1      3     1.00                         5     c4 41 69 58 c6                vaddpd	%xmm14, %xmm2, %xmm8
 2      1     1.00           *             6     c4 21 79 11 04 2a             vmovupd	%xmm8, (%rdx,%r13)
 1      1     1.00                         5     c5 e1 c6 d3 01                vshufpd	$1, %xmm3, %xmm3, %xmm2
 1      5     0.50    *                    7     c4 21 79 10 7c 0a 20          vmovupd	32(%rdx,%r9), %xmm15
 1      1     1.00                         5     c4 41 01 15 f7                vunpckhpd	%xmm15, %xmm15, %xmm14
 1      3     0.50                         4     c5 09 59 ca                   vmulpd	%xmm2, %xmm14, %xmm9
 1      5     0.50    *                    7     c4 a1 7b 12 7c 0a 20          vmovddup	32(%rdx,%r9), %xmm7
 1      5     0.50                         5     c4 c2 e1 a6 f9                vfmaddsub213pd	%xmm9, %xmm3, %xmm7
 1      3     1.00                         4     c5 b9 58 f7                   vaddpd	%xmm7, %xmm8, %xmm6
 1      5     0.50    *                    7     c4 a1 79 10 7c 10 40          vmovupd	64(%rax,%r10), %xmm7
 2      1     1.00           *             6     c4 a1 79 11 34 2a             vmovupd	%xmm6, (%rdx,%r13)
 1      1     1.00                         5     c5 c1 c6 f7 01                vshufpd	$1, %xmm7, %xmm7, %xmm6
 1      5     0.50    *                    6     c4 a1 79 10 2c 0a             vmovupd	(%rdx,%r9), %xmm5
 1      1     1.00                         4     c5 51 15 e5                   vunpckhpd	%xmm5, %xmm5, %xmm12
 1      1     1.00                         5     c5 d9 c6 ec 01                vshufpd	$1, %xmm4, %xmm4, %xmm5
 1      3     0.50                         4     c5 19 59 ed                   vmulpd	%xmm5, %xmm12, %xmm13
 1      5     0.50    *                    6     c4 21 7b 12 0c 0a             vmovddup	(%rdx,%r9), %xmm9
 1      5     0.50                         5     c4 42 d9 a6 cd                vfmaddsub213pd	%xmm13, %xmm4, %xmm9
 2      1     1.00           *             7     c4 21 79 11 4c 2a 10          vmovupd	%xmm9, 16(%rdx,%r13)
 1      5     0.50    *                    7     c4 21 79 10 7c 0a 10          vmovupd	16(%rdx,%r9), %xmm15
 1      1     1.00                         5     c4 41 01 15 f7                vunpckhpd	%xmm15, %xmm15, %xmm14
 1      3     0.50                         4     c5 09 59 c6                   vmulpd	%xmm6, %xmm14, %xmm8
 1      5     0.50    *                    7     c4 21 7b 12 64 0a 10          vmovddup	16(%rdx,%r9), %xmm12
 1      5     0.50                         5     c4 42 c1 a6 e0                vfmaddsub213pd	%xmm8, %xmm7, %xmm12
 1      3     1.00                         5     c4 41 31 58 ec                vaddpd	%xmm12, %xmm9, %xmm13
 1      5     0.50    *                    7     c4 21 79 10 4c 10 50          vmovupd	80(%rax,%r10), %xmm9
 2      1     1.00           *             7     c4 21 79 11 6c 2a 10          vmovupd	%xmm13, 16(%rdx,%r13)
 1      1     1.00                         6     c4 41 31 c6 c1 01             vshufpd	$1, %xmm9, %xmm9, %xmm8
 1      5     0.50    *                    7     c4 21 79 10 7c 0a 20          vmovupd	32(%rdx,%r9), %xmm15
 1      1     1.00                         5     c4 41 01 15 e7                vunpckhpd	%xmm15, %xmm15, %xmm12
 1      3     0.50                         5     c4 41 19 59 f8                vmulpd	%xmm8, %xmm12, %xmm15
 1      5     0.50    *                    7     c4 21 7b 12 74 0a 20          vmovddup	32(%rdx,%r9), %xmm14
 1      5     0.50                         5     c4 42 b1 a6 f7                vfmaddsub213pd	%xmm15, %xmm9, %xmm14
 1      3     1.00                         5     c4 41 11 58 ee                vaddpd	%xmm14, %xmm13, %xmm13
 1      5     0.50    *                    7     c4 21 79 10 74 10 60          vmovupd	96(%rax,%r10), %xmm14
 2      1     1.00           *             7     c4 21 79 11 6c 2a 10          vmovupd	%xmm13, 16(%rdx,%r13)
 1      5     0.50    *                    6     c4 21 79 10 2c 0a             vmovupd	(%rdx,%r9), %xmm13
 1      1     1.00                         5     c4 41 11 15 fd                vunpckhpd	%xmm13, %xmm13, %xmm15
 1      1     1.00                         6     c4 41 09 c6 ee 01             vshufpd	$1, %xmm14, %xmm14, %xmm13
 1      3     0.50                         5     c4 41 01 59 fd                vmulpd	%xmm13, %xmm15, %xmm15
 1      5     0.50    *                    6     c4 21 7b 12 24 0a             vmovddup	(%rdx,%r9), %xmm12
 1      5     0.50                         5     c4 42 89 a6 e7                vfmaddsub213pd	%xmm15, %xmm14, %xmm12
 1      5     0.50    *                    7     c4 21 79 10 7c 10 70          vmovupd	112(%rax,%r10), %xmm15
 2      1     1.00           *             9     c5 79 11 ac 24 e0 00 00 00    vmovupd	%xmm13, 224(%rsp)
 2      1     1.00           *             7     c4 21 79 11 64 2a 20          vmovupd	%xmm12, 32(%rdx,%r13)
 1      1     1.00                         6     c4 41 01 c6 ef 01             vshufpd	$1, %xmm15, %xmm15, %xmm13
 1      5     0.50    *                    7     c4 21 79 10 74 0a 10          vmovupd	16(%rdx,%r9), %xmm14
 1      1     1.00                         5     c4 41 09 15 f6                vunpckhpd	%xmm14, %xmm14, %xmm14
 1      3     0.50                         5     c4 41 09 59 f5                vmulpd	%xmm13, %xmm14, %xmm14
 2      1     1.00           *             9     c5 79 11 ac 24 f0 00 00 00    vmovupd	%xmm13, 240(%rsp)
 1      5     0.50    *                    7     c4 21 7b 12 6c 0a 10          vmovddup	16(%rdx,%r9), %xmm13
 1      5     0.50                         5     c4 42 81 a6 ee                vfmaddsub213pd	%xmm14, %xmm15, %xmm13
 1      5     0.50    *                    10    c4 21 79 10 b4 10 80 00 00 00  vmovupd	128(%rax,%r10), %xmm14
 1      1     1.00                         6     c4 41 09 c6 fe 01             vshufpd	$1, %xmm14, %xmm14, %xmm15
 1      3     1.00                         5     c4 41 19 58 ed                vaddpd	%xmm13, %xmm12, %xmm13
 2      1     1.00           *             7     c4 21 79 11 6c 2a 20          vmovupd	%xmm13, 32(%rdx,%r13)
 2      1     1.00           *             9     c5 79 11 bc 24 00 01 00 00    vmovupd	%xmm15, 256(%rsp)
 1      5     0.50    *                    7     c4 21 79 10 64 0a 20          vmovupd	32(%rdx,%r9), %xmm12
 1      1     1.00                         5     c4 41 19 15 e4                vunpckhpd	%xmm12, %xmm12, %xmm12
 1      3     0.50                         5     c4 41 19 59 e7                vmulpd	%xmm15, %xmm12, %xmm12
 1      5     0.50    *                    7     c4 21 7b 12 7c 0a 20          vmovddup	32(%rdx,%r9), %xmm15
 1      5     0.50                         5     c4 42 89 a6 fc                vfmaddsub213pd	%xmm12, %xmm14, %xmm15
 1      3     1.00                         5     c4 41 11 58 ef                vaddpd	%xmm15, %xmm13, %xmm13
 2      1     1.00           *             7     c4 21 79 11 6c 2a 20          vmovupd	%xmm13, 32(%rdx,%r13)
 1      5     0.50    *                    5     c5 79 10 2c 1a                vmovupd	(%rdx,%rbx), %xmm13
 1      1     1.00                         5     c4 41 11 15 fd                vunpckhpd	%xmm13, %xmm13, %xmm15
 1      3     0.50                         5     c4 41 01 59 db                vmulpd	%xmm11, %xmm15, %xmm11
 1      5     0.50    *                    5     c5 7b 12 24 1a                vmovddup	(%rdx,%rbx), %xmm12
 1      5     0.50                         5     c4 42 a9 a6 e3                vfmaddsub213pd	%xmm11, %xmm10, %xmm12
 2      1     1.00           *             6     c4 21 79 11 24 22             vmovupd	%xmm12, (%rdx,%r12)
 1      5     0.50    *                    6     c5 79 10 54 1a 10             vmovupd	16(%rdx,%rbx), %xmm10
 1      1     1.00                         5     c4 41 29 15 d2                vunpckhpd	%xmm10, %xmm10, %xmm10
 1      3     0.50                         4     c5 a9 59 c0                   vmulpd	%xmm0, %xmm10, %xmm0
 1      5     0.50    *                    6     c5 7b 12 5c 1a 10             vmovddup	16(%rdx,%rbx), %xmm11
 1      5     0.50                         5     c4 62 f1 a6 d8                vfmaddsub213pd	%xmm0, %xmm1, %xmm11
 1      3     1.00                         5     c4 c1 19 58 c3                vaddpd	%xmm11, %xmm12, %xmm0
 2      1     1.00           *             6     c4 a1 79 11 04 22             vmovupd	%xmm0, (%rdx,%r12)
 1      5     0.50    *                    6     c5 f9 10 4c 1a 20             vmovupd	32(%rdx,%rbx), %xmm1
 1      1     1.00                         4     c5 f1 15 c9                   vunpckhpd	%xmm1, %xmm1, %xmm1
 1      3     0.50                         4     c5 f1 59 d2                   vmulpd	%xmm2, %xmm1, %xmm2
 1      5     0.50    *                    6     c5 7b 12 54 1a 20             vmovddup	32(%rdx,%rbx), %xmm10
 1      5     0.50                         5     c4 62 e1 a6 d2                vfmaddsub213pd	%xmm2, %xmm3, %xmm10
 1      3     1.00                         5     c4 c1 79 58 da                vaddpd	%xmm10, %xmm0, %xmm3
 2      1     1.00           *             6     c4 a1 79 11 1c 22             vmovupd	%xmm3, (%rdx,%r12)
 1      5     0.50    *                    5     c5 79 10 1c 1a                vmovupd	(%rdx,%rbx), %xmm11
 1      1     1.00                         5     c4 41 21 15 e3                vunpckhpd	%xmm11, %xmm11, %xmm12
 1      3     0.50                         4     c5 99 59 ed                   vmulpd	%xmm5, %xmm12, %xmm5
 1      5     0.50    *                    5     c5 7b 12 3c 1a                vmovddup	(%rdx,%rbx), %xmm15
 1      5     0.50                         5     c4 62 d9 a6 fd                vfmaddsub213pd	%xmm5, %xmm4, %xmm15
 2      1     1.00           *             7     c4 21 79 11 7c 22 10          vmovupd	%xmm15, 16(%rdx,%r12)
 1      5     0.50    *                    6     c5 f9 10 64 1a 10             vmovupd	16(%rdx,%rbx), %xmm4
 1      1     1.00                         4     c5 59 15 ec                   vunpckhpd	%xmm4, %xmm4, %xmm13
 1      3     0.50                         4     c5 91 59 f6                   vmulpd	%xmm6, %xmm13, %xmm6
 1      5     0.50    *                    6     c5 fb 12 44 1a 10             vmovddup	16(%rdx,%rbx), %xmm0
 1      5     0.50                         5     c4 e2 c1 a6 c6                vfmaddsub213pd	%xmm6, %xmm7, %xmm0
 1      3     1.00                         4     c5 81 58 c0                   vaddpd	%xmm0, %xmm15, %xmm0
 2      1     1.00           *             7     c4 a1 79 11 44 22 10          vmovupd	%xmm0, 16(%rdx,%r12)
 1      5     0.50    *                    6     c5 f9 10 7c 1a 20             vmovupd	32(%rdx,%rbx), %xmm7
 1      1     1.00                         4     c5 c1 15 ff                   vunpckhpd	%xmm7, %xmm7, %xmm7
 1      3     0.50                         5     c4 41 41 59 c0                vmulpd	%xmm8, %xmm7, %xmm8
 1      5     0.50    *                    6     c5 fb 12 4c 1a 20             vmovddup	32(%rdx,%rbx), %xmm1
 1      5     0.50                         5     c4 c2 b1 a6 c8                vfmaddsub213pd	%xmm8, %xmm9, %xmm1
 1      3     1.00                         4     c5 79 58 c9                   vaddpd	%xmm1, %xmm0, %xmm9
 2      1     1.00           *             7     c4 21 79 11 4c 22 10          vmovupd	%xmm9, 16(%rdx,%r12)
 1      5     0.50    *                    5     c5 f9 10 04 1a                vmovupd	(%rdx,%rbx), %xmm0
 1      1     1.00                         4     c5 f9 15 c8                   vunpckhpd	%xmm0, %xmm0, %xmm1
 2      8     0.50    *                    9     c5 f1 59 94 24 e0 00 00 00    vmulpd	224(%rsp), %xmm1, %xmm2
 1      5     0.50    *                    5     c5 fb 12 34 1a                vmovddup	(%rdx,%rbx), %xmm6
 2      10    0.50    *                    7     c4 a2 e9 96 74 10 60          vfmaddsub132pd	96(%rax,%r10), %xmm2, %xmm6
 2      1     1.00           *             7     c4 a1 79 11 74 22 20          vmovupd	%xmm6, 32(%rdx,%r12)
 1      5     0.50    *                    6     c5 f9 10 5c 1a 10             vmovupd	16(%rdx,%rbx), %xmm3
 1      1     1.00                         4     c5 e1 15 e3                   vunpckhpd	%xmm3, %xmm3, %xmm4
 2      8     0.50    *                    9     c5 d9 59 ac 24 f0 00 00 00    vmulpd	240(%rsp), %xmm4, %xmm5
 1      5     0.50    *                    6     c5 fb 12 7c 1a 10             vmovddup	16(%rdx,%rbx), %xmm7
 2      10    0.50    *                    7     c4 a2 d1 96 7c 10 70          vfmaddsub132pd	112(%rax,%r10), %xmm5, %xmm7
 1      1     0.25                         6     48 05 90 00 00 00             addq	$144, %rax
 1      3     1.00                         4     c5 49 58 df                   vaddpd	%xmm7, %xmm6, %xmm11
 2      1     1.00           *             7     c4 21 79 11 5c 22 20          vmovupd	%xmm11, 32(%rdx,%r12)
 1      5     0.50    *                    6     c5 79 10 44 1a 20             vmovupd	32(%rdx,%rbx), %xmm8
 1      1     1.00                         5     c4 41 39 15 c8                vunpckhpd	%xmm8, %xmm8, %xmm9
 2      8     0.50    *                    9     c5 31 59 94 24 00 01 00 00    vmulpd	256(%rsp), %xmm9, %xmm10
 1      5     0.50    *                    6     c5 7b 12 64 1a 20             vmovddup	32(%rdx,%rbx), %xmm12
 1      5     0.50                         5     c4 42 89 a6 e2                vfmaddsub213pd	%xmm10, %xmm14, %xmm12
 1      3     1.00                         5     c4 41 21 58 f4                vaddpd	%xmm12, %xmm11, %xmm14
 2      1     1.00           *             7     c4 21 79 11 74 22 20          vmovupd	%xmm14, 32(%rdx,%r12)
 1      1     0.25                         4     48 83 c2 30                   addq	$48, %rdx


Resources:
[0]   - BWDivider
[1]   - BWFPDivider
[2]   - BWPort0
[3]   - BWPort1
[4]   - BWPort2
[5]   - BWPort3
[6]   - BWPort4
[7]   - BWPort5
[8]   - BWPort6
[9]   - BWPort7


Resource pressure per iteration:
[0]    [1]    [2]    [3]    [4]    [5]    [6]    [7]    [8]    [9]    
 -      -     24.00  24.00  26.50  26.51  21.00  27.00  3.00   17.99  

Resource pressure by instruction:
[0]    [1]    [2]    [3]    [4]    [5]    [6]    [7]    [8]    [9]    Instructions:
 -      -      -      -      -      -      -      -     1.00    -     incl	%ecx
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	(%rax,%r10), %xmm10
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	(%rdx,%r9), %xmm8
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	16(%rax,%r10), %xmm1
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm8, %xmm8, %xmm7
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$1, %xmm10, %xmm10, %xmm11
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm11, %xmm7, %xmm6
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	(%rdx,%r9), %xmm2
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub213pd	%xmm6, %xmm10, %xmm2
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$1, %xmm1, %xmm1, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm2, (%rdx,%r13)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	16(%rdx,%r9), %xmm4
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm4, %xmm4, %xmm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm0, %xmm5, %xmm3
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	48(%rax,%r10), %xmm4
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	16(%rdx,%r9), %xmm14
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub213pd	%xmm3, %xmm1, %xmm14
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	32(%rax,%r10), %xmm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm14, %xmm2, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm8, (%rdx,%r13)
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$1, %xmm3, %xmm3, %xmm2
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	32(%rdx,%r9), %xmm15
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm15, %xmm15, %xmm14
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm2, %xmm14, %xmm9
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	32(%rdx,%r9), %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub213pd	%xmm9, %xmm3, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm7, %xmm8, %xmm6
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	64(%rax,%r10), %xmm7
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm6, (%rdx,%r13)
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$1, %xmm7, %xmm7, %xmm6
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	(%rdx,%r9), %xmm5
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm5, %xmm5, %xmm12
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$1, %xmm4, %xmm4, %xmm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm5, %xmm12, %xmm13
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	(%rdx,%r9), %xmm9
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub213pd	%xmm13, %xmm4, %xmm9
 -      -      -      -     0.50   0.50   1.00    -      -      -     vmovupd	%xmm9, 16(%rdx,%r13)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	16(%rdx,%r9), %xmm15
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm15, %xmm15, %xmm14
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm6, %xmm14, %xmm8
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	16(%rdx,%r9), %xmm12
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub213pd	%xmm8, %xmm7, %xmm12
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm12, %xmm9, %xmm13
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	80(%rax,%r10), %xmm9
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm13, 16(%rdx,%r13)
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$1, %xmm9, %xmm9, %xmm8
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	32(%rdx,%r9), %xmm15
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm15, %xmm15, %xmm12
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm8, %xmm12, %xmm15
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	32(%rdx,%r9), %xmm14
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub213pd	%xmm15, %xmm9, %xmm14
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm14, %xmm13, %xmm13
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	96(%rax,%r10), %xmm14
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm13, 16(%rdx,%r13)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	(%rdx,%r9), %xmm13
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm13, %xmm13, %xmm15
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$1, %xmm14, %xmm14, %xmm13
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm13, %xmm15, %xmm15
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	(%rdx,%r9), %xmm12
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub213pd	%xmm15, %xmm14, %xmm12
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	112(%rax,%r10), %xmm15
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm13, 224(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm12, 32(%rdx,%r13)
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$1, %xmm15, %xmm15, %xmm13
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	16(%rdx,%r9), %xmm14
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm14, %xmm14, %xmm14
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm13, %xmm14, %xmm14
 -      -      -      -     0.50   0.50   1.00    -      -      -     vmovupd	%xmm13, 240(%rsp)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	16(%rdx,%r9), %xmm13
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub213pd	%xmm14, %xmm15, %xmm13
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	128(%rax,%r10), %xmm14
 -      -      -      -      -      -      -     1.00    -      -     vshufpd	$1, %xmm14, %xmm14, %xmm15
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm13, %xmm12, %xmm13
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm13, 32(%rdx,%r13)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm15, 256(%rsp)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	32(%rdx,%r9), %xmm12
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm12, %xmm12, %xmm12
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%xmm15, %xmm12, %xmm12
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	32(%rdx,%r9), %xmm15
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub213pd	%xmm12, %xmm14, %xmm15
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm15, %xmm13, %xmm13
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm13, 32(%rdx,%r13)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	(%rdx,%rbx), %xmm13
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm13, %xmm13, %xmm15
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm11, %xmm15, %xmm11
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	(%rdx,%rbx), %xmm12
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub213pd	%xmm11, %xmm10, %xmm12
 -      -      -      -     0.50   0.50   1.00    -      -      -     vmovupd	%xmm12, (%rdx,%r12)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	16(%rdx,%rbx), %xmm10
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm10, %xmm10, %xmm10
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm0, %xmm10, %xmm0
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	16(%rdx,%rbx), %xmm11
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub213pd	%xmm0, %xmm1, %xmm11
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm11, %xmm12, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm0, (%rdx,%r12)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	32(%rdx,%rbx), %xmm1
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm1, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%xmm2, %xmm1, %xmm2
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	32(%rdx,%rbx), %xmm10
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub213pd	%xmm2, %xmm3, %xmm10
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm10, %xmm0, %xmm3
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm3, (%rdx,%r12)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	(%rdx,%rbx), %xmm11
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm11, %xmm11, %xmm12
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm5, %xmm12, %xmm5
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	(%rdx,%rbx), %xmm15
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub213pd	%xmm5, %xmm4, %xmm15
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm15, 16(%rdx,%r12)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	16(%rdx,%rbx), %xmm4
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm4, %xmm4, %xmm13
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm6, %xmm13, %xmm6
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	16(%rdx,%rbx), %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub213pd	%xmm6, %xmm7, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm0, %xmm15, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm0, 16(%rdx,%r12)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	32(%rdx,%rbx), %xmm7
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm7, %xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%xmm8, %xmm7, %xmm8
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	32(%rdx,%rbx), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub213pd	%xmm8, %xmm9, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm1, %xmm0, %xmm9
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm9, 16(%rdx,%r12)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	(%rdx,%rbx), %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm0, %xmm0, %xmm1
 -      -      -     1.00   0.50   0.50    -      -      -      -     vmulpd	224(%rsp), %xmm1, %xmm2
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	(%rdx,%rbx), %xmm6
 -      -     1.00    -     0.50   0.50    -      -      -      -     vfmaddsub132pd	96(%rax,%r10), %xmm2, %xmm6
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm6, 32(%rdx,%r12)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	16(%rdx,%rbx), %xmm3
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm3, %xmm3, %xmm4
 -      -      -     1.00   0.50   0.50    -      -      -      -     vmulpd	240(%rsp), %xmm4, %xmm5
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	16(%rdx,%rbx), %xmm7
 -      -     1.00    -     0.50   0.50    -      -      -      -     vfmaddsub132pd	112(%rax,%r10), %xmm5, %xmm7
 -      -      -      -      -      -      -      -     1.00    -     addq	$144, %rax
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm7, %xmm6, %xmm11
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm11, 32(%rdx,%r12)
 -      -      -      -     0.50   0.50    -      -      -      -     vmovupd	32(%rdx,%rbx), %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vunpckhpd	%xmm8, %xmm8, %xmm9
 -      -     1.00    -     0.50   0.50    -      -      -      -     vmulpd	256(%rsp), %xmm9, %xmm10
 -      -      -      -     0.50   0.50    -      -      -      -     vmovddup	32(%rdx,%rbx), %xmm12
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub213pd	%xmm10, %xmm14, %xmm12
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm12, %xmm11, %xmm14
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm14, 32(%rdx,%r12)
 -      -      -      -      -      -      -      -     1.00    -     addq	$48, %rdx
