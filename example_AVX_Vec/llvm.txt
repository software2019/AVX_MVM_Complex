Iterations:        300
Instructions:      1190100
Total Cycles:      678604
Total uOps:        1538400

Dispatch Width:    4
uOps Per Cycle:    2.27
IPC:               1.75
Block RThroughput: 1282.0


Instruction Info:
[1]: #uOps
[2]: Latency
[3]: RThroughput
[4]: MayLoad
[5]: MayStore
[6]: HasSideEffects (U)
[7]: Encoding Size

[1]    [2]    [3]    [4]    [5]    [6]    [7]    Encodings:                    Instructions:
 3      2     1.00           *             1     55                            pushq	%rbp
 1      1     0.25                         3     48 89 e5                      movq	%rsp, %rbp
 3      2     1.00           *             2     41 57                         pushq	%r15
 3      2     1.00           *             2     41 56                         pushq	%r14
 3      2     1.00           *             2     41 55                         pushq	%r13
 3      2     1.00           *             2     41 54                         pushq	%r12
 3      2     1.00           *             1     53                            pushq	%rbx
 1      1     0.25                         4     48 83 e4 e0                   andq	$-32, %rsp
 1      1     0.25                         7     48 81 ec 40 01 00 00          subq	$320, %rsp
 1      6     0.50    *                    8     c5 fc 28 05 00 00 00 00       vmovaps	.LCPI0_0(%rip), %ymm0
 2      1     1.00           *             8     c5 fc 29 05 00 00 00 00       vmovaps	%ymm0, mask(%rip)
 1      1     0.25                         5     bf 90 00 00 00                movl	$144, %edi
 1      1     0.25                         5     be 08 00 00 00                movl	$8, %esi
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	amalloc
 1      1     0.25                         3     49 89 c4                      movq	%rax, %r12
 1      1     0.25                         5     bf 30 00 00 00                movl	$48, %edi
 1      1     0.25                         5     be 08 00 00 00                movl	$8, %esi
 4      3     1.00                         5     e8 00 00 00 00                callq	amalloc
 1      1     0.25                         3     49 89 c6                      movq	%rax, %r14
 1      1     0.25                         5     bf 30 00 00 00                movl	$48, %edi
 1      1     0.25                         5     be 08 00 00 00                movl	$8, %esi
 4      3     1.00                         5     e8 00 00 00 00                callq	amalloc
 1      1     0.25                         3     49 89 c7                      movq	%rax, %r15
 1      1     0.25                         5     bf 30 00 00 00                movl	$48, %edi
 1      1     0.25                         5     be 08 00 00 00                movl	$8, %esi
 4      3     1.00                         5     e8 00 00 00 00                callq	amalloc
 1      1     1.00           *             4     48 89 04 24                   movq	%rax, (%rsp)
 1      1     0.25                         5     bf 30 00 00 00                movl	$48, %edi
 1      1     0.25                         5     be 08 00 00 00                movl	$8, %esi
 4      3     1.00                         5     e8 00 00 00 00                callq	amalloc
 1      1     0.25                         3     48 89 c3                      movq	%rax, %rbx
 1      1     0.25                         5     bf 30 00 00 00                movl	$48, %edi
 1      1     0.25                         5     be 08 00 00 00                movl	$8, %esi
 4      3     1.00                         5     e8 00 00 00 00                callq	amalloc
 1      1     1.00           *             5     48 89 44 24 78                movq	%rax, 120(%rsp)
 1      1     0.25                         5     bf 30 00 00 00                movl	$48, %edi
 1      1     0.25                         5     be 08 00 00 00                movl	$8, %esi
 4      3     1.00                         5     e8 00 00 00 00                callq	amalloc
 1      6     0.50    *                    8     c5 fc 28 05 00 00 00 00       vmovaps	.LCPI0_1(%rip), %ymm0
 2      1     1.00           *             5     c4 c1 7c 11 06                vmovups	%ymm0, (%r14)
 1      5     0.50    *                    8     c5 f8 28 05 00 00 00 00       vmovaps	.LCPI0_2(%rip), %xmm0
 2      1     1.00           *             6     c4 c1 78 11 46 20             vmovups	%xmm0, 32(%r14)
 1      6     0.50    *                    8     c5 fc 28 05 00 00 00 00       vmovaps	.LCPI0_3(%rip), %ymm0
 2      1     1.00           *             5     c4 c1 7c 11 07                vmovups	%ymm0, (%r15)
 1      5     0.50    *                    8     c5 f8 28 0d 00 00 00 00       vmovaps	.LCPI0_4(%rip), %xmm1
 2      1     1.00           *             6     c4 c1 78 11 4f 20             vmovups	%xmm1, 32(%r15)
 2      1     1.00           *             6     c4 c1 7c 11 04 24             vmovups	%ymm0, (%r12)
 1      6     0.50    *                    8     c5 fc 28 05 00 00 00 00       vmovaps	.LCPI0_5(%rip), %ymm0
 2      1     1.00           *             7     c4 c1 7c 11 44 24 20          vmovups	%ymm0, 32(%r12)
 1      6     0.50    *                    8     c5 fc 28 05 00 00 00 00       vmovaps	.LCPI0_6(%rip), %ymm0
 2      1     1.00           *             7     c4 c1 7c 11 44 24 40          vmovups	%ymm0, 64(%r12)
 1      6     0.50    *                    8     c5 fc 28 05 00 00 00 00       vmovaps	.LCPI0_7(%rip), %ymm0
 2      1     1.00           *             7     c4 c1 7c 11 44 24 60          vmovups	%ymm0, 96(%r12)
 1      1     0.25                         3     49 89 c5                      movq	%rax, %r13
 1      5     0.50    *                    8     c5 f8 28 05 00 00 00 00       vmovaps	.LCPI0_8(%rip), %xmm0
 2      1     1.00           *             10    c4 c1 78 11 84 24 80 00 00 00  vmovups	%xmm0, 128(%r12)
 1      1     0.25                         3     4c 89 f7                      movq	%r14, %rdi
 1      1     0.25                         3     4c 89 fe                      movq	%r15, %rsi
 1      1     0.25                         3     4c 89 e2                      movq	%r12, %rdx
 1      1     0.25                         5     b9 05 00 00 00                movl	$5, %ecx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	my_init
 1      1     0.25                         3     48 89 da                      movq	%rbx, %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      6     0.50    *                    6     c4 c1 7d 28 04 24             vmovapd	(%r12), %ymm0
 1      1     1.00                         4     c5 ff 12 f0                   vmovddup	%ymm0, %ymm6
 1      1     1.00                         6     c4 63 7d 05 c0 0f             vpermilpd	$15, %ymm0, %ymm8
 1      6     0.50    *                    7     c4 c1 7d 10 44 24 30          vmovupd	48(%r12), %ymm0
 1      1     1.00                         4     c5 ff 12 f8                   vmovddup	%ymm0, %ymm7
 1      1     1.00                         6     c4 63 7d 05 c8 0f             vpermilpd	$15, %ymm0, %ymm9
 1      6     0.50    *                    7     c4 c1 7d 28 4c 24 60          vmovapd	96(%r12), %ymm1
 1      1     1.00                         4     c5 ff 12 c1                   vmovddup	%ymm1, %ymm0
 1      1     1.00                         6     c4 e3 7d 05 c9 0f             vpermilpd	$15, %ymm1, %ymm1
 1      6     0.50    *                    5     c4 c1 7d 28 16                vmovapd	(%r14), %ymm2
 1      1     1.00                         6     c4 e3 7d 05 da 05             vpermilpd	$5, %ymm2, %ymm3
 1      3     0.50                         4     c5 bd 59 e3                   vmulpd	%ymm3, %ymm8, %ymm4
 1      5     0.50                         5     c4 e2 cd b6 e2                vfmaddsub231pd	%ymm2, %ymm6, %ymm4
 1      3     0.50                         4     c5 b5 59 eb                   vmulpd	%ymm3, %ymm9, %ymm5
 1      5     0.50                         5     c4 e2 c5 b6 ea                vfmaddsub231pd	%ymm2, %ymm7, %ymm5
 1      3     1.00                         6     c4 63 5d 18 d5 01             vinsertf128	$1, %xmm5, %ymm4, %ymm10
 1      3     1.00                         6     c4 e3 5d 06 e5 31             vperm2f128	$49, %ymm5, %ymm4, %ymm4
 1      6     0.50    *                    7     c4 c1 7d 10 6c 24 10          vmovupd	16(%r12), %ymm5
 2      9     1.00    *                    8     c4 c3 55 06 6c 24 40 31       vperm2f128	$49, 64(%r12), %ymm5, %ymm5
 1      3     1.00                         4     c5 2d 58 d4                   vaddpd	%ymm4, %ymm10, %ymm10
 1      6     0.50    *                    6     c4 c1 7d 10 66 10             vmovupd	16(%r14), %ymm4
 1      3     1.00                         6     c4 63 fd 01 dc ee             vpermpd	$238, %ymm4, %ymm11
 1      1     1.00                         4     c5 7f 12 e5                   vmovddup	%ymm5, %ymm12
 1      1     1.00                         6     c4 63 7d 05 ed 0f             vpermilpd	$15, %ymm5, %ymm13
 1      3     1.00                         6     c4 e3 fd 01 ec bb             vpermpd	$187, %ymm4, %ymm5
 1      3     0.50                         4     c5 95 59 ed                   vmulpd	%ymm5, %ymm13, %ymm5
 1      5     0.50                         5     c4 c2 9d b6 eb                vfmaddsub231pd	%ymm11, %ymm12, %ymm5
 1      6     0.50    *                    5     c4 41 7d 28 1f                vmovapd	(%r15), %ymm11
 1      3     1.00                         4     c5 ad 58 ed                   vaddpd	%ymm5, %ymm10, %ymm5
 1      1     1.00                         6     c4 43 7d 05 d3 05             vpermilpd	$5, %ymm11, %ymm10
 1      3     0.50                         5     c4 41 3d 59 c2                vmulpd	%ymm10, %ymm8, %ymm8
 1      5     0.50                         5     c4 62 a5 b6 c6                vfmaddsub231pd	%ymm6, %ymm11, %ymm8
 1      3     0.50                         5     c4 c1 35 59 f2                vmulpd	%ymm10, %ymm9, %ymm6
 1      5     0.50                         5     c4 e2 a5 b6 f7                vfmaddsub231pd	%ymm7, %ymm11, %ymm6
 1      3     1.00                         6     c4 e3 3d 18 fe 01             vinsertf128	$1, %xmm6, %ymm8, %ymm7
 1      3     1.00                         6     c4 e3 3d 06 f6 31             vperm2f128	$49, %ymm6, %ymm8, %ymm6
 1      3     1.00                         4     c5 c5 58 f6                   vaddpd	%ymm6, %ymm7, %ymm6
 1      6     0.50    *                    6     c4 c1 7d 10 7f 10             vmovupd	16(%r15), %ymm7
 1      3     1.00                         6     c4 63 fd 01 c7 ee             vpermpd	$238, %ymm7, %ymm8
 1      3     1.00                         6     c4 63 fd 01 cf bb             vpermpd	$187, %ymm7, %ymm9
 1      3     0.50                         5     c4 41 15 59 c9                vmulpd	%ymm9, %ymm13, %ymm9
 1      5     0.50                         5     c4 42 9d b6 c8                vfmaddsub231pd	%ymm8, %ymm12, %ymm9
 1      3     1.00                         4     c5 b5 58 f6                   vaddpd	%ymm6, %ymm9, %ymm6
 1      3     0.50                         4     c5 f5 59 db                   vmulpd	%ymm3, %ymm1, %ymm3
 1      5     0.50                         5     c4 e2 fd b6 da                vfmaddsub231pd	%ymm2, %ymm0, %ymm3
 1      3     0.50                         4     c5 ad 59 c9                   vmulpd	%ymm1, %ymm10, %ymm1
 1      5     0.50                         5     c4 c2 fd b6 cb                vfmaddsub231pd	%ymm11, %ymm0, %ymm1
 1      3     1.00                         6     c4 e3 65 18 c1 01             vinsertf128	$1, %xmm1, %ymm3, %ymm0
 1      3     1.00                         6     c4 e3 65 06 c9 31             vperm2f128	$49, %ymm1, %ymm3, %ymm1
 1      3     1.00                         4     c5 fd 58 c1                   vaddpd	%ymm1, %ymm0, %ymm0
 1      6     0.50    *                    10    c4 c2 7d 19 8c 24 80 00 00 00  vbroadcastsd	128(%r12), %ymm1
 1      6     0.50    *                    10    c4 c2 7d 19 94 24 88 00 00 00  vbroadcastsd	136(%r12), %ymm2
 1      3     1.00                         6     c4 e3 5d 06 df 31             vperm2f128	$49, %ymm7, %ymm4, %ymm3
 1      1     1.00                         6     c4 e3 7d 05 e3 05             vpermilpd	$5, %ymm3, %ymm4
 1      3     0.50                         4     c5 dd 59 d2                   vmulpd	%ymm2, %ymm4, %ymm2
 1      5     0.50                         5     c4 e2 e5 b6 d1                vfmaddsub231pd	%ymm1, %ymm3, %ymm2
 1      3     1.00                         4     c5 fd 58 c2                   vaddpd	%ymm2, %ymm0, %ymm0
 1      5     0.50    *                    5     48 8b 44 24 78                movq	120(%rsp), %rax
 2      1     1.00           *             4     c5 fd 29 28                   vmovapd	%ymm5, (%rax)
 2      1     1.00           *             5     c5 f9 29 40 20                vmovapd	%xmm0, 32(%rax)
 2      1     1.00           *             6     c4 c1 7d 29 75 00             vmovapd	%ymm6, (%r13)
 1      1     1.00           *             8     4c 89 ac 24 90 00 00 00       movq	%r13, 144(%rsp)
 2      1     1.00           *             7     c4 c3 7d 19 45 20 01          vextractf128	$1, %ymm0, 32(%r13)
 1      6     0.50    *                    6     c4 c1 7d 10 04 24             vmovupd	(%r12), %ymm0
 1      6     0.50    *                    7     c4 41 7d 10 4c 24 10          vmovupd	16(%r12), %ymm9
 1      6     0.50    *                    7     c4 c1 7d 10 64 24 30          vmovupd	48(%r12), %ymm4
 1      6     0.50    *                    7     c4 c1 7d 10 4c 24 60          vmovupd	96(%r12), %ymm1
 1      1     1.00                         4     c5 ff 12 d0                   vmovddup	%ymm0, %ymm2
 1      1     1.00                         6     c4 e3 7d 05 e8 0f             vpermilpd	$15, %ymm0, %ymm5
 1      1     1.00                         4     c5 ff 12 dc                   vmovddup	%ymm4, %ymm3
 1      1     1.00                         6     c4 e3 7d 05 f4 0f             vpermilpd	$15, %ymm4, %ymm6
 1      6     0.50    *                    5     c4 c1 7d 10 26                vmovupd	(%r14), %ymm4
 1      6     0.50    *                    6     c4 c1 7d 10 46 10             vmovupd	16(%r14), %ymm0
 1      1     1.00                         6     c4 63 7d 05 c4 05             vpermilpd	$5, %ymm4, %ymm8
 1      6     0.50    *                    5     c4 c1 7d 10 3f                vmovupd	(%r15), %ymm7
 2      9     1.00    *                    8     c4 43 35 06 54 24 40 31       vperm2f128	$49, 64(%r12), %ymm9, %ymm10
 1      6     0.50    *                    6     c4 41 7d 10 4f 10             vmovupd	16(%r15), %ymm9
 1      3     1.00                         6     c4 63 fd 01 d8 ee             vpermpd	$238, %ymm0, %ymm11
 1      1     1.00                         5     c4 41 7f 12 e2                vmovddup	%ymm10, %ymm12
 1      1     1.00                         6     c4 43 7d 05 d2 0f             vpermilpd	$15, %ymm10, %ymm10
 1      3     1.00                         6     c4 63 fd 01 e8 bb             vpermpd	$187, %ymm0, %ymm13
 1      3     0.50                         5     c4 41 2d 59 ed                vmulpd	%ymm13, %ymm10, %ymm13
 1      5     0.50                         5     c4 42 9d b6 eb                vfmaddsub231pd	%ymm11, %ymm12, %ymm13
 1      3     1.00                         6     c4 43 fd 01 d9 bb             vpermpd	$187, %ymm9, %ymm11
 1      3     0.50                         5     c4 41 2d 59 d3                vmulpd	%ymm11, %ymm10, %ymm10
 1      3     1.00                         6     c4 43 fd 01 d9 ee             vpermpd	$238, %ymm9, %ymm11
 1      5     0.50                         5     c4 42 9d b6 d3                vfmaddsub231pd	%ymm11, %ymm12, %ymm10
 1      1     1.00                         6     c4 63 7d 05 df 05             vpermilpd	$5, %ymm7, %ymm11
 1      3     0.50                         4     c5 3d 59 e5                   vmulpd	%ymm5, %ymm8, %ymm12
 1      5     0.50                         5     c4 62 ed b6 e4                vfmaddsub231pd	%ymm4, %ymm2, %ymm12
 1      3     0.50                         4     c5 a5 59 ed                   vmulpd	%ymm5, %ymm11, %ymm5
 1      5     0.50                         5     c4 e2 c5 b6 ea                vfmaddsub231pd	%ymm2, %ymm7, %ymm5
 1      3     0.50                         4     c5 bd 59 d6                   vmulpd	%ymm6, %ymm8, %ymm2
 1      5     0.50                         5     c4 e2 e5 b6 d4                vfmaddsub231pd	%ymm4, %ymm3, %ymm2
 1      3     0.50                         4     c5 a5 59 f6                   vmulpd	%ymm6, %ymm11, %ymm6
 1      5     0.50                         5     c4 e2 c5 b6 f3                vfmaddsub231pd	%ymm3, %ymm7, %ymm6
 1      1     1.00                         4     c5 ff 12 d9                   vmovddup	%ymm1, %ymm3
 1      1     1.00                         6     c4 e3 7d 05 c9 0f             vpermilpd	$15, %ymm1, %ymm1
 1      3     0.50                         4     c5 3d 59 c1                   vmulpd	%ymm1, %ymm8, %ymm8
 1      5     0.50                         5     c4 62 e5 b6 c4                vfmaddsub231pd	%ymm4, %ymm3, %ymm8
 1      3     0.50                         4     c5 a5 59 c9                   vmulpd	%ymm1, %ymm11, %ymm1
 1      5     0.50                         5     c4 e2 e5 b6 cf                vfmaddsub231pd	%ymm7, %ymm3, %ymm1
 1      3     1.00                         6     c4 e3 1d 18 da 01             vinsertf128	$1, %xmm2, %ymm12, %ymm3
 1      3     1.00                         6     c4 e3 1d 06 d2 31             vperm2f128	$49, %ymm2, %ymm12, %ymm2
 1      3     1.00                         4     c5 e5 58 d2                   vaddpd	%ymm2, %ymm3, %ymm2
 1      3     1.00                         4     c5 95 58 d2                   vaddpd	%ymm2, %ymm13, %ymm2
 1      3     1.00                         6     c4 e3 55 18 de 01             vinsertf128	$1, %xmm6, %ymm5, %ymm3
 1      3     1.00                         6     c4 e3 55 06 e6 31             vperm2f128	$49, %ymm6, %ymm5, %ymm4
 1      3     1.00                         4     c5 e5 58 dc                   vaddpd	%ymm4, %ymm3, %ymm3
 1      3     1.00                         4     c5 ad 58 db                   vaddpd	%ymm3, %ymm10, %ymm3
 1      3     1.00                         6     c4 e3 3d 18 e1 01             vinsertf128	$1, %xmm1, %ymm8, %ymm4
 1      3     1.00                         6     c4 e3 3d 06 c9 31             vperm2f128	$49, %ymm1, %ymm8, %ymm1
 1      3     1.00                         4     c5 dd 58 c9                   vaddpd	%ymm1, %ymm4, %ymm1
 1      6     0.50    *                    10    c4 c2 7d 19 a4 24 80 00 00 00  vbroadcastsd	128(%r12), %ymm4
 1      6     0.50    *                    10    c4 c2 7d 19 ac 24 88 00 00 00  vbroadcastsd	136(%r12), %ymm5
 1      3     1.00                         6     c4 c3 7d 06 c1 31             vperm2f128	$49, %ymm9, %ymm0, %ymm0
 1      1     1.00                         6     c4 e3 7d 05 f0 05             vpermilpd	$5, %ymm0, %ymm6
 1      3     0.50                         4     c5 cd 59 ed                   vmulpd	%ymm5, %ymm6, %ymm5
 1      5     0.50                         5     c4 e2 fd b6 ec                vfmaddsub231pd	%ymm4, %ymm0, %ymm5
 1      3     1.00                         4     c5 f5 58 c5                   vaddpd	%ymm5, %ymm1, %ymm0
 2      1     1.00           *             4     c5 fd 11 11                   vmovupd	%ymm2, (%rcx)
 2      1     1.00           *             5     c5 f9 11 41 20                vmovupd	%xmm0, 32(%rcx)
 2      1     1.00           *             4     c5 fd 11 1b                   vmovupd	%ymm3, (%rbx)
 2      1     1.00           *             7     c4 e3 7d 19 43 20 01          vextractf128	$1, %ymm0, 32(%rbx)
 1      5     0.50    *                    6     c4 c1 7b 10 04 24             vmovsd	(%r12), %xmm0
 1      5     0.50    *                    7     c4 c1 7b 10 4c 24 08          vmovsd	8(%r12), %xmm1
 1      5     0.50    *                    5     c4 c1 7b 10 16                vmovsd	(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 08             vmovsd	8(%r14), %xmm3
 1      3     0.50                         4     c5 fb 59 e2                   vmulsd	%xmm2, %xmm0, %xmm4
 1      3     0.50                         4     c5 f3 59 eb                   vmulsd	%xmm3, %xmm1, %xmm5
 1      3     1.00                         4     c5 db 5c fd                   vsubsd	%xmm5, %xmm4, %xmm7
 1      3     0.50                         4     c5 fb 59 e3                   vmulsd	%xmm3, %xmm0, %xmm4
 1      3     0.50                         4     c5 f3 59 ea                   vmulsd	%xmm2, %xmm1, %xmm5
 1      3     1.00                         4     c5 53 58 c4                   vaddsd	%xmm4, %xmm5, %xmm8
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     1.00           *             5     48 89 5c 24 08                movq	%rbx, 8(%rsp)
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_1
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 10          vmovsd	16(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 18          vmovsd	24(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 10             vmovsd	16(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 18             vmovsd	24(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_4
 1      3     1.00                         4     c5 3b 58 c1                   vaddsd	%xmm1, %xmm8, %xmm8
 1      3     1.00                         4     c5 c3 58 f8                   vaddsd	%xmm0, %xmm7, %xmm7
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 20          vmovsd	32(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 28          vmovsd	40(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 20             vmovsd	32(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 28             vmovsd	40(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_7
 1      3     1.00                         4     c5 3b 58 c1                   vaddsd	%xmm1, %xmm8, %xmm8
 1      3     1.00                         4     c5 c3 58 f8                   vaddsd	%xmm0, %xmm7, %xmm7
 2      1     1.00           *             9     c5 fb 11 bc 24 f8 00 00 00    vmovsd	%xmm7, 248(%rsp)
 2      1     1.00           *             9     c5 7b 11 84 24 00 01 00 00    vmovsd	%xmm8, 256(%rsp)
 1      5     0.50    *                    7     c4 c1 7b 10 44 24 30          vmovsd	48(%r12), %xmm0
 1      5     0.50    *                    7     c4 c1 7b 10 4c 24 38          vmovsd	56(%r12), %xmm1
 1      5     0.50    *                    5     c4 c1 7b 10 16                vmovsd	(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 08             vmovsd	8(%r14), %xmm3
 1      3     0.50                         4     c5 fb 59 e2                   vmulsd	%xmm2, %xmm0, %xmm4
 1      3     0.50                         4     c5 f3 59 eb                   vmulsd	%xmm3, %xmm1, %xmm5
 1      3     1.00                         4     c5 5b 5c cd                   vsubsd	%xmm5, %xmm4, %xmm9
 1      3     0.50                         4     c5 fb 59 e3                   vmulsd	%xmm3, %xmm0, %xmm4
 1      3     0.50                         4     c5 f3 59 ea                   vmulsd	%xmm2, %xmm1, %xmm5
 1      3     1.00                         4     c5 53 58 d4                   vaddsd	%xmm4, %xmm5, %xmm10
 1      3     1.00                         5     c4 41 79 2e c9                vucomisd	%xmm9, %xmm9
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_10
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 40          vmovsd	64(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 48          vmovsd	72(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 10             vmovsd	16(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 18             vmovsd	24(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_13
 1      3     1.00                         4     c5 2b 58 d1                   vaddsd	%xmm1, %xmm10, %xmm10
 1      3     1.00                         4     c5 33 58 c8                   vaddsd	%xmm0, %xmm9, %xmm9
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 50          vmovsd	80(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 58          vmovsd	88(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 20             vmovsd	32(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 28             vmovsd	40(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_16
 1      3     1.00                         4     c5 ab 58 c9                   vaddsd	%xmm1, %xmm10, %xmm1
 1      3     1.00                         4     c5 b3 58 c0                   vaddsd	%xmm0, %xmm9, %xmm0
 2      1     1.00           *             9     c5 fb 11 84 24 08 01 00 00    vmovsd	%xmm0, 264(%rsp)
 2      1     1.00           *             9     c5 fb 11 8c 24 10 01 00 00    vmovsd	%xmm1, 272(%rsp)
 1      5     0.50    *                    7     c4 c1 7b 10 44 24 60          vmovsd	96(%r12), %xmm0
 1      5     0.50    *                    7     c4 c1 7b 10 4c 24 68          vmovsd	104(%r12), %xmm1
 1      5     0.50    *                    5     c4 c1 7b 10 16                vmovsd	(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 08             vmovsd	8(%r14), %xmm3
 1      3     0.50                         4     c5 fb 59 e2                   vmulsd	%xmm2, %xmm0, %xmm4
 1      3     0.50                         4     c5 f3 59 eb                   vmulsd	%xmm3, %xmm1, %xmm5
 1      3     1.00                         4     c5 5b 5c cd                   vsubsd	%xmm5, %xmm4, %xmm9
 1      3     0.50                         4     c5 fb 59 e3                   vmulsd	%xmm3, %xmm0, %xmm4
 1      3     0.50                         4     c5 f3 59 ea                   vmulsd	%xmm2, %xmm1, %xmm5
 1      3     1.00                         4     c5 53 58 d4                   vaddsd	%xmm4, %xmm5, %xmm10
 1      3     1.00                         5     c4 41 79 2e c9                vucomisd	%xmm9, %xmm9
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_19
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 70          vmovsd	112(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 78          vmovsd	120(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 10             vmovsd	16(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 18             vmovsd	24(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_22
 1      3     1.00                         4     c5 2b 58 d1                   vaddsd	%xmm1, %xmm10, %xmm10
 1      3     1.00                         4     c5 33 58 c8                   vaddsd	%xmm0, %xmm9, %xmm9
 1      5     0.50    *                    10    c4 c1 7b 10 a4 24 80 00 00 00  vmovsd	128(%r12), %xmm4
 1      5     0.50    *                    10    c4 c1 7b 10 ac 24 88 00 00 00  vmovsd	136(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 20             vmovsd	32(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 28             vmovsd	40(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_25
 1      3     1.00                         4     c5 ab 58 c9                   vaddsd	%xmm1, %xmm10, %xmm1
 1      3     1.00                         4     c5 b3 58 c0                   vaddsd	%xmm0, %xmm9, %xmm0
 2      1     1.00           *             9     c5 fb 11 84 24 18 01 00 00    vmovsd	%xmm0, 280(%rsp)
 2      1     1.00           *             9     c5 fb 11 8c 24 20 01 00 00    vmovsd	%xmm1, 288(%rsp)
 1      5     0.50    *                    6     c4 c1 7b 10 04 24             vmovsd	(%r12), %xmm0
 1      5     0.50    *                    7     c4 c1 7b 10 4c 24 08          vmovsd	8(%r12), %xmm1
 1      5     0.50    *                    5     c4 c1 7b 10 17                vmovsd	(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 08             vmovsd	8(%r15), %xmm3
 1      3     0.50                         4     c5 fb 59 e2                   vmulsd	%xmm2, %xmm0, %xmm4
 1      3     0.50                         4     c5 f3 59 eb                   vmulsd	%xmm3, %xmm1, %xmm5
 1      3     1.00                         4     c5 5b 5c cd                   vsubsd	%xmm5, %xmm4, %xmm9
 1      3     0.50                         4     c5 fb 59 e3                   vmulsd	%xmm3, %xmm0, %xmm4
 1      3     0.50                         4     c5 f3 59 ea                   vmulsd	%xmm2, %xmm1, %xmm5
 1      3     1.00                         4     c5 53 58 d4                   vaddsd	%xmm4, %xmm5, %xmm10
 1      3     1.00                         5     c4 41 79 2e c9                vucomisd	%xmm9, %xmm9
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_28
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 10          vmovsd	16(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 18          vmovsd	24(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 10             vmovsd	16(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 18             vmovsd	24(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_31
 1      3     1.00                         4     c5 2b 58 d1                   vaddsd	%xmm1, %xmm10, %xmm10
 1      3     1.00                         4     c5 33 58 c8                   vaddsd	%xmm0, %xmm9, %xmm9
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 20          vmovsd	32(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 28          vmovsd	40(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 20             vmovsd	32(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 28             vmovsd	40(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_34
 1      3     1.00                         4     c5 ab 58 c9                   vaddsd	%xmm1, %xmm10, %xmm1
 1      3     1.00                         4     c5 b3 58 c0                   vaddsd	%xmm0, %xmm9, %xmm0
 2      1     1.00           *             6     c5 fb 11 44 24 20             vmovsd	%xmm0, 32(%rsp)
 2      1     1.00           *             9     c5 fb 11 84 24 c8 00 00 00    vmovsd	%xmm0, 200(%rsp)
 2      1     1.00           *             6     c5 fb 11 4c 24 50             vmovsd	%xmm1, 80(%rsp)
 2      1     1.00           *             9     c5 fb 11 8c 24 d0 00 00 00    vmovsd	%xmm1, 208(%rsp)
 1      5     0.50    *                    7     c4 c1 7b 10 44 24 30          vmovsd	48(%r12), %xmm0
 1      5     0.50    *                    7     c4 c1 7b 10 4c 24 38          vmovsd	56(%r12), %xmm1
 1      5     0.50    *                    5     c4 c1 7b 10 17                vmovsd	(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 08             vmovsd	8(%r15), %xmm3
 1      3     0.50                         4     c5 fb 59 e2                   vmulsd	%xmm2, %xmm0, %xmm4
 1      3     0.50                         4     c5 f3 59 eb                   vmulsd	%xmm3, %xmm1, %xmm5
 1      3     1.00                         4     c5 5b 5c cd                   vsubsd	%xmm5, %xmm4, %xmm9
 1      3     0.50                         4     c5 fb 59 e3                   vmulsd	%xmm3, %xmm0, %xmm4
 1      3     0.50                         4     c5 f3 59 ea                   vmulsd	%xmm2, %xmm1, %xmm5
 1      3     1.00                         4     c5 53 58 d4                   vaddsd	%xmm4, %xmm5, %xmm10
 1      3     1.00                         5     c4 41 79 2e c9                vucomisd	%xmm9, %xmm9
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_37
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 40          vmovsd	64(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 48          vmovsd	72(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 10             vmovsd	16(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 18             vmovsd	24(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_40
 1      3     1.00                         4     c5 2b 58 d1                   vaddsd	%xmm1, %xmm10, %xmm10
 1      3     1.00                         4     c5 33 58 c8                   vaddsd	%xmm0, %xmm9, %xmm9
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 50          vmovsd	80(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 58          vmovsd	88(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 20             vmovsd	32(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 28             vmovsd	40(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_43
 1      3     1.00                         4     c5 ab 58 c9                   vaddsd	%xmm1, %xmm10, %xmm1
 1      3     1.00                         4     c5 b3 58 c0                   vaddsd	%xmm0, %xmm9, %xmm0
 2      1     1.00           *             9     c5 fb 11 84 24 d8 00 00 00    vmovsd	%xmm0, 216(%rsp)
 2      1     1.00           *             9     c5 fb 11 8c 24 e0 00 00 00    vmovsd	%xmm1, 224(%rsp)
 1      5     0.50    *                    7     c4 c1 7b 10 44 24 60          vmovsd	96(%r12), %xmm0
 1      5     0.50    *                    7     c4 c1 7b 10 4c 24 68          vmovsd	104(%r12), %xmm1
 1      5     0.50    *                    5     c4 c1 7b 10 17                vmovsd	(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 08             vmovsd	8(%r15), %xmm3
 1      3     0.50                         4     c5 fb 59 e2                   vmulsd	%xmm2, %xmm0, %xmm4
 1      3     0.50                         4     c5 f3 59 eb                   vmulsd	%xmm3, %xmm1, %xmm5
 1      3     1.00                         4     c5 5b 5c cd                   vsubsd	%xmm5, %xmm4, %xmm9
 1      3     0.50                         4     c5 fb 59 e3                   vmulsd	%xmm3, %xmm0, %xmm4
 1      3     0.50                         4     c5 f3 59 ea                   vmulsd	%xmm2, %xmm1, %xmm5
 1      3     1.00                         4     c5 53 58 d4                   vaddsd	%xmm4, %xmm5, %xmm10
 1      3     1.00                         5     c4 41 79 2e c9                vucomisd	%xmm9, %xmm9
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_46
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 70          vmovsd	112(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 78          vmovsd	120(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 10             vmovsd	16(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 18             vmovsd	24(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_49
 1      3     1.00                         4     c5 2b 58 d1                   vaddsd	%xmm1, %xmm10, %xmm10
 1      3     1.00                         4     c5 33 58 c8                   vaddsd	%xmm0, %xmm9, %xmm9
 1      5     0.50    *                    10    c4 c1 7b 10 a4 24 80 00 00 00  vmovsd	128(%r12), %xmm4
 1      5     0.50    *                    10    c4 c1 7b 10 ac 24 88 00 00 00  vmovsd	136(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 20             vmovsd	32(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 28             vmovsd	40(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_52
 1      3     1.00                         4     c5 ab 58 c9                   vaddsd	%xmm1, %xmm10, %xmm1
 1      3     1.00                         4     c5 b3 58 c0                   vaddsd	%xmm0, %xmm9, %xmm0
 2      1     1.00           *             9     c5 fb 11 84 24 e8 00 00 00    vmovsd	%xmm0, 232(%rsp)
 2      1     1.00           *             9     c5 fb 11 8c 24 f0 00 00 00    vmovsd	%xmm1, 240(%rsp)
 1      0     0.25                         2     31 db                         xorl	%ebx, %ebx
 1      5     0.50    *                    8     c5 f9 28 15 00 00 00 00       vmovapd	.LCPI0_9(%rip), %xmm2
 1      5     0.50    *                    8     c5 fb 10 1d 00 00 00 00       vmovsd	.LCPI0_10(%rip), %xmm3
 1      5     0.50    *                    5     c5 fb 10 04 19                vmovsd	(%rcx,%rbx), %xmm0
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 1      3     1.00                         4     c5 fb 5c cf                   vsubsd	%xmm7, %xmm0, %xmm1
 1      14    4.00                         4     c5 f3 5e c0                   vdivsd	%xmm0, %xmm1, %xmm0
 1      1     1.00                         4     c5 f9 54 c2                   vandpd	%xmm2, %xmm0, %xmm0
 1      1     0.25                         3     41 b5 01                      movb	$1, %r13b
 1      3     1.00                         4     c5 f9 2e c3                   vucomisd	%xmm3, %xmm0
 1      1     0.25                         2     b0 01                         movb	$1, %al
 1      1     0.50                         6     0f 87 00 00 00 00             ja	.LBB0_57
 1      5     0.50    *                    6     c5 fb 10 44 19 08             vmovsd	8(%rcx,%rbx), %xmm0
 1      3     1.00                         5     c4 c1 7b 5c c8                vsubsd	%xmm8, %xmm0, %xmm1
 1      14    4.00                         4     c5 f3 5e c0                   vdivsd	%xmm0, %xmm1, %xmm0
 1      1     1.00                         4     c5 f9 54 c2                   vandpd	%xmm2, %xmm0, %xmm0
 1      3     1.00                         4     c5 f9 2e c3                   vucomisd	%xmm3, %xmm0
 2      2     0.50                         3     0f 97 c0                      seta	%al
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 1      5     0.50    *                    5     c5 fb 10 04 1a                vmovsd	(%rdx,%rbx), %xmm0
 2      1     1.00           *             9     c5 fb 11 84 24 b0 00 00 00    vmovsd	%xmm0, 176(%rsp)
 1      5     0.50    *                    6     c5 fb 10 44 1a 08             vmovsd	8(%rdx,%rbx), %xmm0
 2      1     1.00           *             9     c5 fb 11 84 24 98 00 00 00    vmovsd	%xmm0, 152(%rsp)
 1      5     0.50    *                    5     48 8b 4c 24 78                movq	120(%rsp), %rcx
 1      5     0.50    *                    5     c5 fb 10 04 19                vmovsd	(%rcx,%rbx), %xmm0
 2      1     1.00           *             6     c5 fb 11 44 24 58             vmovsd	%xmm0, 88(%rsp)
 1      5     0.50    *                    6     c5 fb 10 44 19 08             vmovsd	8(%rcx,%rbx), %xmm0
 2      1     1.00           *             9     c5 fb 11 84 24 a0 00 00 00    vmovsd	%xmm0, 160(%rsp)
 1      5     0.50    *                    8     48 8b 8c 24 90 00 00 00       movq	144(%rsp), %rcx
 1      5     0.50    *                    5     c5 fb 10 04 19                vmovsd	(%rcx,%rbx), %xmm0
 2      1     1.00           *             6     c5 fb 11 44 24 60             vmovsd	%xmm0, 96(%rsp)
 1      5     0.50    *                    6     c5 fb 10 44 19 08             vmovsd	8(%rcx,%rbx), %xmm0
 2      1     1.00           *             9     c5 fb 11 84 24 a8 00 00 00    vmovsd	%xmm0, 168(%rsp)
 1      1     0.25                         3     0f b6 f8                      movzbl	%al, %edi
 1      1     0.25                         5     ba 00 00 00 00                movl	$.L.str, %edx
 1      1     0.25                         5     b9 00 00 00 00                movl	$.L.str.1, %ecx
 1      1     0.25                         5     be 01 00 00 00                movl	$1, %esi
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	error
 1      5     0.50    *                    8     c5 fb 10 15 00 00 00 00       vmovsd	.LCPI0_10(%rip), %xmm2
 1      5     0.50    *                    8     c5 f9 28 0d 00 00 00 00       vmovapd	.LCPI0_9(%rip), %xmm1
 1      5     0.50    *                    9     c5 fb 10 9c 24 b0 00 00 00    vmovsd	176(%rsp), %xmm3
 2      8     1.00    *                    6     c5 e3 5c 44 24 20             vsubsd	32(%rsp), %xmm3, %xmm0
 1      14    4.00                         4     c5 fb 5e c3                   vdivsd	%xmm3, %xmm0, %xmm0
 1      1     1.00                         4     c5 f9 54 c1                   vandpd	%xmm1, %xmm0, %xmm0
 1      3     1.00                         4     c5 f9 2e c2                   vucomisd	%xmm2, %xmm0
 1      1     0.50                         6     0f 87 00 00 00 00             ja	.LBB0_59
 1      5     0.50    *                    9     c5 fb 10 9c 24 98 00 00 00    vmovsd	152(%rsp), %xmm3
 2      8     1.00    *                    6     c5 e3 5c 44 24 50             vsubsd	80(%rsp), %xmm3, %xmm0
 1      14    4.00                         4     c5 fb 5e c3                   vdivsd	%xmm3, %xmm0, %xmm0
 1      1     1.00                         4     c5 f9 54 c1                   vandpd	%xmm1, %xmm0, %xmm0
 1      3     1.00                         4     c5 f9 2e c2                   vucomisd	%xmm2, %xmm0
 2      2     0.50                         4     41 0f 97 c5                   seta	%r13b
 1      1     0.25                         4     41 0f b6 fd                   movzbl	%r13b, %edi
 1      1     0.25                         5     ba 00 00 00 00                movl	$.L.str.2, %edx
 1      1     0.25                         5     b9 00 00 00 00                movl	$.L.str.3, %ecx
 1      1     0.25                         5     be 01 00 00 00                movl	$1, %esi
 4      3     1.00                         5     e8 00 00 00 00                callq	error
 1      5     0.50    *                    8     c5 fb 10 15 00 00 00 00       vmovsd	.LCPI0_10(%rip), %xmm2
 1      5     0.50    *                    8     c5 f9 28 0d 00 00 00 00       vmovapd	.LCPI0_9(%rip), %xmm1
 1      5     0.50    *                    6     c5 fb 10 5c 24 58             vmovsd	88(%rsp), %xmm3
 2      8     1.00    *                    6     c5 e3 5c 44 24 10             vsubsd	16(%rsp), %xmm3, %xmm0
 1      14    4.00                         4     c5 fb 5e c3                   vdivsd	%xmm3, %xmm0, %xmm0
 1      1     1.00                         4     c5 f9 54 c1                   vandpd	%xmm1, %xmm0, %xmm0
 1      1     0.25                         3     41 b5 01                      movb	$1, %r13b
 1      3     1.00                         4     c5 f9 2e c2                   vucomisd	%xmm2, %xmm0
 1      1     0.25                         2     b0 01                         movb	$1, %al
 1      1     0.50                         6     0f 87 00 00 00 00             ja	.LBB0_61
 1      5     0.50    *                    9     c5 fb 10 9c 24 a0 00 00 00    vmovsd	160(%rsp), %xmm3
 2      8     1.00    *                    6     c5 e3 5c 44 24 18             vsubsd	24(%rsp), %xmm3, %xmm0
 1      14    4.00                         4     c5 fb 5e c3                   vdivsd	%xmm3, %xmm0, %xmm0
 1      1     1.00                         4     c5 f9 54 c1                   vandpd	%xmm1, %xmm0, %xmm0
 1      3     1.00                         4     c5 f9 2e c2                   vucomisd	%xmm2, %xmm0
 2      2     0.50                         3     0f 97 c0                      seta	%al
 1      1     0.25                         3     0f b6 f8                      movzbl	%al, %edi
 1      1     0.25                         5     ba 00 00 00 00                movl	$.L.str.4, %edx
 1      1     0.25                         5     b9 00 00 00 00                movl	$.L.str.1, %ecx
 1      1     0.25                         5     be 01 00 00 00                movl	$1, %esi
 4      3     1.00                         5     e8 00 00 00 00                callq	error
 1      5     0.50    *                    8     c5 fb 10 15 00 00 00 00       vmovsd	.LCPI0_10(%rip), %xmm2
 1      5     0.50    *                    8     c5 f9 28 0d 00 00 00 00       vmovapd	.LCPI0_9(%rip), %xmm1
 1      5     0.50    *                    6     c5 fb 10 5c 24 60             vmovsd	96(%rsp), %xmm3
 2      8     1.00    *                    6     c5 e3 5c 44 24 20             vsubsd	32(%rsp), %xmm3, %xmm0
 1      14    4.00                         4     c5 fb 5e c3                   vdivsd	%xmm3, %xmm0, %xmm0
 1      1     1.00                         4     c5 f9 54 c1                   vandpd	%xmm1, %xmm0, %xmm0
 1      3     1.00                         4     c5 f9 2e c2                   vucomisd	%xmm2, %xmm0
 1      1     0.50                         6     0f 87 00 00 00 00             ja	.LBB0_63
 1      5     0.50    *                    9     c5 fb 10 9c 24 a8 00 00 00    vmovsd	168(%rsp), %xmm3
 2      8     1.00    *                    6     c5 e3 5c 44 24 50             vsubsd	80(%rsp), %xmm3, %xmm0
 1      14    4.00                         4     c5 fb 5e c3                   vdivsd	%xmm3, %xmm0, %xmm0
 1      1     1.00                         4     c5 f9 54 c1                   vandpd	%xmm1, %xmm0, %xmm0
 1      3     1.00                         4     c5 f9 2e c2                   vucomisd	%xmm2, %xmm0
 2      2     0.50                         4     41 0f 97 c5                   seta	%r13b
 1      1     0.25                         4     41 0f b6 fd                   movzbl	%r13b, %edi
 1      1     0.25                         5     ba 00 00 00 00                movl	$.L.str.5, %edx
 1      1     0.25                         5     b9 00 00 00 00                movl	$.L.str.3, %ecx
 1      1     0.25                         5     be 01 00 00 00                movl	$1, %esi
 4      3     1.00                         5     e8 00 00 00 00                callq	error
 1      1     0.25                         4     48 83 fb 20                   cmpq	$32, %rbx
 1      1     0.50                         6     0f 84 00 00 00 00             je	.LBB0_65
 1      5     0.50    *                    9     c5 fb 10 bc 1c 08 01 00 00    vmovsd	264(%rsp,%rbx), %xmm7
 1      5     0.50    *                    9     c5 7b 10 84 1c 10 01 00 00    vmovsd	272(%rsp,%rbx), %xmm8
 1      5     0.50    *                    9     c5 fb 10 84 1c d8 00 00 00    vmovsd	216(%rsp,%rbx), %xmm0
 2      1     1.00           *             6     c5 fb 11 44 24 20             vmovsd	%xmm0, 32(%rsp)
 1      5     0.50    *                    9     c5 fb 10 84 1c e0 00 00 00    vmovsd	224(%rsp,%rbx), %xmm0
 2      1     1.00           *             6     c5 fb 11 44 24 50             vmovsd	%xmm0, 80(%rsp)
 1      1     0.25                         4     48 83 c3 10                   addq	$16, %rbx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_55
 1      1     0.25                         5     b8 e8 03 00 00                movl	$1000, %eax
 1      6     0.50    *                    9     c4 62 7d 19 35 00 00 00 00    vbroadcastsd	.LCPI0_11(%rip), %ymm14
 1      5     0.50    *                    8     c5 79 28 3d 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm15
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      6     0.50    *                    6     c4 c1 7d 10 04 24             vmovupd	(%r12), %ymm0
 1      6     0.50    *                    7     c4 41 7d 10 44 24 10          vmovupd	16(%r12), %ymm8
 1      6     0.50    *                    7     c4 c1 7d 10 4c 24 30          vmovupd	48(%r12), %ymm1
 1      1     1.00                         4     c5 ff 12 d0                   vmovddup	%ymm0, %ymm2
 1      1     1.00                         6     c4 e3 7d 05 e8 0f             vpermilpd	$15, %ymm0, %ymm5
 1      1     1.00                         4     c5 ff 12 d9                   vmovddup	%ymm1, %ymm3
 1      6     0.50    *                    5     c4 c1 7d 10 26                vmovupd	(%r14), %ymm4
 1      6     0.50    *                    6     c4 c1 7d 10 46 10             vmovupd	16(%r14), %ymm0
 1      6     0.50    *                    5     c4 c1 7d 10 37                vmovupd	(%r15), %ymm6
 1      1     1.00                         6     c4 e3 7d 05 f9 0f             vpermilpd	$15, %ymm1, %ymm7
 1      6     0.50    *                    6     c4 c1 7d 10 4f 10             vmovupd	16(%r15), %ymm1
 2      9     1.00    *                    8     c4 43 3d 06 44 24 40 31       vperm2f128	$49, 64(%r12), %ymm8, %ymm8
 1      1     1.00                         6     c4 63 7d 05 cc 05             vpermilpd	$5, %ymm4, %ymm9
 1      3     0.50                         4     c5 35 59 d5                   vmulpd	%ymm5, %ymm9, %ymm10
 1      3     1.00                         6     c4 63 fd 01 d8 ee             vpermpd	$238, %ymm0, %ymm11
 1      1     1.00                         5     c4 41 7f 12 e0                vmovddup	%ymm8, %ymm12
 1      5     0.50                         5     c4 62 ed b6 d4                vfmaddsub231pd	%ymm4, %ymm2, %ymm10
 1      1     1.00                         6     c4 43 7d 05 c0 0f             vpermilpd	$15, %ymm8, %ymm8
 1      3     1.00                         6     c4 63 fd 01 e8 bb             vpermpd	$187, %ymm0, %ymm13
 1      3     0.50                         5     c4 41 3d 59 ed                vmulpd	%ymm13, %ymm8, %ymm13
 1      5     0.50                         5     c4 42 9d b6 eb                vfmaddsub231pd	%ymm11, %ymm12, %ymm13
 1      3     1.00                         6     c4 63 fd 01 d9 bb             vpermpd	$187, %ymm1, %ymm11
 1      3     0.50                         5     c4 41 3d 59 c3                vmulpd	%ymm11, %ymm8, %ymm8
 1      3     1.00                         6     c4 63 fd 01 d9 ee             vpermpd	$238, %ymm1, %ymm11
 1      5     0.50                         5     c4 42 9d b6 c3                vfmaddsub231pd	%ymm11, %ymm12, %ymm8
 1      3     0.50                         4     c5 35 59 df                   vmulpd	%ymm7, %ymm9, %ymm11
 1      5     0.50                         5     c4 62 e5 b6 dc                vfmaddsub231pd	%ymm4, %ymm3, %ymm11
 1      3     1.00                         6     c4 43 2d 18 e3 01             vinsertf128	$1, %xmm11, %ymm10, %ymm12
 1      3     1.00                         6     c4 43 2d 06 d3 31             vperm2f128	$49, %ymm11, %ymm10, %ymm10
 1      1     1.00                         6     c4 63 7d 05 de 05             vpermilpd	$5, %ymm6, %ymm11
 1      3     0.50                         4     c5 a5 59 ed                   vmulpd	%ymm5, %ymm11, %ymm5
 1      5     0.50                         5     c4 e2 cd b6 ea                vfmaddsub231pd	%ymm2, %ymm6, %ymm5
 1      3     1.00                         5     c4 c1 1d 58 d2                vaddpd	%ymm10, %ymm12, %ymm2
 1      6     0.50    *                    7     c4 41 7d 10 54 24 60          vmovupd	96(%r12), %ymm10
 1      3     0.50                         4     c5 a5 59 ff                   vmulpd	%ymm7, %ymm11, %ymm7
 1      5     0.50                         5     c4 e2 cd b6 fb                vfmaddsub231pd	%ymm3, %ymm6, %ymm7
 1      3     1.00                         6     c4 e3 55 18 df 01             vinsertf128	$1, %xmm7, %ymm5, %ymm3
 1      3     1.00                         6     c4 e3 55 06 ef 31             vperm2f128	$49, %ymm7, %ymm5, %ymm5
 1      1     1.00                         5     c4 c1 7f 12 fa                vmovddup	%ymm10, %ymm7
 1      1     1.00                         6     c4 43 7d 05 d2 0f             vpermilpd	$15, %ymm10, %ymm10
 1      3     0.50                         5     c4 41 2d 59 c9                vmulpd	%ymm9, %ymm10, %ymm9
 1      5     0.50                         5     c4 62 c5 b6 cc                vfmaddsub231pd	%ymm4, %ymm7, %ymm9
 1      3     0.50                         5     c4 c1 2d 59 e3                vmulpd	%ymm11, %ymm10, %ymm4
 1      5     0.50                         5     c4 e2 c5 b6 e6                vfmaddsub231pd	%ymm6, %ymm7, %ymm4
 1      3     1.00                         4     c5 e5 58 dd                   vaddpd	%ymm5, %ymm3, %ymm3
 1      3     1.00                         6     c4 e3 35 18 ec 01             vinsertf128	$1, %xmm4, %ymm9, %ymm5
 1      3     1.00                         6     c4 e3 35 06 e4 31             vperm2f128	$49, %ymm4, %ymm9, %ymm4
 1      3     1.00                         4     c5 d5 58 e4                   vaddpd	%ymm4, %ymm5, %ymm4
 1      3     1.00                         4     c5 95 58 d2                   vaddpd	%ymm2, %ymm13, %ymm2
 1      6     0.50    *                    10    c4 c2 7d 19 ac 24 80 00 00 00  vbroadcastsd	128(%r12), %ymm5
 1      6     0.50    *                    10    c4 c2 7d 19 b4 24 88 00 00 00  vbroadcastsd	136(%r12), %ymm6
 1      3     1.00                         6     c4 e3 7d 06 c9 31             vperm2f128	$49, %ymm1, %ymm0, %ymm1
 1      3     1.00                         4     c5 bd 58 c3                   vaddpd	%ymm3, %ymm8, %ymm0
 1      1     1.00                         6     c4 e3 7d 05 d9 05             vpermilpd	$5, %ymm1, %ymm3
 1      3     0.50                         4     c5 e5 59 de                   vmulpd	%ymm6, %ymm3, %ymm3
 1      5     0.50                         5     c4 e2 f5 b6 dd                vfmaddsub231pd	%ymm5, %ymm1, %ymm3
 1      3     1.00                         4     c5 dd 58 cb                   vaddpd	%ymm3, %ymm4, %ymm1
 2      1     1.00           *             4     c5 fd 11 11                   vmovupd	%ymm2, (%rcx)
 2      1     1.00           *             5     c5 f9 11 49 20                vmovupd	%xmm1, 32(%rcx)
 2      1     1.00           *             4     c5 fd 11 02                   vmovupd	%ymm0, (%rdx)
 2      1     1.00           *             7     c4 e3 7d 19 4a 20 01          vextractf128	$1, %ymm1, 32(%rdx)
 1      6     0.50    *                    6     c4 c1 7d 10 0c 24             vmovupd	(%r12), %ymm1
 1      6     0.50    *                    7     c4 c1 7d 10 7c 24 10          vmovupd	16(%r12), %ymm7
 1      6     0.50    *                    7     c4 c1 7d 10 54 24 30          vmovupd	48(%r12), %ymm2
 1      6     0.50    *                    7     c4 c1 7d 10 5c 24 60          vmovupd	96(%r12), %ymm3
 1      1     1.00                         4     c5 7f 12 c9                   vmovddup	%ymm1, %ymm9
 1      1     1.00                         6     c4 63 7d 05 c1 0f             vpermilpd	$15, %ymm1, %ymm8
 1      1     1.00                         4     c5 7f 12 d2                   vmovddup	%ymm2, %ymm10
 1      1     1.00                         6     c4 63 7d 05 da 0f             vpermilpd	$15, %ymm2, %ymm11
 1      1     1.00                         4     c5 ff 12 d3                   vmovddup	%ymm3, %ymm2
 1      6     0.50    *                    4     c5 fd 10 21                   vmovupd	(%rcx), %ymm4
 1      1     1.00                         6     c4 e3 7d 05 db 0f             vpermilpd	$15, %ymm3, %ymm3
 1      1     1.00                         6     c4 e3 7d 05 f4 05             vpermilpd	$5, %ymm4, %ymm6
 1      1     1.00                         6     c4 e3 7d 05 e8 05             vpermilpd	$5, %ymm0, %ymm5
 1      3     0.50                         4     c5 bd 59 ce                   vmulpd	%ymm6, %ymm8, %ymm1
 1      5     0.50                         5     c4 e2 b5 b6 cc                vfmaddsub231pd	%ymm4, %ymm9, %ymm1
 1      3     0.50                         4     c5 3d 59 c5                   vmulpd	%ymm5, %ymm8, %ymm8
 1      5     0.50                         5     c4 42 fd b6 c1                vfmaddsub231pd	%ymm9, %ymm0, %ymm8
 1      3     0.50                         4     c5 25 59 ce                   vmulpd	%ymm6, %ymm11, %ymm9
 1      5     0.50                         5     c4 62 ad b6 cc                vfmaddsub231pd	%ymm4, %ymm10, %ymm9
 2      9     1.00    *                    8     c4 c3 45 06 7c 24 40 31       vperm2f128	$49, 64(%r12), %ymm7, %ymm7
 1      3     0.50                         4     c5 25 59 dd                   vmulpd	%ymm5, %ymm11, %ymm11
 1      5     0.50                         5     c4 42 fd b6 da                vfmaddsub231pd	%ymm10, %ymm0, %ymm11
 1      6     0.50    *                    5     c5 7d 10 51 10                vmovupd	16(%rcx), %ymm10
 1      3     0.50                         4     c5 e5 59 f6                   vmulpd	%ymm6, %ymm3, %ymm6
 1      5     0.50                         5     c4 e2 ed b6 f4                vfmaddsub231pd	%ymm4, %ymm2, %ymm6
 1      3     1.00                         6     c4 c3 fd 01 e2 ee             vpermpd	$238, %ymm10, %ymm4
 1      3     0.50                         4     c5 d5 59 db                   vmulpd	%ymm3, %ymm5, %ymm3
 1      1     1.00                         4     c5 ff 12 ef                   vmovddup	%ymm7, %ymm5
 1      1     1.00                         6     c4 e3 7d 05 ff 0f             vpermilpd	$15, %ymm7, %ymm7
 1      5     0.50                         5     c4 e2 ed b6 d8                vfmaddsub231pd	%ymm0, %ymm2, %ymm3
 1      3     1.00                         6     c4 c3 fd 01 c2 bb             vpermpd	$187, %ymm10, %ymm0
 1      3     0.50                         4     c5 c5 59 c0                   vmulpd	%ymm0, %ymm7, %ymm0
 1      6     0.50    *                    5     c5 fd 10 52 10                vmovupd	16(%rdx), %ymm2
 1      5     0.50                         5     c4 e2 d5 b6 c4                vfmaddsub231pd	%ymm4, %ymm5, %ymm0
 1      3     1.00                         6     c4 e3 fd 01 e2 bb             vpermpd	$187, %ymm2, %ymm4
 1      3     0.50                         4     c5 c5 59 e4                   vmulpd	%ymm4, %ymm7, %ymm4
 1      3     1.00                         6     c4 e3 fd 01 fa ee             vpermpd	$238, %ymm2, %ymm7
 1      5     0.50                         5     c4 e2 d5 b6 e7                vfmaddsub231pd	%ymm7, %ymm5, %ymm4
 1      6     0.50    *                    10    c4 c2 7d 19 ac 24 88 00 00 00  vbroadcastsd	136(%r12), %ymm5
 1      3     1.00                         6     c4 e3 2d 06 d2 31             vperm2f128	$49, %ymm2, %ymm10, %ymm2
 1      1     1.00                         6     c4 e3 7d 05 fa 05             vpermilpd	$5, %ymm2, %ymm7
 1      3     0.50                         4     c5 c5 59 ed                   vmulpd	%ymm5, %ymm7, %ymm5
 1      6     0.50    *                    10    c4 c2 7d 19 bc 24 80 00 00 00  vbroadcastsd	128(%r12), %ymm7
 1      5     0.50                         5     c4 e2 ed b6 ef                vfmaddsub231pd	%ymm7, %ymm2, %ymm5
 1      3     1.00                         6     c4 c3 75 18 d1 01             vinsertf128	$1, %xmm9, %ymm1, %ymm2
 1      3     1.00                         6     c4 c3 75 06 c9 31             vperm2f128	$49, %ymm9, %ymm1, %ymm1
 1      3     1.00                         4     c5 ed 58 c9                   vaddpd	%ymm1, %ymm2, %ymm1
 1      3     1.00                         6     c4 c3 3d 18 d3 01             vinsertf128	$1, %xmm11, %ymm8, %ymm2
 1      3     1.00                         6     c4 c3 3d 06 fb 31             vperm2f128	$49, %ymm11, %ymm8, %ymm7
 1      3     1.00                         4     c5 f5 58 c0                   vaddpd	%ymm0, %ymm1, %ymm0
 1      3     1.00                         4     c5 ed 58 cf                   vaddpd	%ymm7, %ymm2, %ymm1
 1      3     1.00                         6     c4 e3 4d 18 d3 01             vinsertf128	$1, %xmm3, %ymm6, %ymm2
 1      3     1.00                         6     c4 e3 4d 06 db 31             vperm2f128	$49, %ymm3, %ymm6, %ymm3
 1      3     1.00                         4     c5 f5 58 cc                   vaddpd	%ymm4, %ymm1, %ymm1
 1      3     1.00                         4     c5 ed 58 d3                   vaddpd	%ymm3, %ymm2, %ymm2
 1      3     1.00                         4     c5 ed 58 d5                   vaddpd	%ymm5, %ymm2, %ymm2
 2      1     1.00           *             5     c4 c1 7d 11 06                vmovupd	%ymm0, (%r14)
 2      1     1.00           *             6     c4 c1 79 11 56 20             vmovupd	%xmm2, 32(%r14)
 2      1     1.00           *             5     c4 c1 7d 11 0f                vmovupd	%ymm1, (%r15)
 2      1     1.00           *             7     c4 c3 7d 19 57 20 01          vextractf128	$1, %ymm2, 32(%r15)
 2      9     0.50    *                    5     c4 c1 0d 59 06                vmulpd	(%r14), %ymm14, %ymm0
 2      1     1.00           *             5     c4 c1 7d 11 06                vmovupd	%ymm0, (%r14)
 2      8     0.50    *                    6     c4 c1 01 59 46 20             vmulpd	32(%r14), %xmm15, %xmm0
 2      1     1.00           *             6     c4 c1 79 11 46 20             vmovupd	%xmm0, 32(%r14)
 2      9     0.50    *                    5     c4 c1 0d 59 07                vmulpd	(%r15), %ymm14, %ymm0
 2      1     1.00           *             5     c4 c1 7d 11 07                vmovupd	%ymm0, (%r15)
 2      8     0.50    *                    6     c4 c1 01 59 47 20             vmulpd	32(%r15), %xmm15, %xmm0
 2      1     1.00           *             6     c4 c1 79 11 47 20             vmovupd	%xmm0, 32(%r15)
 1      1     0.25                         2     ff c8                         decl	%eax
 1      1     0.50                         6     0f 85 00 00 00 00             jne	.LBB0_66
 1      1     0.50                         8     48 8d bc 24 80 00 00 00       leaq	128(%rsp), %rdi
 1      0     0.25                         2     31 f6                         xorl	%esi, %esi
 2      1     1.00           *             6     c5 7d 29 74 24 20             vmovapd	%ymm14, 32(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	gettimeofday
 1      1     0.25                         6     41 bd 00 e1 f5 05             movl	$100000000, %r13d
 4      3     1.00                         5     e8 00 00 00 00                callq	clock
 1      5     0.50    *                    8     c5 79 28 3d 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm15
 1      6     0.50    *                    6     c5 7d 28 74 24 20             vmovapd	32(%rsp), %ymm14
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     1.00           *             5     48 89 44 24 10                movq	%rax, 16(%rsp)
 1      6     0.50    *                    6     c4 c1 7d 10 04 24             vmovupd	(%r12), %ymm0
 1      6     0.50    *                    7     c4 41 7d 10 44 24 10          vmovupd	16(%r12), %ymm8
 1      6     0.50    *                    7     c4 c1 7d 10 4c 24 30          vmovupd	48(%r12), %ymm1
 1      1     1.00                         4     c5 ff 12 d0                   vmovddup	%ymm0, %ymm2
 1      1     1.00                         6     c4 e3 7d 05 e8 0f             vpermilpd	$15, %ymm0, %ymm5
 1      1     1.00                         4     c5 ff 12 d9                   vmovddup	%ymm1, %ymm3
 1      6     0.50    *                    5     c4 c1 7d 10 26                vmovupd	(%r14), %ymm4
 1      6     0.50    *                    6     c4 c1 7d 10 46 10             vmovupd	16(%r14), %ymm0
 1      6     0.50    *                    5     c4 c1 7d 10 37                vmovupd	(%r15), %ymm6
 1      1     1.00                         6     c4 e3 7d 05 f9 0f             vpermilpd	$15, %ymm1, %ymm7
 1      6     0.50    *                    6     c4 c1 7d 10 4f 10             vmovupd	16(%r15), %ymm1
 2      9     1.00    *                    8     c4 43 3d 06 44 24 40 31       vperm2f128	$49, 64(%r12), %ymm8, %ymm8
 1      1     1.00                         6     c4 63 7d 05 cc 05             vpermilpd	$5, %ymm4, %ymm9
 1      3     0.50                         4     c5 35 59 d5                   vmulpd	%ymm5, %ymm9, %ymm10
 1      3     1.00                         6     c4 63 fd 01 d8 ee             vpermpd	$238, %ymm0, %ymm11
 1      1     1.00                         5     c4 41 7f 12 e0                vmovddup	%ymm8, %ymm12
 1      5     0.50                         5     c4 62 ed b6 d4                vfmaddsub231pd	%ymm4, %ymm2, %ymm10
 1      1     1.00                         6     c4 43 7d 05 c0 0f             vpermilpd	$15, %ymm8, %ymm8
 1      3     1.00                         6     c4 63 fd 01 e8 bb             vpermpd	$187, %ymm0, %ymm13
 1      3     0.50                         5     c4 41 3d 59 ed                vmulpd	%ymm13, %ymm8, %ymm13
 1      5     0.50                         5     c4 42 9d b6 eb                vfmaddsub231pd	%ymm11, %ymm12, %ymm13
 1      3     1.00                         6     c4 63 fd 01 d9 bb             vpermpd	$187, %ymm1, %ymm11
 1      3     0.50                         5     c4 41 3d 59 c3                vmulpd	%ymm11, %ymm8, %ymm8
 1      3     1.00                         6     c4 63 fd 01 d9 ee             vpermpd	$238, %ymm1, %ymm11
 1      5     0.50                         5     c4 42 9d b6 c3                vfmaddsub231pd	%ymm11, %ymm12, %ymm8
 1      3     0.50                         4     c5 35 59 df                   vmulpd	%ymm7, %ymm9, %ymm11
 1      5     0.50                         5     c4 62 e5 b6 dc                vfmaddsub231pd	%ymm4, %ymm3, %ymm11
 1      3     1.00                         6     c4 43 2d 18 e3 01             vinsertf128	$1, %xmm11, %ymm10, %ymm12
 1      3     1.00                         6     c4 43 2d 06 d3 31             vperm2f128	$49, %ymm11, %ymm10, %ymm10
 1      1     1.00                         6     c4 63 7d 05 de 05             vpermilpd	$5, %ymm6, %ymm11
 1      3     0.50                         4     c5 a5 59 ed                   vmulpd	%ymm5, %ymm11, %ymm5
 1      5     0.50                         5     c4 e2 cd b6 ea                vfmaddsub231pd	%ymm2, %ymm6, %ymm5
 1      3     1.00                         5     c4 c1 1d 58 d2                vaddpd	%ymm10, %ymm12, %ymm2
 1      6     0.50    *                    7     c4 41 7d 10 54 24 60          vmovupd	96(%r12), %ymm10
 1      3     0.50                         4     c5 a5 59 ff                   vmulpd	%ymm7, %ymm11, %ymm7
 1      5     0.50                         5     c4 e2 cd b6 fb                vfmaddsub231pd	%ymm3, %ymm6, %ymm7
 1      3     1.00                         6     c4 e3 55 18 df 01             vinsertf128	$1, %xmm7, %ymm5, %ymm3
 1      3     1.00                         6     c4 e3 55 06 ef 31             vperm2f128	$49, %ymm7, %ymm5, %ymm5
 1      1     1.00                         5     c4 c1 7f 12 fa                vmovddup	%ymm10, %ymm7
 1      1     1.00                         6     c4 43 7d 05 d2 0f             vpermilpd	$15, %ymm10, %ymm10
 1      3     0.50                         5     c4 41 2d 59 c9                vmulpd	%ymm9, %ymm10, %ymm9
 1      5     0.50                         5     c4 62 c5 b6 cc                vfmaddsub231pd	%ymm4, %ymm7, %ymm9
 1      3     0.50                         5     c4 c1 2d 59 e3                vmulpd	%ymm11, %ymm10, %ymm4
 1      5     0.50                         5     c4 e2 c5 b6 e6                vfmaddsub231pd	%ymm6, %ymm7, %ymm4
 1      3     1.00                         4     c5 e5 58 dd                   vaddpd	%ymm5, %ymm3, %ymm3
 1      3     1.00                         6     c4 e3 35 18 ec 01             vinsertf128	$1, %xmm4, %ymm9, %ymm5
 1      3     1.00                         6     c4 e3 35 06 e4 31             vperm2f128	$49, %ymm4, %ymm9, %ymm4
 1      3     1.00                         4     c5 d5 58 e4                   vaddpd	%ymm4, %ymm5, %ymm4
 1      3     1.00                         4     c5 95 58 d2                   vaddpd	%ymm2, %ymm13, %ymm2
 1      6     0.50    *                    10    c4 c2 7d 19 ac 24 80 00 00 00  vbroadcastsd	128(%r12), %ymm5
 1      6     0.50    *                    10    c4 c2 7d 19 b4 24 88 00 00 00  vbroadcastsd	136(%r12), %ymm6
 1      3     1.00                         6     c4 e3 7d 06 c9 31             vperm2f128	$49, %ymm1, %ymm0, %ymm1
 1      3     1.00                         4     c5 bd 58 c3                   vaddpd	%ymm3, %ymm8, %ymm0
 1      1     1.00                         6     c4 e3 7d 05 d9 05             vpermilpd	$5, %ymm1, %ymm3
 1      3     0.50                         4     c5 e5 59 de                   vmulpd	%ymm6, %ymm3, %ymm3
 1      5     0.50                         5     c4 e2 f5 b6 dd                vfmaddsub231pd	%ymm5, %ymm1, %ymm3
 1      3     1.00                         4     c5 dd 58 cb                   vaddpd	%ymm3, %ymm4, %ymm1
 2      1     1.00           *             4     c5 fd 11 11                   vmovupd	%ymm2, (%rcx)
 2      1     1.00           *             5     c5 f9 11 49 20                vmovupd	%xmm1, 32(%rcx)
 2      1     1.00           *             4     c5 fd 11 02                   vmovupd	%ymm0, (%rdx)
 2      1     1.00           *             7     c4 e3 7d 19 4a 20 01          vextractf128	$1, %ymm1, 32(%rdx)
 1      6     0.50    *                    6     c4 c1 7d 10 0c 24             vmovupd	(%r12), %ymm1
 1      6     0.50    *                    7     c4 c1 7d 10 7c 24 10          vmovupd	16(%r12), %ymm7
 1      6     0.50    *                    7     c4 c1 7d 10 54 24 30          vmovupd	48(%r12), %ymm2
 1      6     0.50    *                    7     c4 c1 7d 10 5c 24 60          vmovupd	96(%r12), %ymm3
 1      1     1.00                         4     c5 7f 12 c9                   vmovddup	%ymm1, %ymm9
 1      1     1.00                         6     c4 63 7d 05 c1 0f             vpermilpd	$15, %ymm1, %ymm8
 1      1     1.00                         4     c5 7f 12 d2                   vmovddup	%ymm2, %ymm10
 1      1     1.00                         6     c4 63 7d 05 da 0f             vpermilpd	$15, %ymm2, %ymm11
 1      1     1.00                         4     c5 ff 12 d3                   vmovddup	%ymm3, %ymm2
 1      6     0.50    *                    4     c5 fd 10 21                   vmovupd	(%rcx), %ymm4
 1      1     1.00                         6     c4 e3 7d 05 db 0f             vpermilpd	$15, %ymm3, %ymm3
 1      1     1.00                         6     c4 e3 7d 05 f4 05             vpermilpd	$5, %ymm4, %ymm6
 1      1     1.00                         6     c4 e3 7d 05 e8 05             vpermilpd	$5, %ymm0, %ymm5
 1      3     0.50                         4     c5 bd 59 ce                   vmulpd	%ymm6, %ymm8, %ymm1
 1      5     0.50                         5     c4 e2 b5 b6 cc                vfmaddsub231pd	%ymm4, %ymm9, %ymm1
 1      3     0.50                         4     c5 3d 59 c5                   vmulpd	%ymm5, %ymm8, %ymm8
 1      5     0.50                         5     c4 42 fd b6 c1                vfmaddsub231pd	%ymm9, %ymm0, %ymm8
 1      3     0.50                         4     c5 25 59 ce                   vmulpd	%ymm6, %ymm11, %ymm9
 1      5     0.50                         5     c4 62 ad b6 cc                vfmaddsub231pd	%ymm4, %ymm10, %ymm9
 2      9     1.00    *                    8     c4 c3 45 06 7c 24 40 31       vperm2f128	$49, 64(%r12), %ymm7, %ymm7
 1      3     0.50                         4     c5 25 59 dd                   vmulpd	%ymm5, %ymm11, %ymm11
 1      5     0.50                         5     c4 42 fd b6 da                vfmaddsub231pd	%ymm10, %ymm0, %ymm11
 1      6     0.50    *                    5     c5 7d 10 51 10                vmovupd	16(%rcx), %ymm10
 1      3     0.50                         4     c5 e5 59 f6                   vmulpd	%ymm6, %ymm3, %ymm6
 1      5     0.50                         5     c4 e2 ed b6 f4                vfmaddsub231pd	%ymm4, %ymm2, %ymm6
 1      3     1.00                         6     c4 c3 fd 01 e2 ee             vpermpd	$238, %ymm10, %ymm4
 1      3     0.50                         4     c5 d5 59 db                   vmulpd	%ymm3, %ymm5, %ymm3
 1      1     1.00                         4     c5 ff 12 ef                   vmovddup	%ymm7, %ymm5
 1      1     1.00                         6     c4 e3 7d 05 ff 0f             vpermilpd	$15, %ymm7, %ymm7
 1      5     0.50                         5     c4 e2 ed b6 d8                vfmaddsub231pd	%ymm0, %ymm2, %ymm3
 1      3     1.00                         6     c4 c3 fd 01 c2 bb             vpermpd	$187, %ymm10, %ymm0
 1      3     0.50                         4     c5 c5 59 c0                   vmulpd	%ymm0, %ymm7, %ymm0
 1      6     0.50    *                    5     c5 fd 10 52 10                vmovupd	16(%rdx), %ymm2
 1      5     0.50                         5     c4 e2 d5 b6 c4                vfmaddsub231pd	%ymm4, %ymm5, %ymm0
 1      3     1.00                         6     c4 e3 fd 01 e2 bb             vpermpd	$187, %ymm2, %ymm4
 1      3     0.50                         4     c5 c5 59 e4                   vmulpd	%ymm4, %ymm7, %ymm4
 1      3     1.00                         6     c4 e3 fd 01 fa ee             vpermpd	$238, %ymm2, %ymm7
 1      5     0.50                         5     c4 e2 d5 b6 e7                vfmaddsub231pd	%ymm7, %ymm5, %ymm4
 1      6     0.50    *                    10    c4 c2 7d 19 ac 24 88 00 00 00  vbroadcastsd	136(%r12), %ymm5
 1      3     1.00                         6     c4 e3 2d 06 d2 31             vperm2f128	$49, %ymm2, %ymm10, %ymm2
 1      1     1.00                         6     c4 e3 7d 05 fa 05             vpermilpd	$5, %ymm2, %ymm7
 1      3     0.50                         4     c5 c5 59 ed                   vmulpd	%ymm5, %ymm7, %ymm5
 1      6     0.50    *                    10    c4 c2 7d 19 bc 24 80 00 00 00  vbroadcastsd	128(%r12), %ymm7
 1      5     0.50                         5     c4 e2 ed b6 ef                vfmaddsub231pd	%ymm7, %ymm2, %ymm5
 1      3     1.00                         6     c4 c3 75 18 d1 01             vinsertf128	$1, %xmm9, %ymm1, %ymm2
 1      3     1.00                         6     c4 c3 75 06 c9 31             vperm2f128	$49, %ymm9, %ymm1, %ymm1
 1      3     1.00                         4     c5 ed 58 c9                   vaddpd	%ymm1, %ymm2, %ymm1
 1      3     1.00                         6     c4 c3 3d 18 d3 01             vinsertf128	$1, %xmm11, %ymm8, %ymm2
 1      3     1.00                         6     c4 c3 3d 06 fb 31             vperm2f128	$49, %ymm11, %ymm8, %ymm7
 1      3     1.00                         4     c5 f5 58 c0                   vaddpd	%ymm0, %ymm1, %ymm0
 1      3     1.00                         4     c5 ed 58 cf                   vaddpd	%ymm7, %ymm2, %ymm1
 1      3     1.00                         6     c4 e3 4d 18 d3 01             vinsertf128	$1, %xmm3, %ymm6, %ymm2
 1      3     1.00                         6     c4 e3 4d 06 db 31             vperm2f128	$49, %ymm3, %ymm6, %ymm3
 1      3     1.00                         4     c5 f5 58 cc                   vaddpd	%ymm4, %ymm1, %ymm1
 1      3     1.00                         4     c5 ed 58 d3                   vaddpd	%ymm3, %ymm2, %ymm2
 1      3     1.00                         4     c5 ed 58 d5                   vaddpd	%ymm5, %ymm2, %ymm2
 2      1     1.00           *             5     c4 c1 7d 11 06                vmovupd	%ymm0, (%r14)
 2      1     1.00           *             6     c4 c1 79 11 56 20             vmovupd	%xmm2, 32(%r14)
 2      1     1.00           *             5     c4 c1 7d 11 0f                vmovupd	%ymm1, (%r15)
 2      1     1.00           *             7     c4 c3 7d 19 57 20 01          vextractf128	$1, %ymm2, 32(%r15)
 2      9     0.50    *                    5     c4 c1 0d 59 06                vmulpd	(%r14), %ymm14, %ymm0
 2      1     1.00           *             5     c4 c1 7d 11 06                vmovupd	%ymm0, (%r14)
 2      8     0.50    *                    6     c4 c1 01 59 46 20             vmulpd	32(%r14), %xmm15, %xmm0
 2      1     1.00           *             6     c4 c1 79 11 46 20             vmovupd	%xmm0, 32(%r14)
 2      9     0.50    *                    5     c4 c1 0d 59 07                vmulpd	(%r15), %ymm14, %ymm0
 2      1     1.00           *             5     c4 c1 7d 11 07                vmovupd	%ymm0, (%r15)
 2      8     0.50    *                    6     c4 c1 01 59 47 20             vmulpd	32(%r15), %xmm15, %xmm0
 2      1     1.00           *             6     c4 c1 79 11 47 20             vmovupd	%xmm0, 32(%r15)
 1      1     0.25                         3     41 ff cd                      decl	%r13d
 1      1     0.50                         6     0f 85 00 00 00 00             jne	.LBB0_68
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	clock
 1      1     0.25                         3     48 89 c3                      movq	%rax, %rbx
 1      1     0.50                         8     4c 8d ac 24 b8 00 00 00       leaq	184(%rsp), %r13
 1      1     0.25                         3     4c 89 ef                      movq	%r13, %rdi
 1      0     0.25                         2     31 f6                         xorl	%esi, %esi
 4      3     1.00                         5     e8 00 00 00 00                callq	gettimeofday
 1      1     0.50                         5     48 8d 7c 24 68                leaq	104(%rsp), %rdi
 1      1     0.50                         8     48 8d 94 24 80 00 00 00       leaq	128(%rsp), %rdx
 1      1     0.25                         3     4c 89 ee                      movq	%r13, %rsi
 4      3     1.00                         5     e8 00 00 00 00                callq	timeval_subtract
 2      6     0.50    *                    5     48 2b 5c 24 10                subq	16(%rsp), %rbx
 2      4     1.00                         5     c4 e1 8b 2a c3                vcvtsi2sd	%rbx, %xmm14, %xmm0
 2      19    8.00    *                    8     c5 fb 5e 05 00 00 00 00       vdivsd	.LCPI0_13(%rip), %xmm0, %xmm0
 1      1     0.25                         5     bf 00 00 00 00                movl	$.L.str.6, %edi
 1      1     0.25                         5     ba 00 00 00 00                movl	$.L.str.7, %edx
 1      0     0.25                         2     31 f6                         xorl	%esi, %esi
 1      1     0.25                         2     b0 01                         movb	$1, %al
 4      3     1.00                         5     e8 00 00 00 00                callq	lprintf
 2      9     1.00    *                    7     c4 e1 93 2a 4c 24 68          vcvtsi2sdq	104(%rsp), %xmm13, %xmm1
 2      9     1.00    *                    7     c4 e1 93 2a 44 24 70          vcvtsi2sdq	112(%rsp), %xmm13, %xmm0
 2      10    0.50    *                    9     c4 e2 f1 99 05 00 00 00 00    vfmadd132sd	.LCPI0_14(%rip), %xmm1, %xmm0
 1      1     0.25                         5     bf 00 00 00 00                movl	$.L.str.6, %edi
 1      1     0.25                         5     ba 00 00 00 00                movl	$.L.str.8, %edx
 1      0     0.25                         2     31 f6                         xorl	%esi, %esi
 1      1     0.25                         2     b0 01                         movb	$1, %al
 4      3     1.00                         5     e8 00 00 00 00                callq	lprintf
 1      5     0.50    *                    8     c5 79 28 3d 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm15
 1      6     0.50    *                    6     c5 7d 28 74 24 20             vmovapd	32(%rsp), %ymm14
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.25                         5     b8 e8 03 00 00                movl	$1000, %eax
 1      6     0.50    *                    6     c4 c1 7d 28 0c 24             vmovapd	(%r12), %ymm1
 1      1     1.00                         4     c5 ff 12 c1                   vmovddup	%ymm1, %ymm0
 1      1     1.00                         6     c4 e3 7d 05 d1 0f             vpermilpd	$15, %ymm1, %ymm2
 1      6     0.50    *                    7     c4 c1 7d 10 5c 24 30          vmovupd	48(%r12), %ymm3
 1      1     1.00                         4     c5 ff 12 cb                   vmovddup	%ymm3, %ymm1
 1      1     1.00                         6     c4 e3 7d 05 e3 0f             vpermilpd	$15, %ymm3, %ymm4
 1      6     0.50    *                    5     c4 c1 7d 28 1e                vmovapd	(%r14), %ymm3
 1      6     0.50    *                    5     c4 c1 7d 28 2f                vmovapd	(%r15), %ymm5
 1      6     0.50    *                    7     c4 c1 7d 10 74 24 10          vmovupd	16(%r12), %ymm6
 1      1     1.00                         6     c4 e3 7d 05 fb 05             vpermilpd	$5, %ymm3, %ymm7
 2      9     1.00    *                    8     c4 43 4d 06 44 24 40 31       vperm2f128	$49, 64(%r12), %ymm6, %ymm8
 1      6     0.50    *                    6     c4 c1 7d 10 76 10             vmovupd	16(%r14), %ymm6
 1      3     0.50                         4     c5 6d 59 cf                   vmulpd	%ymm7, %ymm2, %ymm9
 1      3     1.00                         6     c4 63 fd 01 d6 ee             vpermpd	$238, %ymm6, %ymm10
 1      1     1.00                         5     c4 41 7f 12 d8                vmovddup	%ymm8, %ymm11
 1      1     1.00                         6     c4 43 7d 05 e0 0f             vpermilpd	$15, %ymm8, %ymm12
 1      5     0.50                         5     c4 62 fd b6 cb                vfmaddsub231pd	%ymm3, %ymm0, %ymm9
 1      3     1.00                         6     c4 63 fd 01 c6 bb             vpermpd	$187, %ymm6, %ymm8
 1      3     0.50                         5     c4 41 1d 59 c0                vmulpd	%ymm8, %ymm12, %ymm8
 1      6     0.50    *                    6     c4 41 7d 10 6f 10             vmovupd	16(%r15), %ymm13
 1      5     0.50                         5     c4 42 a5 b6 c2                vfmaddsub231pd	%ymm10, %ymm11, %ymm8
 1      3     1.00                         6     c4 43 fd 01 d5 bb             vpermpd	$187, %ymm13, %ymm10
 1      3     0.50                         5     c4 41 1d 59 d2                vmulpd	%ymm10, %ymm12, %ymm10
 1      3     1.00                         6     c4 43 fd 01 e5 ee             vpermpd	$238, %ymm13, %ymm12
 1      5     0.50                         5     c4 42 a5 b6 d4                vfmaddsub231pd	%ymm12, %ymm11, %ymm10
 1      3     0.50                         4     c5 5d 59 df                   vmulpd	%ymm7, %ymm4, %ymm11
 1      5     0.50                         5     c4 62 f5 b6 db                vfmaddsub231pd	%ymm3, %ymm1, %ymm11
 1      3     1.00                         6     c4 43 35 18 e3 01             vinsertf128	$1, %xmm11, %ymm9, %ymm12
 1      3     1.00                         6     c4 43 35 06 cb 31             vperm2f128	$49, %ymm11, %ymm9, %ymm9
 1      1     1.00                         6     c4 63 7d 05 dd 05             vpermilpd	$5, %ymm5, %ymm11
 1      3     0.50                         4     c5 a5 59 d2                   vmulpd	%ymm2, %ymm11, %ymm2
 1      5     0.50                         5     c4 e2 d5 b6 d0                vfmaddsub231pd	%ymm0, %ymm5, %ymm2
 1      3     1.00                         5     c4 c1 1d 58 c1                vaddpd	%ymm9, %ymm12, %ymm0
 1      6     0.50    *                    7     c4 41 7d 28 4c 24 60          vmovapd	96(%r12), %ymm9
 1      3     0.50                         4     c5 a5 59 e4                   vmulpd	%ymm4, %ymm11, %ymm4
 1      5     0.50                         5     c4 e2 d5 b6 e1                vfmaddsub231pd	%ymm1, %ymm5, %ymm4
 1      3     1.00                         6     c4 e3 6d 18 cc 01             vinsertf128	$1, %xmm4, %ymm2, %ymm1
 1      3     1.00                         6     c4 e3 6d 06 d4 31             vperm2f128	$49, %ymm4, %ymm2, %ymm2
 1      1     1.00                         5     c4 c1 7f 12 e1                vmovddup	%ymm9, %ymm4
 1      1     1.00                         6     c4 43 7d 05 c9 0f             vpermilpd	$15, %ymm9, %ymm9
 1      3     0.50                         4     c5 b5 59 ff                   vmulpd	%ymm7, %ymm9, %ymm7
 1      5     0.50                         5     c4 e2 dd b6 fb                vfmaddsub231pd	%ymm3, %ymm4, %ymm7
 1      3     0.50                         5     c4 c1 35 59 db                vmulpd	%ymm11, %ymm9, %ymm3
 1      5     0.50                         5     c4 e2 dd b6 dd                vfmaddsub231pd	%ymm5, %ymm4, %ymm3
 1      3     1.00                         4     c5 f5 58 ca                   vaddpd	%ymm2, %ymm1, %ymm1
 1      3     1.00                         6     c4 e3 45 18 d3 01             vinsertf128	$1, %xmm3, %ymm7, %ymm2
 1      3     1.00                         6     c4 e3 45 06 db 31             vperm2f128	$49, %ymm3, %ymm7, %ymm3
 1      3     1.00                         4     c5 ed 58 d3                   vaddpd	%ymm3, %ymm2, %ymm2
 1      3     1.00                         4     c5 bd 58 d8                   vaddpd	%ymm0, %ymm8, %ymm3
 1      6     0.50    *                    10    c4 c2 7d 19 a4 24 80 00 00 00  vbroadcastsd	128(%r12), %ymm4
 1      6     0.50    *                    10    c4 c2 7d 19 ac 24 88 00 00 00  vbroadcastsd	136(%r12), %ymm5
 1      3     1.00                         6     c4 c3 4d 06 f5 31             vperm2f128	$49, %ymm13, %ymm6, %ymm6
 1      3     1.00                         4     c5 ad 58 c1                   vaddpd	%ymm1, %ymm10, %ymm0
 1      1     1.00                         6     c4 e3 7d 05 ce 05             vpermilpd	$5, %ymm6, %ymm1
 1      3     0.50                         4     c5 f5 59 cd                   vmulpd	%ymm5, %ymm1, %ymm1
 1      5     0.50                         5     c4 e2 cd b6 cc                vfmaddsub231pd	%ymm4, %ymm6, %ymm1
 1      3     1.00                         4     c5 ed 58 c9                   vaddpd	%ymm1, %ymm2, %ymm1
 2      1     1.00           *             4     c5 fd 29 19                   vmovapd	%ymm3, (%rcx)
 2      1     1.00           *             5     c5 f9 29 49 20                vmovapd	%xmm1, 32(%rcx)
 2      1     1.00           *             4     c5 fd 29 02                   vmovapd	%ymm0, (%rdx)
 2      1     1.00           *             7     c4 e3 7d 19 4a 20 01          vextractf128	$1, %ymm1, 32(%rdx)
 1      6     0.50    *                    6     c4 c1 7d 28 0c 24             vmovapd	(%r12), %ymm1
 1      1     1.00                         4     c5 7f 12 c9                   vmovddup	%ymm1, %ymm9
 1      1     1.00                         6     c4 63 7d 05 c1 0f             vpermilpd	$15, %ymm1, %ymm8
 1      6     0.50    *                    7     c4 c1 7d 10 4c 24 30          vmovupd	48(%r12), %ymm1
 1      1     1.00                         4     c5 7f 12 d1                   vmovddup	%ymm1, %ymm10
 1      6     0.50    *                    7     c4 c1 7d 28 54 24 60          vmovapd	96(%r12), %ymm2
 1      1     1.00                         6     c4 63 7d 05 d9 0f             vpermilpd	$15, %ymm1, %ymm11
 1      1     1.00                         4     c5 ff 12 da                   vmovddup	%ymm2, %ymm3
 1      1     1.00                         6     c4 e3 7d 05 e2 0f             vpermilpd	$15, %ymm2, %ymm4
 1      6     0.50    *                    4     c5 fd 28 29                   vmovapd	(%rcx), %ymm5
 1      1     1.00                         6     c4 e3 7d 05 fd 05             vpermilpd	$5, %ymm5, %ymm7
 1      1     1.00                         6     c4 e3 7d 05 f0 05             vpermilpd	$5, %ymm0, %ymm6
 1      3     0.50                         4     c5 bd 59 cf                   vmulpd	%ymm7, %ymm8, %ymm1
 1      3     0.50                         4     c5 a5 59 d7                   vmulpd	%ymm7, %ymm11, %ymm2
 1      5     0.50                         5     c4 e2 b5 b6 cd                vfmaddsub231pd	%ymm5, %ymm9, %ymm1
 1      3     0.50                         4     c5 3d 59 c6                   vmulpd	%ymm6, %ymm8, %ymm8
 1      5     0.50                         5     c4 42 fd b6 c1                vfmaddsub231pd	%ymm9, %ymm0, %ymm8
 1      6     0.50    *                    7     c4 41 7d 10 4c 24 10          vmovupd	16(%r12), %ymm9
 1      5     0.50                         5     c4 e2 ad b6 d5                vfmaddsub231pd	%ymm5, %ymm10, %ymm2
 2      9     1.00    *                    8     c4 43 35 06 4c 24 40 31       vperm2f128	$49, 64(%r12), %ymm9, %ymm9
 1      3     0.50                         4     c5 25 59 de                   vmulpd	%ymm6, %ymm11, %ymm11
 1      5     0.50                         5     c4 42 fd b6 da                vfmaddsub231pd	%ymm10, %ymm0, %ymm11
 1      6     0.50    *                    5     c5 7d 10 51 10                vmovupd	16(%rcx), %ymm10
 1      3     0.50                         4     c5 dd 59 ff                   vmulpd	%ymm7, %ymm4, %ymm7
 1      5     0.50                         5     c4 e2 e5 b6 fd                vfmaddsub231pd	%ymm5, %ymm3, %ymm7
 1      3     1.00                         6     c4 c3 fd 01 ea ee             vpermpd	$238, %ymm10, %ymm5
 1      3     0.50                         4     c5 cd 59 e4                   vmulpd	%ymm4, %ymm6, %ymm4
 1      1     1.00                         5     c4 c1 7f 12 f1                vmovddup	%ymm9, %ymm6
 1      1     1.00                         6     c4 43 7d 05 c9 0f             vpermilpd	$15, %ymm9, %ymm9
 1      5     0.50                         5     c4 e2 e5 b6 e0                vfmaddsub231pd	%ymm0, %ymm3, %ymm4
 1      3     1.00                         6     c4 c3 fd 01 c2 bb             vpermpd	$187, %ymm10, %ymm0
 1      3     0.50                         4     c5 b5 59 c0                   vmulpd	%ymm0, %ymm9, %ymm0
 1      6     0.50    *                    5     c5 fd 10 5a 10                vmovupd	16(%rdx), %ymm3
 1      5     0.50                         5     c4 e2 cd b6 c5                vfmaddsub231pd	%ymm5, %ymm6, %ymm0
 1      3     1.00                         6     c4 e3 fd 01 eb bb             vpermpd	$187, %ymm3, %ymm5
 1      3     0.50                         4     c5 b5 59 ed                   vmulpd	%ymm5, %ymm9, %ymm5
 1      3     1.00                         6     c4 63 fd 01 cb ee             vpermpd	$238, %ymm3, %ymm9
 1      5     0.50                         5     c4 c2 cd b6 e9                vfmaddsub231pd	%ymm9, %ymm6, %ymm5
 1      6     0.50    *                    10    c4 c2 7d 19 b4 24 88 00 00 00  vbroadcastsd	136(%r12), %ymm6
 1      3     1.00                         6     c4 e3 2d 06 db 31             vperm2f128	$49, %ymm3, %ymm10, %ymm3
 1      1     1.00                         6     c4 63 7d 05 cb 05             vpermilpd	$5, %ymm3, %ymm9
 1      3     0.50                         4     c5 b5 59 f6                   vmulpd	%ymm6, %ymm9, %ymm6
 1      6     0.50    *                    10    c4 42 7d 19 8c 24 80 00 00 00  vbroadcastsd	128(%r12), %ymm9
 1      5     0.50                         5     c4 c2 e5 b6 f1                vfmaddsub231pd	%ymm9, %ymm3, %ymm6
 1      3     1.00                         6     c4 e3 75 18 da 01             vinsertf128	$1, %xmm2, %ymm1, %ymm3
 1      3     1.00                         6     c4 e3 75 06 ca 31             vperm2f128	$49, %ymm2, %ymm1, %ymm1
 1      3     1.00                         4     c5 e5 58 c9                   vaddpd	%ymm1, %ymm3, %ymm1
 1      3     1.00                         6     c4 c3 3d 18 d3 01             vinsertf128	$1, %xmm11, %ymm8, %ymm2
 1      3     1.00                         6     c4 c3 3d 06 db 31             vperm2f128	$49, %ymm11, %ymm8, %ymm3
 1      3     1.00                         4     c5 f5 58 c0                   vaddpd	%ymm0, %ymm1, %ymm0
 1      3     1.00                         4     c5 ed 58 cb                   vaddpd	%ymm3, %ymm2, %ymm1
 1      3     1.00                         6     c4 e3 45 18 d4 01             vinsertf128	$1, %xmm4, %ymm7, %ymm2
 1      3     1.00                         6     c4 e3 45 06 dc 31             vperm2f128	$49, %ymm4, %ymm7, %ymm3
 1      3     1.00                         4     c5 f5 58 cd                   vaddpd	%ymm5, %ymm1, %ymm1
 1      3     1.00                         4     c5 ed 58 d3                   vaddpd	%ymm3, %ymm2, %ymm2
 1      3     1.00                         4     c5 ed 58 d6                   vaddpd	%ymm6, %ymm2, %ymm2
 2      1     1.00           *             5     c4 c1 7d 29 06                vmovapd	%ymm0, (%r14)
 2      1     1.00           *             6     c4 c1 79 29 56 20             vmovapd	%xmm2, 32(%r14)
 2      1     1.00           *             5     c4 c1 7d 29 0f                vmovapd	%ymm1, (%r15)
 2      1     1.00           *             7     c4 c3 7d 19 57 20 01          vextractf128	$1, %ymm2, 32(%r15)
 2      9     0.50    *                    5     c4 c1 0d 59 06                vmulpd	(%r14), %ymm14, %ymm0
 2      1     1.00           *             5     c4 c1 7d 11 06                vmovupd	%ymm0, (%r14)
 2      8     0.50    *                    6     c4 c1 01 59 46 20             vmulpd	32(%r14), %xmm15, %xmm0
 2      1     1.00           *             6     c4 c1 79 11 46 20             vmovupd	%xmm0, 32(%r14)
 2      9     0.50    *                    5     c4 c1 0d 59 07                vmulpd	(%r15), %ymm14, %ymm0
 2      1     1.00           *             5     c4 c1 7d 11 07                vmovupd	%ymm0, (%r15)
 2      8     0.50    *                    6     c4 c1 01 59 47 20             vmulpd	32(%r15), %xmm15, %xmm0
 2      1     1.00           *             6     c4 c1 79 11 47 20             vmovupd	%xmm0, 32(%r15)
 1      1     0.25                         2     ff c8                         decl	%eax
 1      1     0.50                         6     0f 85 00 00 00 00             jne	.LBB0_70
 1      1     0.50                         8     48 8d bc 24 80 00 00 00       leaq	128(%rsp), %rdi
 1      0     0.25                         2     31 f6                         xorl	%esi, %esi
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	gettimeofday
 1      1     0.25                         6     41 bd 00 e1 f5 05             movl	$100000000, %r13d
 4      3     1.00                         5     e8 00 00 00 00                callq	clock
 1      5     0.50    *                    8     c5 79 28 3d 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm15
 1      6     0.50    *                    6     c5 7d 28 74 24 20             vmovapd	32(%rsp), %ymm14
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     1.00           *             5     48 89 44 24 10                movq	%rax, 16(%rsp)
 1      6     0.50    *                    6     c4 c1 7d 28 0c 24             vmovapd	(%r12), %ymm1
 1      1     1.00                         4     c5 ff 12 c1                   vmovddup	%ymm1, %ymm0
 1      1     1.00                         6     c4 e3 7d 05 d1 0f             vpermilpd	$15, %ymm1, %ymm2
 1      6     0.50    *                    7     c4 c1 7d 10 5c 24 30          vmovupd	48(%r12), %ymm3
 1      1     1.00                         4     c5 ff 12 cb                   vmovddup	%ymm3, %ymm1
 1      1     1.00                         6     c4 e3 7d 05 e3 0f             vpermilpd	$15, %ymm3, %ymm4
 1      6     0.50    *                    5     c4 c1 7d 28 1e                vmovapd	(%r14), %ymm3
 1      6     0.50    *                    5     c4 c1 7d 28 2f                vmovapd	(%r15), %ymm5
 1      6     0.50    *                    7     c4 c1 7d 10 74 24 10          vmovupd	16(%r12), %ymm6
 1      1     1.00                         6     c4 e3 7d 05 fb 05             vpermilpd	$5, %ymm3, %ymm7
 2      9     1.00    *                    8     c4 43 4d 06 44 24 40 31       vperm2f128	$49, 64(%r12), %ymm6, %ymm8
 1      6     0.50    *                    6     c4 c1 7d 10 76 10             vmovupd	16(%r14), %ymm6
 1      3     0.50                         4     c5 6d 59 cf                   vmulpd	%ymm7, %ymm2, %ymm9
 1      3     1.00                         6     c4 63 fd 01 d6 ee             vpermpd	$238, %ymm6, %ymm10
 1      1     1.00                         5     c4 41 7f 12 d8                vmovddup	%ymm8, %ymm11
 1      1     1.00                         6     c4 43 7d 05 e0 0f             vpermilpd	$15, %ymm8, %ymm12
 1      5     0.50                         5     c4 62 fd b6 cb                vfmaddsub231pd	%ymm3, %ymm0, %ymm9
 1      3     1.00                         6     c4 63 fd 01 c6 bb             vpermpd	$187, %ymm6, %ymm8
 1      3     0.50                         5     c4 41 1d 59 c0                vmulpd	%ymm8, %ymm12, %ymm8
 1      6     0.50    *                    6     c4 41 7d 10 6f 10             vmovupd	16(%r15), %ymm13
 1      5     0.50                         5     c4 42 a5 b6 c2                vfmaddsub231pd	%ymm10, %ymm11, %ymm8
 1      3     1.00                         6     c4 43 fd 01 d5 bb             vpermpd	$187, %ymm13, %ymm10
 1      3     0.50                         5     c4 41 1d 59 d2                vmulpd	%ymm10, %ymm12, %ymm10
 1      3     1.00                         6     c4 43 fd 01 e5 ee             vpermpd	$238, %ymm13, %ymm12
 1      5     0.50                         5     c4 42 a5 b6 d4                vfmaddsub231pd	%ymm12, %ymm11, %ymm10
 1      3     0.50                         4     c5 5d 59 df                   vmulpd	%ymm7, %ymm4, %ymm11
 1      5     0.50                         5     c4 62 f5 b6 db                vfmaddsub231pd	%ymm3, %ymm1, %ymm11
 1      3     1.00                         6     c4 43 35 18 e3 01             vinsertf128	$1, %xmm11, %ymm9, %ymm12
 1      3     1.00                         6     c4 43 35 06 cb 31             vperm2f128	$49, %ymm11, %ymm9, %ymm9
 1      1     1.00                         6     c4 63 7d 05 dd 05             vpermilpd	$5, %ymm5, %ymm11
 1      3     0.50                         4     c5 a5 59 d2                   vmulpd	%ymm2, %ymm11, %ymm2
 1      5     0.50                         5     c4 e2 d5 b6 d0                vfmaddsub231pd	%ymm0, %ymm5, %ymm2
 1      3     1.00                         5     c4 c1 1d 58 c1                vaddpd	%ymm9, %ymm12, %ymm0
 1      6     0.50    *                    7     c4 41 7d 28 4c 24 60          vmovapd	96(%r12), %ymm9
 1      3     0.50                         4     c5 a5 59 e4                   vmulpd	%ymm4, %ymm11, %ymm4
 1      5     0.50                         5     c4 e2 d5 b6 e1                vfmaddsub231pd	%ymm1, %ymm5, %ymm4
 1      3     1.00                         6     c4 e3 6d 18 cc 01             vinsertf128	$1, %xmm4, %ymm2, %ymm1
 1      3     1.00                         6     c4 e3 6d 06 d4 31             vperm2f128	$49, %ymm4, %ymm2, %ymm2
 1      1     1.00                         5     c4 c1 7f 12 e1                vmovddup	%ymm9, %ymm4
 1      1     1.00                         6     c4 43 7d 05 c9 0f             vpermilpd	$15, %ymm9, %ymm9
 1      3     0.50                         4     c5 b5 59 ff                   vmulpd	%ymm7, %ymm9, %ymm7
 1      5     0.50                         5     c4 e2 dd b6 fb                vfmaddsub231pd	%ymm3, %ymm4, %ymm7
 1      3     0.50                         5     c4 c1 35 59 db                vmulpd	%ymm11, %ymm9, %ymm3
 1      5     0.50                         5     c4 e2 dd b6 dd                vfmaddsub231pd	%ymm5, %ymm4, %ymm3
 1      3     1.00                         4     c5 f5 58 ca                   vaddpd	%ymm2, %ymm1, %ymm1
 1      3     1.00                         6     c4 e3 45 18 d3 01             vinsertf128	$1, %xmm3, %ymm7, %ymm2
 1      3     1.00                         6     c4 e3 45 06 db 31             vperm2f128	$49, %ymm3, %ymm7, %ymm3
 1      3     1.00                         4     c5 ed 58 d3                   vaddpd	%ymm3, %ymm2, %ymm2
 1      3     1.00                         4     c5 bd 58 d8                   vaddpd	%ymm0, %ymm8, %ymm3
 1      6     0.50    *                    10    c4 c2 7d 19 a4 24 80 00 00 00  vbroadcastsd	128(%r12), %ymm4
 1      6     0.50    *                    10    c4 c2 7d 19 ac 24 88 00 00 00  vbroadcastsd	136(%r12), %ymm5
 1      3     1.00                         6     c4 c3 4d 06 f5 31             vperm2f128	$49, %ymm13, %ymm6, %ymm6
 1      3     1.00                         4     c5 ad 58 c1                   vaddpd	%ymm1, %ymm10, %ymm0
 1      1     1.00                         6     c4 e3 7d 05 ce 05             vpermilpd	$5, %ymm6, %ymm1
 1      3     0.50                         4     c5 f5 59 cd                   vmulpd	%ymm5, %ymm1, %ymm1
 1      5     0.50                         5     c4 e2 cd b6 cc                vfmaddsub231pd	%ymm4, %ymm6, %ymm1
 1      3     1.00                         4     c5 ed 58 c9                   vaddpd	%ymm1, %ymm2, %ymm1
 2      1     1.00           *             4     c5 fd 29 19                   vmovapd	%ymm3, (%rcx)
 2      1     1.00           *             5     c5 f9 29 49 20                vmovapd	%xmm1, 32(%rcx)
 2      1     1.00           *             4     c5 fd 29 02                   vmovapd	%ymm0, (%rdx)
 2      1     1.00           *             7     c4 e3 7d 19 4a 20 01          vextractf128	$1, %ymm1, 32(%rdx)
 1      6     0.50    *                    6     c4 c1 7d 28 0c 24             vmovapd	(%r12), %ymm1
 1      1     1.00                         4     c5 7f 12 c9                   vmovddup	%ymm1, %ymm9
 1      1     1.00                         6     c4 63 7d 05 c1 0f             vpermilpd	$15, %ymm1, %ymm8
 1      6     0.50    *                    7     c4 c1 7d 10 4c 24 30          vmovupd	48(%r12), %ymm1
 1      1     1.00                         4     c5 7f 12 d1                   vmovddup	%ymm1, %ymm10
 1      6     0.50    *                    7     c4 c1 7d 28 54 24 60          vmovapd	96(%r12), %ymm2
 1      1     1.00                         6     c4 63 7d 05 d9 0f             vpermilpd	$15, %ymm1, %ymm11
 1      1     1.00                         4     c5 ff 12 da                   vmovddup	%ymm2, %ymm3
 1      1     1.00                         6     c4 e3 7d 05 e2 0f             vpermilpd	$15, %ymm2, %ymm4
 1      6     0.50    *                    4     c5 fd 28 29                   vmovapd	(%rcx), %ymm5
 1      1     1.00                         6     c4 e3 7d 05 fd 05             vpermilpd	$5, %ymm5, %ymm7
 1      1     1.00                         6     c4 e3 7d 05 f0 05             vpermilpd	$5, %ymm0, %ymm6
 1      3     0.50                         4     c5 bd 59 cf                   vmulpd	%ymm7, %ymm8, %ymm1
 1      3     0.50                         4     c5 a5 59 d7                   vmulpd	%ymm7, %ymm11, %ymm2
 1      5     0.50                         5     c4 e2 b5 b6 cd                vfmaddsub231pd	%ymm5, %ymm9, %ymm1
 1      3     0.50                         4     c5 3d 59 c6                   vmulpd	%ymm6, %ymm8, %ymm8
 1      5     0.50                         5     c4 42 fd b6 c1                vfmaddsub231pd	%ymm9, %ymm0, %ymm8
 1      6     0.50    *                    7     c4 41 7d 10 4c 24 10          vmovupd	16(%r12), %ymm9
 1      5     0.50                         5     c4 e2 ad b6 d5                vfmaddsub231pd	%ymm5, %ymm10, %ymm2
 2      9     1.00    *                    8     c4 43 35 06 4c 24 40 31       vperm2f128	$49, 64(%r12), %ymm9, %ymm9
 1      3     0.50                         4     c5 25 59 de                   vmulpd	%ymm6, %ymm11, %ymm11
 1      5     0.50                         5     c4 42 fd b6 da                vfmaddsub231pd	%ymm10, %ymm0, %ymm11
 1      6     0.50    *                    5     c5 7d 10 51 10                vmovupd	16(%rcx), %ymm10
 1      3     0.50                         4     c5 dd 59 ff                   vmulpd	%ymm7, %ymm4, %ymm7
 1      5     0.50                         5     c4 e2 e5 b6 fd                vfmaddsub231pd	%ymm5, %ymm3, %ymm7
 1      3     1.00                         6     c4 c3 fd 01 ea ee             vpermpd	$238, %ymm10, %ymm5
 1      3     0.50                         4     c5 cd 59 e4                   vmulpd	%ymm4, %ymm6, %ymm4
 1      1     1.00                         5     c4 c1 7f 12 f1                vmovddup	%ymm9, %ymm6
 1      1     1.00                         6     c4 43 7d 05 c9 0f             vpermilpd	$15, %ymm9, %ymm9
 1      5     0.50                         5     c4 e2 e5 b6 e0                vfmaddsub231pd	%ymm0, %ymm3, %ymm4
 1      3     1.00                         6     c4 c3 fd 01 c2 bb             vpermpd	$187, %ymm10, %ymm0
 1      3     0.50                         4     c5 b5 59 c0                   vmulpd	%ymm0, %ymm9, %ymm0
 1      6     0.50    *                    5     c5 fd 10 5a 10                vmovupd	16(%rdx), %ymm3
 1      5     0.50                         5     c4 e2 cd b6 c5                vfmaddsub231pd	%ymm5, %ymm6, %ymm0
 1      3     1.00                         6     c4 e3 fd 01 eb bb             vpermpd	$187, %ymm3, %ymm5
 1      3     0.50                         4     c5 b5 59 ed                   vmulpd	%ymm5, %ymm9, %ymm5
 1      3     1.00                         6     c4 63 fd 01 cb ee             vpermpd	$238, %ymm3, %ymm9
 1      5     0.50                         5     c4 c2 cd b6 e9                vfmaddsub231pd	%ymm9, %ymm6, %ymm5
 1      6     0.50    *                    10    c4 c2 7d 19 b4 24 88 00 00 00  vbroadcastsd	136(%r12), %ymm6
 1      3     1.00                         6     c4 e3 2d 06 db 31             vperm2f128	$49, %ymm3, %ymm10, %ymm3
 1      1     1.00                         6     c4 63 7d 05 cb 05             vpermilpd	$5, %ymm3, %ymm9
 1      3     0.50                         4     c5 b5 59 f6                   vmulpd	%ymm6, %ymm9, %ymm6
 1      6     0.50    *                    10    c4 42 7d 19 8c 24 80 00 00 00  vbroadcastsd	128(%r12), %ymm9
 1      5     0.50                         5     c4 c2 e5 b6 f1                vfmaddsub231pd	%ymm9, %ymm3, %ymm6
 1      3     1.00                         6     c4 e3 75 18 da 01             vinsertf128	$1, %xmm2, %ymm1, %ymm3
 1      3     1.00                         6     c4 e3 75 06 ca 31             vperm2f128	$49, %ymm2, %ymm1, %ymm1
 1      3     1.00                         4     c5 e5 58 c9                   vaddpd	%ymm1, %ymm3, %ymm1
 1      3     1.00                         6     c4 c3 3d 18 d3 01             vinsertf128	$1, %xmm11, %ymm8, %ymm2
 1      3     1.00                         6     c4 c3 3d 06 db 31             vperm2f128	$49, %ymm11, %ymm8, %ymm3
 1      3     1.00                         4     c5 f5 58 c0                   vaddpd	%ymm0, %ymm1, %ymm0
 1      3     1.00                         4     c5 ed 58 cb                   vaddpd	%ymm3, %ymm2, %ymm1
 1      3     1.00                         6     c4 e3 45 18 d4 01             vinsertf128	$1, %xmm4, %ymm7, %ymm2
 1      3     1.00                         6     c4 e3 45 06 dc 31             vperm2f128	$49, %ymm4, %ymm7, %ymm3
 1      3     1.00                         4     c5 f5 58 cd                   vaddpd	%ymm5, %ymm1, %ymm1
 1      3     1.00                         4     c5 ed 58 d3                   vaddpd	%ymm3, %ymm2, %ymm2
 1      3     1.00                         4     c5 ed 58 d6                   vaddpd	%ymm6, %ymm2, %ymm2
 2      1     1.00           *             5     c4 c1 7d 29 06                vmovapd	%ymm0, (%r14)
 2      1     1.00           *             6     c4 c1 79 29 56 20             vmovapd	%xmm2, 32(%r14)
 2      1     1.00           *             5     c4 c1 7d 29 0f                vmovapd	%ymm1, (%r15)
 2      1     1.00           *             7     c4 c3 7d 19 57 20 01          vextractf128	$1, %ymm2, 32(%r15)
 2      9     0.50    *                    5     c4 c1 0d 59 06                vmulpd	(%r14), %ymm14, %ymm0
 2      1     1.00           *             5     c4 c1 7d 11 06                vmovupd	%ymm0, (%r14)
 2      8     0.50    *                    6     c4 c1 01 59 46 20             vmulpd	32(%r14), %xmm15, %xmm0
 2      1     1.00           *             6     c4 c1 79 11 46 20             vmovupd	%xmm0, 32(%r14)
 2      9     0.50    *                    5     c4 c1 0d 59 07                vmulpd	(%r15), %ymm14, %ymm0
 2      1     1.00           *             5     c4 c1 7d 11 07                vmovupd	%ymm0, (%r15)
 2      8     0.50    *                    6     c4 c1 01 59 47 20             vmulpd	32(%r15), %xmm15, %xmm0
 2      1     1.00           *             6     c4 c1 79 11 47 20             vmovupd	%xmm0, 32(%r15)
 1      1     0.25                         3     41 ff cd                      decl	%r13d
 1      1     0.50                         6     0f 85 00 00 00 00             jne	.LBB0_72
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	clock
 1      1     0.25                         3     48 89 c3                      movq	%rax, %rbx
 1      1     0.50                         8     4c 8d ac 24 b8 00 00 00       leaq	184(%rsp), %r13
 1      1     0.25                         3     4c 89 ef                      movq	%r13, %rdi
 1      0     0.25                         2     31 f6                         xorl	%esi, %esi
 4      3     1.00                         5     e8 00 00 00 00                callq	gettimeofday
 1      1     0.50                         5     48 8d 7c 24 68                leaq	104(%rsp), %rdi
 1      1     0.50                         8     48 8d 94 24 80 00 00 00       leaq	128(%rsp), %rdx
 1      1     0.25                         3     4c 89 ee                      movq	%r13, %rsi
 4      3     1.00                         5     e8 00 00 00 00                callq	timeval_subtract
 2      6     0.50    *                    5     48 2b 5c 24 10                subq	16(%rsp), %rbx
 2      4     1.00                         5     c4 e1 8b 2a c3                vcvtsi2sd	%rbx, %xmm14, %xmm0
 2      19    8.00    *                    8     c5 fb 5e 05 00 00 00 00       vdivsd	.LCPI0_13(%rip), %xmm0, %xmm0
 1      1     0.25                         5     bf 00 00 00 00                movl	$.L.str.9, %edi
 1      1     0.25                         5     ba 00 00 00 00                movl	$.L.str.7, %edx
 1      0     0.25                         2     31 f6                         xorl	%esi, %esi
 1      1     0.25                         2     b0 01                         movb	$1, %al
 4      3     1.00                         5     e8 00 00 00 00                callq	lprintf
 2      9     1.00    *                    7     c4 e1 93 2a 4c 24 68          vcvtsi2sdq	104(%rsp), %xmm13, %xmm1
 2      9     1.00    *                    7     c4 e1 93 2a 44 24 70          vcvtsi2sdq	112(%rsp), %xmm13, %xmm0
 2      10    0.50    *                    9     c4 e2 f1 99 05 00 00 00 00    vfmadd132sd	.LCPI0_14(%rip), %xmm1, %xmm0
 1      1     0.25                         5     bf 00 00 00 00                movl	$.L.str.10, %edi
 1      1     0.25                         5     ba 00 00 00 00                movl	$.L.str.8, %edx
 1      0     0.25                         2     31 f6                         xorl	%esi, %esi
 1      1     0.25                         2     b0 01                         movb	$1, %al
 4      3     1.00                         5     e8 00 00 00 00                callq	lprintf
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.25                         5     bb e8 03 00 00                movl	$1000, %ebx
 1      5     0.50    *                    6     c4 c1 7b 10 24 24             vmovsd	(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 08          vmovsd	8(%r12), %xmm5
 1      5     0.50    *                    5     c4 c1 7b 10 16                vmovsd	(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 08             vmovsd	8(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_75
 2      1     1.00           *             4     c5 fb 11 00                   vmovsd	%xmm0, (%rax)
 2      1     1.00           *             5     c5 fb 11 48 08                vmovsd	%xmm1, 8(%rax)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 10          vmovsd	16(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 18          vmovsd	24(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 10             vmovsd	16(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 18             vmovsd	24(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_78
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             4     c5 7b 11 00                   vmovsd	%xmm8, (%rax)
 2      1     1.00           *             5     c5 fb 11 78 08                vmovsd	%xmm7, 8(%rax)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 20          vmovsd	32(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 28          vmovsd	40(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 20             vmovsd	32(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 28             vmovsd	40(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_81
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             4     c5 fb 11 00                   vmovsd	%xmm0, (%rax)
 2      1     1.00           *             5     c5 fb 11 48 08                vmovsd	%xmm1, 8(%rax)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 30          vmovsd	48(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 38          vmovsd	56(%r12), %xmm5
 1      5     0.50    *                    5     c4 c1 7b 10 16                vmovsd	(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 08             vmovsd	8(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_84
 2      1     1.00           *             5     c5 fb 11 40 10                vmovsd	%xmm0, 16(%rax)
 2      1     1.00           *             5     c5 fb 11 48 18                vmovsd	%xmm1, 24(%rax)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 40          vmovsd	64(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 48          vmovsd	72(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 10             vmovsd	16(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 18             vmovsd	24(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_87
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             5     c5 7b 11 40 10                vmovsd	%xmm8, 16(%rax)
 2      1     1.00           *             5     c5 fb 11 78 18                vmovsd	%xmm7, 24(%rax)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 50          vmovsd	80(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 58          vmovsd	88(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 20             vmovsd	32(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 28             vmovsd	40(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_90
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             5     c5 fb 11 40 10                vmovsd	%xmm0, 16(%rax)
 2      1     1.00           *             5     c5 fb 11 48 18                vmovsd	%xmm1, 24(%rax)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 60          vmovsd	96(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 68          vmovsd	104(%r12), %xmm5
 1      5     0.50    *                    5     c4 c1 7b 10 16                vmovsd	(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 08             vmovsd	8(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_93
 2      1     1.00           *             5     c5 fb 11 40 20                vmovsd	%xmm0, 32(%rax)
 2      1     1.00           *             5     c5 fb 11 48 28                vmovsd	%xmm1, 40(%rax)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 70          vmovsd	112(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 78          vmovsd	120(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 10             vmovsd	16(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 18             vmovsd	24(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_96
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             5     c5 7b 11 40 20                vmovsd	%xmm8, 32(%rax)
 2      1     1.00           *             5     c5 fb 11 78 28                vmovsd	%xmm7, 40(%rax)
 1      5     0.50    *                    10    c4 c1 7b 10 a4 24 80 00 00 00  vmovsd	128(%r12), %xmm4
 1      5     0.50    *                    10    c4 c1 7b 10 ac 24 88 00 00 00  vmovsd	136(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 20             vmovsd	32(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 28             vmovsd	40(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_99
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             5     c5 fb 11 40 20                vmovsd	%xmm0, 32(%rax)
 2      1     1.00           *             5     c5 fb 11 48 28                vmovsd	%xmm1, 40(%rax)
 1      5     0.50    *                    6     c4 c1 7b 10 24 24             vmovsd	(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 08          vmovsd	8(%r12), %xmm5
 1      5     0.50    *                    5     c4 c1 7b 10 17                vmovsd	(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 08             vmovsd	8(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_102
 2      1     1.00           *             4     c5 fb 11 01                   vmovsd	%xmm0, (%rcx)
 2      1     1.00           *             5     c5 fb 11 49 08                vmovsd	%xmm1, 8(%rcx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 10          vmovsd	16(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 18          vmovsd	24(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 10             vmovsd	16(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 18             vmovsd	24(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_105
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             4     c5 7b 11 01                   vmovsd	%xmm8, (%rcx)
 2      1     1.00           *             5     c5 fb 11 79 08                vmovsd	%xmm7, 8(%rcx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 20          vmovsd	32(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 28          vmovsd	40(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 20             vmovsd	32(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 28             vmovsd	40(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_108
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             4     c5 fb 11 01                   vmovsd	%xmm0, (%rcx)
 2      1     1.00           *             5     c5 fb 11 49 08                vmovsd	%xmm1, 8(%rcx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 30          vmovsd	48(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 38          vmovsd	56(%r12), %xmm5
 1      5     0.50    *                    5     c4 c1 7b 10 17                vmovsd	(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 08             vmovsd	8(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_111
 2      1     1.00           *             5     c5 fb 11 41 10                vmovsd	%xmm0, 16(%rcx)
 2      1     1.00           *             5     c5 fb 11 49 18                vmovsd	%xmm1, 24(%rcx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 40          vmovsd	64(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 48          vmovsd	72(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 10             vmovsd	16(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 18             vmovsd	24(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_114
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             5     c5 7b 11 41 10                vmovsd	%xmm8, 16(%rcx)
 2      1     1.00           *             5     c5 fb 11 79 18                vmovsd	%xmm7, 24(%rcx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 50          vmovsd	80(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 58          vmovsd	88(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 20             vmovsd	32(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 28             vmovsd	40(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_117
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             5     c5 fb 11 41 10                vmovsd	%xmm0, 16(%rcx)
 2      1     1.00           *             5     c5 fb 11 49 18                vmovsd	%xmm1, 24(%rcx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 60          vmovsd	96(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 68          vmovsd	104(%r12), %xmm5
 1      5     0.50    *                    5     c4 c1 7b 10 17                vmovsd	(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 08             vmovsd	8(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_120
 2      1     1.00           *             5     c5 fb 11 41 20                vmovsd	%xmm0, 32(%rcx)
 2      1     1.00           *             5     c5 fb 11 49 28                vmovsd	%xmm1, 40(%rcx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 70          vmovsd	112(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 78          vmovsd	120(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 10             vmovsd	16(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 18             vmovsd	24(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_123
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             5     c5 7b 11 41 20                vmovsd	%xmm8, 32(%rcx)
 2      1     1.00           *             5     c5 fb 11 79 28                vmovsd	%xmm7, 40(%rcx)
 1      5     0.50    *                    10    c4 c1 7b 10 a4 24 80 00 00 00  vmovsd	128(%r12), %xmm4
 1      5     0.50    *                    10    c4 c1 7b 10 ac 24 88 00 00 00  vmovsd	136(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 20             vmovsd	32(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 28             vmovsd	40(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_126
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             5     c5 fb 11 41 20                vmovsd	%xmm0, 32(%rcx)
 2      1     1.00           *             5     c5 fb 11 49 28                vmovsd	%xmm1, 40(%rcx)
 1      5     0.50    *                    6     c4 c1 7b 10 24 24             vmovsd	(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 08          vmovsd	8(%r12), %xmm5
 1      5     0.50    *                    4     c5 fb 10 10                   vmovsd	(%rax), %xmm2
 1      5     0.50    *                    5     c5 fb 10 58 08                vmovsd	8(%rax), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_129
 2      1     1.00           *             5     c4 c1 7b 11 06                vmovsd	%xmm0, (%r14)
 2      1     1.00           *             6     c4 c1 7b 11 4e 08             vmovsd	%xmm1, 8(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 10          vmovsd	16(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 18          vmovsd	24(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 50 10                vmovsd	16(%rax), %xmm2
 1      5     0.50    *                    5     c5 fb 10 58 18                vmovsd	24(%rax), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_132
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             5     c4 41 7b 11 06                vmovsd	%xmm8, (%r14)
 2      1     1.00           *             6     c4 c1 7b 11 7e 08             vmovsd	%xmm7, 8(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 20          vmovsd	32(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 28          vmovsd	40(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 50 20                vmovsd	32(%rax), %xmm2
 1      5     0.50    *                    5     c5 fb 10 58 28                vmovsd	40(%rax), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_135
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             5     c4 c1 7b 11 06                vmovsd	%xmm0, (%r14)
 2      1     1.00           *             6     c4 c1 7b 11 4e 08             vmovsd	%xmm1, 8(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 30          vmovsd	48(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 38          vmovsd	56(%r12), %xmm5
 1      5     0.50    *                    4     c5 fb 10 10                   vmovsd	(%rax), %xmm2
 1      5     0.50    *                    5     c5 fb 10 58 08                vmovsd	8(%rax), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_138
 2      1     1.00           *             6     c4 c1 7b 11 46 10             vmovsd	%xmm0, 16(%r14)
 2      1     1.00           *             6     c4 c1 7b 11 4e 18             vmovsd	%xmm1, 24(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 40          vmovsd	64(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 48          vmovsd	72(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 50 10                vmovsd	16(%rax), %xmm2
 1      5     0.50    *                    5     c5 fb 10 58 18                vmovsd	24(%rax), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_141
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             6     c4 41 7b 11 46 10             vmovsd	%xmm8, 16(%r14)
 2      1     1.00           *             6     c4 c1 7b 11 7e 18             vmovsd	%xmm7, 24(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 50          vmovsd	80(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 58          vmovsd	88(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 50 20                vmovsd	32(%rax), %xmm2
 1      5     0.50    *                    5     c5 fb 10 58 28                vmovsd	40(%rax), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_144
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             6     c4 c1 7b 11 46 10             vmovsd	%xmm0, 16(%r14)
 2      1     1.00           *             6     c4 c1 7b 11 4e 18             vmovsd	%xmm1, 24(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 60          vmovsd	96(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 68          vmovsd	104(%r12), %xmm5
 1      5     0.50    *                    4     c5 fb 10 10                   vmovsd	(%rax), %xmm2
 1      5     0.50    *                    5     c5 fb 10 58 08                vmovsd	8(%rax), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_147
 2      1     1.00           *             6     c4 c1 7b 11 46 20             vmovsd	%xmm0, 32(%r14)
 2      1     1.00           *             6     c4 c1 7b 11 4e 28             vmovsd	%xmm1, 40(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 70          vmovsd	112(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 78          vmovsd	120(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 50 10                vmovsd	16(%rax), %xmm2
 1      5     0.50    *                    5     c5 fb 10 58 18                vmovsd	24(%rax), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_150
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             6     c4 41 7b 11 46 20             vmovsd	%xmm8, 32(%r14)
 2      1     1.00           *             6     c4 c1 7b 11 7e 28             vmovsd	%xmm7, 40(%r14)
 1      5     0.50    *                    10    c4 c1 7b 10 a4 24 80 00 00 00  vmovsd	128(%r12), %xmm4
 1      5     0.50    *                    10    c4 c1 7b 10 ac 24 88 00 00 00  vmovsd	136(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 50 20                vmovsd	32(%rax), %xmm2
 1      5     0.50    *                    5     c5 fb 10 58 28                vmovsd	40(%rax), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_153
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             6     c4 c1 7b 11 46 20             vmovsd	%xmm0, 32(%r14)
 2      1     1.00           *             6     c4 c1 7b 11 4e 28             vmovsd	%xmm1, 40(%r14)
 1      5     0.50    *                    6     c4 c1 7b 10 24 24             vmovsd	(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 08          vmovsd	8(%r12), %xmm5
 1      5     0.50    *                    4     c5 fb 10 11                   vmovsd	(%rcx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 59 08                vmovsd	8(%rcx), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_156
 2      1     1.00           *             5     c4 c1 7b 11 07                vmovsd	%xmm0, (%r15)
 2      1     1.00           *             6     c4 c1 7b 11 4f 08             vmovsd	%xmm1, 8(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 10          vmovsd	16(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 18          vmovsd	24(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 51 10                vmovsd	16(%rcx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 59 18                vmovsd	24(%rcx), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_159
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             5     c4 41 7b 11 07                vmovsd	%xmm8, (%r15)
 2      1     1.00           *             6     c4 c1 7b 11 7f 08             vmovsd	%xmm7, 8(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 20          vmovsd	32(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 28          vmovsd	40(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 51 20                vmovsd	32(%rcx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 59 28                vmovsd	40(%rcx), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_162
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             5     c4 c1 7b 11 07                vmovsd	%xmm0, (%r15)
 2      1     1.00           *             6     c4 c1 7b 11 4f 08             vmovsd	%xmm1, 8(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 30          vmovsd	48(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 38          vmovsd	56(%r12), %xmm5
 1      5     0.50    *                    4     c5 fb 10 11                   vmovsd	(%rcx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 59 08                vmovsd	8(%rcx), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_165
 2      1     1.00           *             6     c4 c1 7b 11 47 10             vmovsd	%xmm0, 16(%r15)
 2      1     1.00           *             6     c4 c1 7b 11 4f 18             vmovsd	%xmm1, 24(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 40          vmovsd	64(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 48          vmovsd	72(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 51 10                vmovsd	16(%rcx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 59 18                vmovsd	24(%rcx), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_168
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             6     c4 41 7b 11 47 10             vmovsd	%xmm8, 16(%r15)
 2      1     1.00           *             6     c4 c1 7b 11 7f 18             vmovsd	%xmm7, 24(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 50          vmovsd	80(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 58          vmovsd	88(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 51 20                vmovsd	32(%rcx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 59 28                vmovsd	40(%rcx), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_171
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             6     c4 c1 7b 11 47 10             vmovsd	%xmm0, 16(%r15)
 2      1     1.00           *             6     c4 c1 7b 11 4f 18             vmovsd	%xmm1, 24(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 60          vmovsd	96(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 68          vmovsd	104(%r12), %xmm5
 1      5     0.50    *                    4     c5 fb 10 11                   vmovsd	(%rcx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 59 08                vmovsd	8(%rcx), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_174
 2      1     1.00           *             6     c4 c1 7b 11 47 20             vmovsd	%xmm0, 32(%r15)
 2      1     1.00           *             6     c4 c1 7b 11 4f 28             vmovsd	%xmm1, 40(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 70          vmovsd	112(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 78          vmovsd	120(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 51 10                vmovsd	16(%rcx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 59 18                vmovsd	24(%rcx), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_177
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             6     c4 41 7b 11 47 20             vmovsd	%xmm8, 32(%r15)
 2      1     1.00           *             6     c4 c1 7b 11 7f 28             vmovsd	%xmm7, 40(%r15)
 1      5     0.50    *                    10    c4 c1 7b 10 a4 24 80 00 00 00  vmovsd	128(%r12), %xmm4
 1      5     0.50    *                    10    c4 c1 7b 10 ac 24 88 00 00 00  vmovsd	136(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 51 20                vmovsd	32(%rcx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 59 28                vmovsd	40(%rcx), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_180
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             6     c4 c1 7b 11 47 20             vmovsd	%xmm0, 32(%r15)
 2      1     1.00           *             6     c4 c1 7b 11 4f 28             vmovsd	%xmm1, 40(%r15)
 2      9     0.50    *                    5     c4 c1 35 59 06                vmulpd	(%r14), %ymm9, %ymm0
 2      1     1.00           *             5     c4 c1 7d 11 06                vmovupd	%ymm0, (%r14)
 2      8     0.50    *                    6     c4 c1 29 59 46 20             vmulpd	32(%r14), %xmm10, %xmm0
 2      1     1.00           *             6     c4 c1 79 11 46 20             vmovupd	%xmm0, 32(%r14)
 2      9     0.50    *                    5     c4 c1 35 59 07                vmulpd	(%r15), %ymm9, %ymm0
 2      1     1.00           *             5     c4 c1 7d 11 07                vmovupd	%ymm0, (%r15)
 2      8     0.50    *                    6     c4 c1 29 59 47 20             vmulpd	32(%r15), %xmm10, %xmm0
 2      1     1.00           *             6     c4 c1 79 11 47 20             vmovupd	%xmm0, 32(%r15)
 1      1     0.25                         2     ff cb                         decl	%ebx
 1      1     0.50                         6     0f 85 00 00 00 00             jne	.LBB0_74
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_183
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_77
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_77
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_80
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    4     c5 fb 10 00                   vmovsd	(%rax), %xmm0
 1      5     0.50    *                    5     c5 fb 10 48 08                vmovsd	8(%rax), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_80
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_83
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      5     0.50    *                    4     c5 7b 10 00                   vmovsd	(%rax), %xmm8
 1      5     0.50    *                    5     c5 fb 10 78 08                vmovsd	8(%rax), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_83
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_86
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_86
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_89
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    5     c5 fb 10 40 10                vmovsd	16(%rax), %xmm0
 1      5     0.50    *                    5     c5 fb 10 48 18                vmovsd	24(%rax), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_89
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_92
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      5     0.50    *                    5     c5 7b 10 40 10                vmovsd	16(%rax), %xmm8
 1      5     0.50    *                    5     c5 fb 10 78 18                vmovsd	24(%rax), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_92
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_95
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_95
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_98
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    5     c5 fb 10 40 20                vmovsd	32(%rax), %xmm0
 1      5     0.50    *                    5     c5 fb 10 48 28                vmovsd	40(%rax), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_98
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_101
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      5     0.50    *                    5     c5 7b 10 40 20                vmovsd	32(%rax), %xmm8
 1      5     0.50    *                    5     c5 fb 10 78 28                vmovsd	40(%rax), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_101
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_104
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_104
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_107
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    4     c5 fb 10 01                   vmovsd	(%rcx), %xmm0
 1      5     0.50    *                    5     c5 fb 10 49 08                vmovsd	8(%rcx), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_107
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_110
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      5     0.50    *                    4     c5 7b 10 01                   vmovsd	(%rcx), %xmm8
 1      5     0.50    *                    5     c5 fb 10 79 08                vmovsd	8(%rcx), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_110
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_113
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_113
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_116
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    5     c5 fb 10 41 10                vmovsd	16(%rcx), %xmm0
 1      5     0.50    *                    5     c5 fb 10 49 18                vmovsd	24(%rcx), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_116
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_119
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      5     0.50    *                    5     c5 7b 10 41 10                vmovsd	16(%rcx), %xmm8
 1      5     0.50    *                    5     c5 fb 10 79 18                vmovsd	24(%rcx), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_119
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_122
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_122
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_125
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    5     c5 fb 10 41 20                vmovsd	32(%rcx), %xmm0
 1      5     0.50    *                    5     c5 fb 10 49 28                vmovsd	40(%rcx), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_125
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_128
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      5     0.50    *                    5     c5 7b 10 41 20                vmovsd	32(%rcx), %xmm8
 1      5     0.50    *                    5     c5 fb 10 79 28                vmovsd	40(%rcx), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_128
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_131
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_131
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_134
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    5     c4 c1 7b 10 06                vmovsd	(%r14), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4e 08             vmovsd	8(%r14), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_134
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_137
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      5     0.50    *                    5     c4 41 7b 10 06                vmovsd	(%r14), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7e 08             vmovsd	8(%r14), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_137
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_140
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_140
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_143
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    6     c4 c1 7b 10 46 10             vmovsd	16(%r14), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4e 18             vmovsd	24(%r14), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_143
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_146
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      5     0.50    *                    6     c4 41 7b 10 46 10             vmovsd	16(%r14), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7e 18             vmovsd	24(%r14), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_146
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_149
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_149
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_152
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    6     c4 c1 7b 10 46 20             vmovsd	32(%r14), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4e 28             vmovsd	40(%r14), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_152
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_155
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      5     0.50    *                    6     c4 41 7b 10 46 20             vmovsd	32(%r14), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7e 28             vmovsd	40(%r14), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_155
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_158
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_158
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_161
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    5     c4 c1 7b 10 07                vmovsd	(%r15), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4f 08             vmovsd	8(%r15), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_161
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_164
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      5     0.50    *                    5     c4 41 7b 10 07                vmovsd	(%r15), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7f 08             vmovsd	8(%r15), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_164
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_167
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_167
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_170
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    6     c4 c1 7b 10 47 10             vmovsd	16(%r15), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4f 18             vmovsd	24(%r15), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_170
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_173
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      5     0.50    *                    6     c4 41 7b 10 47 10             vmovsd	16(%r15), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7f 18             vmovsd	24(%r15), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_173
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_176
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_176
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_179
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    6     c4 c1 7b 10 47 20             vmovsd	32(%r15), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4f 28             vmovsd	40(%r15), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_179
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_182
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     48 8b 4c 24 08                movq	8(%rsp), %rcx
 1      5     0.50    *                    4     48 8b 04 24                   movq	(%rsp), %rax
 1      5     0.50    *                    6     c4 41 7b 10 47 20             vmovsd	32(%r15), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7f 28             vmovsd	40(%r15), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_182
 1      1     0.50                         8     48 8d bc 24 80 00 00 00       leaq	128(%rsp), %rdi
 1      0     0.25                         2     31 f6                         xorl	%esi, %esi
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	gettimeofday
 4      3     1.00                         5     e8 00 00 00 00                callq	clock
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00           *             5     48 89 44 24 10                movq	%rax, 16(%rsp)
 1      1     0.25                         5     b8 00 e1 f5 05                movl	$100000000, %eax
 1      5     0.50    *                    6     c4 c1 7b 10 24 24             vmovsd	(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 08          vmovsd	8(%r12), %xmm5
 1      5     0.50    *                    5     c4 c1 7b 10 16                vmovsd	(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 08             vmovsd	8(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_185
 2      1     1.00           *             4     c5 fb 11 03                   vmovsd	%xmm0, (%rbx)
 2      1     1.00           *             5     c5 fb 11 4b 08                vmovsd	%xmm1, 8(%rbx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 10          vmovsd	16(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 18          vmovsd	24(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 10             vmovsd	16(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 18             vmovsd	24(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_188
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             4     c5 7b 11 03                   vmovsd	%xmm8, (%rbx)
 2      1     1.00           *             5     c5 fb 11 7b 08                vmovsd	%xmm7, 8(%rbx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 20          vmovsd	32(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 28          vmovsd	40(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 20             vmovsd	32(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 28             vmovsd	40(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_191
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             4     c5 fb 11 03                   vmovsd	%xmm0, (%rbx)
 2      1     1.00           *             5     c5 fb 11 4b 08                vmovsd	%xmm1, 8(%rbx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 30          vmovsd	48(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 38          vmovsd	56(%r12), %xmm5
 1      5     0.50    *                    5     c4 c1 7b 10 16                vmovsd	(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 08             vmovsd	8(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_194
 2      1     1.00           *             5     c5 fb 11 43 10                vmovsd	%xmm0, 16(%rbx)
 2      1     1.00           *             5     c5 fb 11 4b 18                vmovsd	%xmm1, 24(%rbx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 40          vmovsd	64(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 48          vmovsd	72(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 10             vmovsd	16(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 18             vmovsd	24(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_197
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             5     c5 7b 11 43 10                vmovsd	%xmm8, 16(%rbx)
 2      1     1.00           *             5     c5 fb 11 7b 18                vmovsd	%xmm7, 24(%rbx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 50          vmovsd	80(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 58          vmovsd	88(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 20             vmovsd	32(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 28             vmovsd	40(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_200
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             5     c5 fb 11 43 10                vmovsd	%xmm0, 16(%rbx)
 2      1     1.00           *             5     c5 fb 11 4b 18                vmovsd	%xmm1, 24(%rbx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 60          vmovsd	96(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 68          vmovsd	104(%r12), %xmm5
 1      5     0.50    *                    5     c4 c1 7b 10 16                vmovsd	(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 08             vmovsd	8(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_203
 2      1     1.00           *             5     c5 fb 11 43 20                vmovsd	%xmm0, 32(%rbx)
 2      1     1.00           *             5     c5 fb 11 4b 28                vmovsd	%xmm1, 40(%rbx)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 70          vmovsd	112(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 78          vmovsd	120(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 10             vmovsd	16(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 18             vmovsd	24(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_206
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             5     c5 7b 11 43 20                vmovsd	%xmm8, 32(%rbx)
 2      1     1.00           *             5     c5 fb 11 7b 28                vmovsd	%xmm7, 40(%rbx)
 1      5     0.50    *                    10    c4 c1 7b 10 a4 24 80 00 00 00  vmovsd	128(%r12), %xmm4
 1      5     0.50    *                    10    c4 c1 7b 10 ac 24 88 00 00 00  vmovsd	136(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 56 20             vmovsd	32(%r14), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5e 28             vmovsd	40(%r14), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_209
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             5     c5 fb 11 43 20                vmovsd	%xmm0, 32(%rbx)
 2      1     1.00           *             5     c5 fb 11 4b 28                vmovsd	%xmm1, 40(%rbx)
 1      5     0.50    *                    6     c4 c1 7b 10 24 24             vmovsd	(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 08          vmovsd	8(%r12), %xmm5
 1      5     0.50    *                    5     c4 c1 7b 10 17                vmovsd	(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 08             vmovsd	8(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_212
 2      1     1.00           *             6     c4 c1 7b 11 45 00             vmovsd	%xmm0, (%r13)
 2      1     1.00           *             6     c4 c1 7b 11 4d 08             vmovsd	%xmm1, 8(%r13)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 10          vmovsd	16(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 18          vmovsd	24(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 10             vmovsd	16(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 18             vmovsd	24(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_215
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             6     c4 41 7b 11 45 00             vmovsd	%xmm8, (%r13)
 2      1     1.00           *             6     c4 c1 7b 11 7d 08             vmovsd	%xmm7, 8(%r13)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 20          vmovsd	32(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 28          vmovsd	40(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 20             vmovsd	32(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 28             vmovsd	40(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_218
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             6     c4 c1 7b 11 45 00             vmovsd	%xmm0, (%r13)
 2      1     1.00           *             6     c4 c1 7b 11 4d 08             vmovsd	%xmm1, 8(%r13)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 30          vmovsd	48(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 38          vmovsd	56(%r12), %xmm5
 1      5     0.50    *                    5     c4 c1 7b 10 17                vmovsd	(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 08             vmovsd	8(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_221
 2      1     1.00           *             6     c4 c1 7b 11 45 10             vmovsd	%xmm0, 16(%r13)
 2      1     1.00           *             6     c4 c1 7b 11 4d 18             vmovsd	%xmm1, 24(%r13)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 40          vmovsd	64(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 48          vmovsd	72(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 10             vmovsd	16(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 18             vmovsd	24(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_224
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             6     c4 41 7b 11 45 10             vmovsd	%xmm8, 16(%r13)
 2      1     1.00           *             6     c4 c1 7b 11 7d 18             vmovsd	%xmm7, 24(%r13)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 50          vmovsd	80(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 58          vmovsd	88(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 20             vmovsd	32(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 28             vmovsd	40(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_227
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             6     c4 c1 7b 11 45 10             vmovsd	%xmm0, 16(%r13)
 2      1     1.00           *             6     c4 c1 7b 11 4d 18             vmovsd	%xmm1, 24(%r13)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 60          vmovsd	96(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 68          vmovsd	104(%r12), %xmm5
 1      5     0.50    *                    5     c4 c1 7b 10 17                vmovsd	(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 08             vmovsd	8(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_230
 2      1     1.00           *             6     c4 c1 7b 11 45 20             vmovsd	%xmm0, 32(%r13)
 2      1     1.00           *             6     c4 c1 7b 11 4d 28             vmovsd	%xmm1, 40(%r13)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 70          vmovsd	112(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 78          vmovsd	120(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 10             vmovsd	16(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 18             vmovsd	24(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_233
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             6     c4 41 7b 11 45 20             vmovsd	%xmm8, 32(%r13)
 2      1     1.00           *             6     c4 c1 7b 11 7d 28             vmovsd	%xmm7, 40(%r13)
 1      5     0.50    *                    10    c4 c1 7b 10 a4 24 80 00 00 00  vmovsd	128(%r12), %xmm4
 1      5     0.50    *                    10    c4 c1 7b 10 ac 24 88 00 00 00  vmovsd	136(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 57 20             vmovsd	32(%r15), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5f 28             vmovsd	40(%r15), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_236
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             6     c4 c1 7b 11 45 20             vmovsd	%xmm0, 32(%r13)
 2      1     1.00           *             6     c4 c1 7b 11 4d 28             vmovsd	%xmm1, 40(%r13)
 1      5     0.50    *                    6     c4 c1 7b 10 24 24             vmovsd	(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 08          vmovsd	8(%r12), %xmm5
 1      5     0.50    *                    4     c5 fb 10 13                   vmovsd	(%rbx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 5b 08                vmovsd	8(%rbx), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_239
 2      1     1.00           *             5     c4 c1 7b 11 06                vmovsd	%xmm0, (%r14)
 2      1     1.00           *             6     c4 c1 7b 11 4e 08             vmovsd	%xmm1, 8(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 10          vmovsd	16(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 18          vmovsd	24(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 53 10                vmovsd	16(%rbx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 5b 18                vmovsd	24(%rbx), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_242
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             5     c4 41 7b 11 06                vmovsd	%xmm8, (%r14)
 2      1     1.00           *             6     c4 c1 7b 11 7e 08             vmovsd	%xmm7, 8(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 20          vmovsd	32(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 28          vmovsd	40(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 53 20                vmovsd	32(%rbx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 5b 28                vmovsd	40(%rbx), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_245
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             5     c4 c1 7b 11 06                vmovsd	%xmm0, (%r14)
 2      1     1.00           *             6     c4 c1 7b 11 4e 08             vmovsd	%xmm1, 8(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 30          vmovsd	48(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 38          vmovsd	56(%r12), %xmm5
 1      5     0.50    *                    4     c5 fb 10 13                   vmovsd	(%rbx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 5b 08                vmovsd	8(%rbx), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_248
 2      1     1.00           *             6     c4 c1 7b 11 46 10             vmovsd	%xmm0, 16(%r14)
 2      1     1.00           *             6     c4 c1 7b 11 4e 18             vmovsd	%xmm1, 24(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 40          vmovsd	64(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 48          vmovsd	72(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 53 10                vmovsd	16(%rbx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 5b 18                vmovsd	24(%rbx), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_251
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             6     c4 41 7b 11 46 10             vmovsd	%xmm8, 16(%r14)
 2      1     1.00           *             6     c4 c1 7b 11 7e 18             vmovsd	%xmm7, 24(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 50          vmovsd	80(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 58          vmovsd	88(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 53 20                vmovsd	32(%rbx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 5b 28                vmovsd	40(%rbx), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_254
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             6     c4 c1 7b 11 46 10             vmovsd	%xmm0, 16(%r14)
 2      1     1.00           *             6     c4 c1 7b 11 4e 18             vmovsd	%xmm1, 24(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 60          vmovsd	96(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 68          vmovsd	104(%r12), %xmm5
 1      5     0.50    *                    4     c5 fb 10 13                   vmovsd	(%rbx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 5b 08                vmovsd	8(%rbx), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_257
 2      1     1.00           *             6     c4 c1 7b 11 46 20             vmovsd	%xmm0, 32(%r14)
 2      1     1.00           *             6     c4 c1 7b 11 4e 28             vmovsd	%xmm1, 40(%r14)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 70          vmovsd	112(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 78          vmovsd	120(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 53 10                vmovsd	16(%rbx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 5b 18                vmovsd	24(%rbx), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_260
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             6     c4 41 7b 11 46 20             vmovsd	%xmm8, 32(%r14)
 2      1     1.00           *             6     c4 c1 7b 11 7e 28             vmovsd	%xmm7, 40(%r14)
 1      5     0.50    *                    10    c4 c1 7b 10 a4 24 80 00 00 00  vmovsd	128(%r12), %xmm4
 1      5     0.50    *                    10    c4 c1 7b 10 ac 24 88 00 00 00  vmovsd	136(%r12), %xmm5
 1      5     0.50    *                    5     c5 fb 10 53 20                vmovsd	32(%rbx), %xmm2
 1      5     0.50    *                    5     c5 fb 10 5b 28                vmovsd	40(%rbx), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_263
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             6     c4 c1 7b 11 46 20             vmovsd	%xmm0, 32(%r14)
 2      1     1.00           *             6     c4 c1 7b 11 4e 28             vmovsd	%xmm1, 40(%r14)
 1      5     0.50    *                    6     c4 c1 7b 10 24 24             vmovsd	(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 08          vmovsd	8(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 55 00             vmovsd	(%r13), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5d 08             vmovsd	8(%r13), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_266
 2      1     1.00           *             5     c4 c1 7b 11 07                vmovsd	%xmm0, (%r15)
 2      1     1.00           *             6     c4 c1 7b 11 4f 08             vmovsd	%xmm1, 8(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 10          vmovsd	16(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 18          vmovsd	24(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 55 10             vmovsd	16(%r13), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5d 18             vmovsd	24(%r13), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_269
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             5     c4 41 7b 11 07                vmovsd	%xmm8, (%r15)
 2      1     1.00           *             6     c4 c1 7b 11 7f 08             vmovsd	%xmm7, 8(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 20          vmovsd	32(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 28          vmovsd	40(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 55 20             vmovsd	32(%r13), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5d 28             vmovsd	40(%r13), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_272
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             5     c4 c1 7b 11 07                vmovsd	%xmm0, (%r15)
 2      1     1.00           *             6     c4 c1 7b 11 4f 08             vmovsd	%xmm1, 8(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 30          vmovsd	48(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 38          vmovsd	56(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 55 00             vmovsd	(%r13), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5d 08             vmovsd	8(%r13), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_275
 2      1     1.00           *             6     c4 c1 7b 11 47 10             vmovsd	%xmm0, 16(%r15)
 2      1     1.00           *             6     c4 c1 7b 11 4f 18             vmovsd	%xmm1, 24(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 40          vmovsd	64(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 48          vmovsd	72(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 55 10             vmovsd	16(%r13), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5d 18             vmovsd	24(%r13), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_278
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             6     c4 41 7b 11 47 10             vmovsd	%xmm8, 16(%r15)
 2      1     1.00           *             6     c4 c1 7b 11 7f 18             vmovsd	%xmm7, 24(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 50          vmovsd	80(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 58          vmovsd	88(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 55 20             vmovsd	32(%r13), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5d 28             vmovsd	40(%r13), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_281
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             6     c4 c1 7b 11 47 10             vmovsd	%xmm0, 16(%r15)
 2      1     1.00           *             6     c4 c1 7b 11 4f 18             vmovsd	%xmm1, 24(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 60          vmovsd	96(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 68          vmovsd	104(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 55 00             vmovsd	(%r13), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5d 08             vmovsd	8(%r13), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_284
 2      1     1.00           *             6     c4 c1 7b 11 47 20             vmovsd	%xmm0, 32(%r15)
 2      1     1.00           *             6     c4 c1 7b 11 4f 28             vmovsd	%xmm1, 40(%r15)
 1      5     0.50    *                    7     c4 c1 7b 10 64 24 70          vmovsd	112(%r12), %xmm4
 1      5     0.50    *                    7     c4 c1 7b 10 6c 24 78          vmovsd	120(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 55 10             vmovsd	16(%r13), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5d 18             vmovsd	24(%r13), %xmm3
 1      3     0.50                         4     c5 db 59 f2                   vmulsd	%xmm2, %xmm4, %xmm6
 1      3     0.50                         4     c5 d3 59 fb                   vmulsd	%xmm3, %xmm5, %xmm7
 1      3     1.00                         4     c5 4b 5c c7                   vsubsd	%xmm7, %xmm6, %xmm8
 1      3     0.50                         4     c5 db 59 fb                   vmulsd	%xmm3, %xmm4, %xmm7
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 ff                   vaddsd	%xmm7, %xmm6, %xmm7
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_287
 1      3     1.00                         4     c5 c3 58 f9                   vaddsd	%xmm1, %xmm7, %xmm7
 1      3     1.00                         4     c5 3b 58 c0                   vaddsd	%xmm0, %xmm8, %xmm8
 2      1     1.00           *             6     c4 41 7b 11 47 20             vmovsd	%xmm8, 32(%r15)
 2      1     1.00           *             6     c4 c1 7b 11 7f 28             vmovsd	%xmm7, 40(%r15)
 1      5     0.50    *                    10    c4 c1 7b 10 a4 24 80 00 00 00  vmovsd	128(%r12), %xmm4
 1      5     0.50    *                    10    c4 c1 7b 10 ac 24 88 00 00 00  vmovsd	136(%r12), %xmm5
 1      5     0.50    *                    6     c4 c1 7b 10 55 20             vmovsd	32(%r13), %xmm2
 1      5     0.50    *                    6     c4 c1 7b 10 5d 28             vmovsd	40(%r13), %xmm3
 1      3     0.50                         4     c5 db 59 c2                   vmulsd	%xmm2, %xmm4, %xmm0
 1      3     0.50                         4     c5 d3 59 cb                   vmulsd	%xmm3, %xmm5, %xmm1
 1      3     1.00                         4     c5 fb 5c c1                   vsubsd	%xmm1, %xmm0, %xmm0
 1      3     0.50                         4     c5 db 59 cb                   vmulsd	%xmm3, %xmm4, %xmm1
 1      3     0.50                         4     c5 d3 59 f2                   vmulsd	%xmm2, %xmm5, %xmm6
 1      3     1.00                         4     c5 cb 58 c9                   vaddsd	%xmm1, %xmm6, %xmm1
 1      3     1.00                         4     c5 f9 2e c0                   vucomisd	%xmm0, %xmm0
 1      1     0.50                         6     0f 8a 00 00 00 00             jp	.LBB0_290
 1      3     1.00                         4     c5 f3 58 cf                   vaddsd	%xmm7, %xmm1, %xmm1
 1      3     1.00                         4     c5 bb 58 c0                   vaddsd	%xmm0, %xmm8, %xmm0
 2      1     1.00           *             6     c4 c1 7b 11 47 20             vmovsd	%xmm0, 32(%r15)
 2      1     1.00           *             6     c4 c1 7b 11 4f 28             vmovsd	%xmm1, 40(%r15)
 2      9     0.50    *                    5     c4 c1 35 59 06                vmulpd	(%r14), %ymm9, %ymm0
 2      1     1.00           *             5     c4 c1 7d 11 06                vmovupd	%ymm0, (%r14)
 2      8     0.50    *                    6     c4 c1 29 59 46 20             vmulpd	32(%r14), %xmm10, %xmm0
 2      1     1.00           *             6     c4 c1 79 11 46 20             vmovupd	%xmm0, 32(%r14)
 2      9     0.50    *                    5     c4 c1 35 59 07                vmulpd	(%r15), %ymm9, %ymm0
 2      1     1.00           *             5     c4 c1 7d 11 07                vmovupd	%ymm0, (%r15)
 2      8     0.50    *                    6     c4 c1 29 59 47 20             vmulpd	32(%r15), %xmm10, %xmm0
 2      1     1.00           *             6     c4 c1 79 11 47 20             vmovupd	%xmm0, 32(%r15)
 1      1     0.25                         2     ff c8                         decl	%eax
 1      1     0.50                         6     0f 85 00 00 00 00             jne	.LBB0_184
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_293
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_187
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_187
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_190
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    4     c5 fb 10 03                   vmovsd	(%rbx), %xmm0
 1      5     0.50    *                    5     c5 fb 10 4b 08                vmovsd	8(%rbx), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_190
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_193
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      5     0.50    *                    4     c5 7b 10 03                   vmovsd	(%rbx), %xmm8
 1      5     0.50    *                    5     c5 fb 10 7b 08                vmovsd	8(%rbx), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_193
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_196
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_196
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_199
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    5     c5 fb 10 43 10                vmovsd	16(%rbx), %xmm0
 1      5     0.50    *                    5     c5 fb 10 4b 18                vmovsd	24(%rbx), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_199
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_202
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      5     0.50    *                    5     c5 7b 10 43 10                vmovsd	16(%rbx), %xmm8
 1      5     0.50    *                    5     c5 fb 10 7b 18                vmovsd	24(%rbx), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_202
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_205
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_205
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_208
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    5     c5 fb 10 43 20                vmovsd	32(%rbx), %xmm0
 1      5     0.50    *                    5     c5 fb 10 4b 28                vmovsd	40(%rbx), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_208
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_211
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      5     0.50    *                    5     c5 7b 10 43 20                vmovsd	32(%rbx), %xmm8
 1      5     0.50    *                    5     c5 fb 10 7b 28                vmovsd	40(%rbx), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_211
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_214
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_214
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_217
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    6     c4 c1 7b 10 45 00             vmovsd	(%r13), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4d 08             vmovsd	8(%r13), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_217
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_220
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      5     0.50    *                    6     c4 41 7b 10 45 00             vmovsd	(%r13), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7d 08             vmovsd	8(%r13), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_220
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_223
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_223
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_226
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    6     c4 c1 7b 10 45 10             vmovsd	16(%r13), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4d 18             vmovsd	24(%r13), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_226
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_229
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      5     0.50    *                    6     c4 41 7b 10 45 10             vmovsd	16(%r13), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7d 18             vmovsd	24(%r13), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_229
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_232
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_232
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_235
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    6     c4 c1 7b 10 45 20             vmovsd	32(%r13), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4d 28             vmovsd	40(%r13), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_235
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_238
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      5     0.50    *                    6     c4 41 7b 10 45 20             vmovsd	32(%r13), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7d 28             vmovsd	40(%r13), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_238
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_241
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_241
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_244
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    5     c4 c1 7b 10 06                vmovsd	(%r14), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4e 08             vmovsd	8(%r14), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_244
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_247
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      5     0.50    *                    5     c4 41 7b 10 06                vmovsd	(%r14), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7e 08             vmovsd	8(%r14), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_247
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_250
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_250
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_253
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    6     c4 c1 7b 10 46 10             vmovsd	16(%r14), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4e 18             vmovsd	24(%r14), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_253
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_256
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      5     0.50    *                    6     c4 41 7b 10 46 10             vmovsd	16(%r14), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7e 18             vmovsd	24(%r14), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_256
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_259
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_259
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_262
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    6     c4 c1 7b 10 46 20             vmovsd	32(%r14), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4e 28             vmovsd	40(%r14), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_262
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_265
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      5     0.50    *                    6     c4 41 7b 10 46 20             vmovsd	32(%r14), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7e 28             vmovsd	40(%r14), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_265
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_268
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_268
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_271
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    5     c4 c1 7b 10 07                vmovsd	(%r15), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4f 08             vmovsd	8(%r15), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_271
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_274
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      5     0.50    *                    5     c4 41 7b 10 07                vmovsd	(%r15), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7f 08             vmovsd	8(%r15), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_274
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_277
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_277
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_280
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    6     c4 c1 7b 10 47 10             vmovsd	16(%r15), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4f 18             vmovsd	24(%r15), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_280
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_283
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      5     0.50    *                    6     c4 41 7b 10 47 10             vmovsd	16(%r15), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7f 18             vmovsd	24(%r15), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_283
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_286
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_286
 1      3     1.00                         4     c5 f9 2e ff                   vucomisd	%xmm7, %xmm7
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_289
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      1     1.00                         4     c5 79 28 c0                   vmovapd	%xmm0, %xmm8
 1      1     1.00                         4     c5 f9 28 f9                   vmovapd	%xmm1, %xmm7
 1      5     0.50    *                    6     c4 c1 7b 10 47 20             vmovsd	32(%r15), %xmm0
 1      5     0.50    *                    6     c4 c1 7b 10 4f 28             vmovsd	40(%r15), %xmm1
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_289
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_292
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 1      1     0.25                         2     89 c3                         movl	%eax, %ebx
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      1     0.25                         2     89 d8                         movl	%ebx, %eax
 1      5     0.50    *                    8     c5 79 28 15 00 00 00 00       vmovapd	.LCPI0_12(%rip), %xmm10
 1      6     0.50    *                    6     c5 7d 28 4c 24 20             vmovapd	32(%rsp), %ymm9
 1      5     0.50    *                    5     4c 8b 6c 24 08                movq	8(%rsp), %r13
 1      5     0.50    *                    4     48 8b 1c 24                   movq	(%rsp), %rbx
 1      5     0.50    *                    6     c4 41 7b 10 47 20             vmovsd	32(%r15), %xmm8
 1      5     0.50    *                    6     c4 c1 7b 10 7f 28             vmovsd	40(%r15), %xmm7
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_292
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	clock
 1      1     0.25                         3     49 89 c5                      movq	%rax, %r13
 1      1     0.50                         8     48 8d 9c 24 b8 00 00 00       leaq	184(%rsp), %rbx
 1      1     0.25                         3     48 89 df                      movq	%rbx, %rdi
 1      0     0.25                         2     31 f6                         xorl	%esi, %esi
 4      3     1.00                         5     e8 00 00 00 00                callq	gettimeofday
 1      1     0.50                         5     48 8d 7c 24 68                leaq	104(%rsp), %rdi
 1      1     0.50                         8     48 8d 94 24 80 00 00 00       leaq	128(%rsp), %rdx
 1      1     0.25                         3     48 89 de                      movq	%rbx, %rsi
 4      3     1.00                         5     e8 00 00 00 00                callq	timeval_subtract
 2      6     0.50    *                    5     4c 2b 6c 24 10                subq	16(%rsp), %r13
 2      4     1.00                         5     c4 c1 a3 2a c5                vcvtsi2sd	%r13, %xmm11, %xmm0
 2      19    8.00    *                    8     c5 fb 5e 05 00 00 00 00       vdivsd	.LCPI0_13(%rip), %xmm0, %xmm0
 1      1     0.25                         5     bf 00 00 00 00                movl	$.L.str.11, %edi
 1      1     0.25                         5     ba 00 00 00 00                movl	$.L.str.7, %edx
 1      0     0.25                         2     31 f6                         xorl	%esi, %esi
 1      1     0.25                         2     b0 01                         movb	$1, %al
 4      3     1.00                         5     e8 00 00 00 00                callq	lprintf
 2      9     1.00    *                    7     c4 e1 a3 2a 4c 24 68          vcvtsi2sdq	104(%rsp), %xmm11, %xmm1
 2      9     1.00    *                    7     c4 e1 a3 2a 44 24 70          vcvtsi2sdq	112(%rsp), %xmm11, %xmm0
 2      10    0.50    *                    9     c4 e2 f1 99 05 00 00 00 00    vfmadd132sd	.LCPI0_14(%rip), %xmm1, %xmm0
 1      1     0.25                         5     bf 00 00 00 00                movl	$.L.str.11, %edi
 1      1     0.25                         5     ba 00 00 00 00                movl	$.L.str.8, %edx
 1      0     0.25                         2     31 f6                         xorl	%esi, %esi
 1      1     0.25                         2     b0 01                         movb	$1, %al
 4      3     1.00                         5     e8 00 00 00 00                callq	lprintf
 1      1     0.25                         3     4c 89 e7                      movq	%r12, %rdi
 4      3     1.00                         5     e8 00 00 00 00                callq	afree
 1      1     0.25                         3     4c 89 f7                      movq	%r14, %rdi
 4      3     1.00                         5     e8 00 00 00 00                callq	afree
 1      1     0.25                         3     4c 89 ff                      movq	%r15, %rdi
 4      3     1.00                         5     e8 00 00 00 00                callq	afree
 1      5     0.50    *                    4     48 8b 3c 24                   movq	(%rsp), %rdi
 4      3     1.00                         5     e8 00 00 00 00                callq	afree
 1      5     0.50    *                    5     48 8b 7c 24 08                movq	8(%rsp), %rdi
 4      3     1.00                         5     e8 00 00 00 00                callq	afree
 1      0     0.25                         2     31 c0                         xorl	%eax, %eax
 1      1     0.50                         4     48 8d 65 d8                   leaq	-40(%rbp), %rsp
 2      6     0.50    *                    1     5b                            popq	%rbx
 2      6     0.50    *                    2     41 5c                         popq	%r12
 2      6     0.50    *                    2     41 5d                         popq	%r13
 2      6     0.50    *                    2     41 5e                         popq	%r14
 2      6     0.50    *                    2     41 5f                         popq	%r15
 2      6     0.50    *                    1     5d                            popq	%rbp
 3      7     1.00                  U      1     c3                            retq
 1      3     1.00                         5     c4 41 79 2e c0                vucomisd	%xmm8, %xmm8
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_3
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     1.00                         4     c5 f9 28 f8                   vmovapd	%xmm0, %xmm7
 1      1     1.00                         4     c5 79 28 c1                   vmovapd	%xmm1, %xmm8
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_3
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_6
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 2      1     1.00           *             6     c5 fb 11 7c 24 20             vmovsd	%xmm7, 32(%rsp)
 2      1     1.00           *             6     c5 7b 11 44 24 10             vmovsd	%xmm8, 16(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 7b 10 44 24 10             vmovsd	16(%rsp), %xmm8
 1      5     0.50    *                    6     c5 fb 10 7c 24 20             vmovsd	32(%rsp), %xmm7
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_6
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_9
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 2      1     1.00           *             6     c5 fb 11 7c 24 20             vmovsd	%xmm7, 32(%rsp)
 2      1     1.00           *             6     c5 7b 11 44 24 10             vmovsd	%xmm8, 16(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 7b 10 44 24 10             vmovsd	16(%rsp), %xmm8
 1      5     0.50    *                    6     c5 fb 10 7c 24 20             vmovsd	32(%rsp), %xmm7
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_9
 1      3     1.00                         5     c4 41 79 2e d2                vucomisd	%xmm10, %xmm10
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_12
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     1.00                         4     c5 79 28 c8                   vmovapd	%xmm0, %xmm9
 1      1     1.00                         4     c5 79 28 d1                   vmovapd	%xmm1, %xmm10
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_12
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_15
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 2      1     1.00           *             6     c5 7b 11 4c 24 20             vmovsd	%xmm9, 32(%rsp)
 2      1     1.00           *             6     c5 7b 11 54 24 50             vmovsd	%xmm10, 80(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 7b 10 54 24 50             vmovsd	80(%rsp), %xmm10
 1      5     0.50    *                    6     c5 7b 10 4c 24 20             vmovsd	32(%rsp), %xmm9
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_15
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_18
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 2      1     1.00           *             6     c5 7b 11 4c 24 20             vmovsd	%xmm9, 32(%rsp)
 2      1     1.00           *             6     c5 7b 11 54 24 50             vmovsd	%xmm10, 80(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 7b 10 54 24 50             vmovsd	80(%rsp), %xmm10
 1      5     0.50    *                    6     c5 7b 10 4c 24 20             vmovsd	32(%rsp), %xmm9
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_18
 1      3     1.00                         5     c4 41 79 2e d2                vucomisd	%xmm10, %xmm10
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_21
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     1.00                         4     c5 79 28 c8                   vmovapd	%xmm0, %xmm9
 1      1     1.00                         4     c5 79 28 d1                   vmovapd	%xmm1, %xmm10
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_21
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_24
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 2      1     1.00           *             6     c5 7b 11 4c 24 20             vmovsd	%xmm9, 32(%rsp)
 2      1     1.00           *             6     c5 7b 11 54 24 50             vmovsd	%xmm10, 80(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 7b 10 54 24 50             vmovsd	80(%rsp), %xmm10
 1      5     0.50    *                    6     c5 7b 10 4c 24 20             vmovsd	32(%rsp), %xmm9
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_24
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_27
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 2      1     1.00           *             6     c5 7b 11 4c 24 20             vmovsd	%xmm9, 32(%rsp)
 2      1     1.00           *             6     c5 7b 11 54 24 50             vmovsd	%xmm10, 80(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 7b 10 54 24 50             vmovsd	80(%rsp), %xmm10
 1      5     0.50    *                    6     c5 7b 10 4c 24 20             vmovsd	32(%rsp), %xmm9
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_27
 1      3     1.00                         5     c4 41 79 2e d2                vucomisd	%xmm10, %xmm10
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_30
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     1.00                         4     c5 79 28 c8                   vmovapd	%xmm0, %xmm9
 1      1     1.00                         4     c5 79 28 d1                   vmovapd	%xmm1, %xmm10
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_30
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_33
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 2      1     1.00           *             6     c5 7b 11 4c 24 20             vmovsd	%xmm9, 32(%rsp)
 2      1     1.00           *             6     c5 7b 11 54 24 50             vmovsd	%xmm10, 80(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 7b 10 54 24 50             vmovsd	80(%rsp), %xmm10
 1      5     0.50    *                    6     c5 7b 10 4c 24 20             vmovsd	32(%rsp), %xmm9
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_33
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_36
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 2      1     1.00           *             6     c5 7b 11 4c 24 20             vmovsd	%xmm9, 32(%rsp)
 2      1     1.00           *             6     c5 7b 11 54 24 50             vmovsd	%xmm10, 80(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 7b 10 54 24 50             vmovsd	80(%rsp), %xmm10
 1      5     0.50    *                    6     c5 7b 10 4c 24 20             vmovsd	32(%rsp), %xmm9
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_36
 1      3     1.00                         5     c4 41 79 2e d2                vucomisd	%xmm10, %xmm10
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_39
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     1.00                         4     c5 79 28 c8                   vmovapd	%xmm0, %xmm9
 1      1     1.00                         4     c5 79 28 d1                   vmovapd	%xmm1, %xmm10
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_39
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_42
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 2      1     1.00           *             6     c5 7b 11 4c 24 60             vmovsd	%xmm9, 96(%rsp)
 2      1     1.00           *             6     c5 7b 11 54 24 58             vmovsd	%xmm10, 88(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 7b 10 54 24 58             vmovsd	88(%rsp), %xmm10
 1      5     0.50    *                    6     c5 7b 10 4c 24 60             vmovsd	96(%rsp), %xmm9
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_42
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_45
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 2      1     1.00           *             6     c5 7b 11 4c 24 60             vmovsd	%xmm9, 96(%rsp)
 2      1     1.00           *             6     c5 7b 11 54 24 58             vmovsd	%xmm10, 88(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 7b 10 54 24 58             vmovsd	88(%rsp), %xmm10
 1      5     0.50    *                    6     c5 7b 10 4c 24 60             vmovsd	96(%rsp), %xmm9
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_45
 1      3     1.00                         5     c4 41 79 2e d2                vucomisd	%xmm10, %xmm10
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_48
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     1.00                         4     c5 79 28 c8                   vmovapd	%xmm0, %xmm9
 1      1     1.00                         4     c5 79 28 d1                   vmovapd	%xmm1, %xmm10
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_48
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_51
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 2      1     1.00           *             6     c5 7b 11 4c 24 60             vmovsd	%xmm9, 96(%rsp)
 2      1     1.00           *             6     c5 7b 11 54 24 58             vmovsd	%xmm10, 88(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 7b 10 54 24 58             vmovsd	88(%rsp), %xmm10
 1      5     0.50    *                    6     c5 7b 10 4c 24 60             vmovsd	96(%rsp), %xmm9
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_51
 1      3     1.00                         4     c5 f9 2e c9                   vucomisd	%xmm1, %xmm1
 1      1     0.50                         6     0f 8b 00 00 00 00             jnp	.LBB0_54
 1      1     1.00                         4     c5 f9 28 c4                   vmovapd	%xmm4, %xmm0
 1      1     1.00                         4     c5 f9 28 cd                   vmovapd	%xmm5, %xmm1
 2      1     1.00           *             6     c5 7b 11 44 24 18             vmovsd	%xmm8, 24(%rsp)
 2      1     1.00           *             6     c5 fb 11 7c 24 10             vmovsd	%xmm7, 16(%rsp)
 2      1     1.00           *             6     c5 7b 11 4c 24 60             vmovsd	%xmm9, 96(%rsp)
 2      1     1.00           *             6     c5 7b 11 54 24 58             vmovsd	%xmm10, 88(%rsp)
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 4      3     1.00                         5     e8 00 00 00 00                callq	__muldc3
 1      5     0.50    *                    6     c5 7b 10 54 24 58             vmovsd	88(%rsp), %xmm10
 1      5     0.50    *                    6     c5 7b 10 4c 24 60             vmovsd	96(%rsp), %xmm9
 1      5     0.50    *                    6     c5 fb 10 7c 24 10             vmovsd	16(%rsp), %xmm7
 1      5     0.50    *                    6     c5 7b 10 44 24 18             vmovsd	24(%rsp), %xmm8
 1      5     0.50    *                    5     48 8b 54 24 08                movq	8(%rsp), %rdx
 1      5     0.50    *                    4     48 8b 0c 24                   movq	(%rsp), %rcx
 1      1     0.50                         5     e9 00 00 00 00                jmp	.LBB0_54
 3      2     1.00           *             1     55                            pushq	%rbp
 1      1     0.25                         3     48 89 e5                      movq	%rsp, %rbp
 1      6     0.50    *                    4     c5 fd 28 02                   vmovapd	(%rdx), %ymm0
 1      1     1.00                         4     c5 7f 12 c0                   vmovddup	%ymm0, %ymm8
 1      1     1.00                         6     c4 63 7d 05 d0 0f             vpermilpd	$15, %ymm0, %ymm10
 1      6     0.50    *                    5     c5 fd 10 42 30                vmovupd	48(%rdx), %ymm0
 1      1     1.00                         4     c5 7f 12 c8                   vmovddup	%ymm0, %ymm9
 1      1     1.00                         6     c4 63 7d 05 d8 0f             vpermilpd	$15, %ymm0, %ymm11
 1      6     0.50    *                    5     c5 fd 28 4a 60                vmovapd	96(%rdx), %ymm1
 1      1     1.00                         4     c5 ff 12 c1                   vmovddup	%ymm1, %ymm0
 1      1     1.00                         6     c4 e3 7d 05 c9 0f             vpermilpd	$15, %ymm1, %ymm1
 1      6     0.50    *                    4     c5 fd 28 19                   vmovapd	(%rcx), %ymm3
 1      1     1.00                         6     c4 e3 7d 05 eb 05             vpermilpd	$5, %ymm3, %ymm5
 1      6     0.50    *                    5     c4 c1 7d 28 10                vmovapd	(%r8), %ymm2
 1      1     1.00                         6     c4 e3 7d 05 e2 05             vpermilpd	$5, %ymm2, %ymm4
 1      3     0.50                         4     c5 ad 59 f5                   vmulpd	%ymm5, %ymm10, %ymm6
 1      5     0.50                         5     c4 e2 bd b6 f3                vfmaddsub231pd	%ymm3, %ymm8, %ymm6
 1      3     0.50                         4     c5 a5 59 fd                   vmulpd	%ymm5, %ymm11, %ymm7
 1      5     0.50                         5     c4 e2 b5 b6 fb                vfmaddsub231pd	%ymm3, %ymm9, %ymm7
 1      3     1.00                         6     c4 63 4d 18 e7 01             vinsertf128	$1, %xmm7, %ymm6, %ymm12
 1      3     1.00                         6     c4 e3 4d 06 f7 31             vperm2f128	$49, %ymm7, %ymm6, %ymm6
 1      6     0.50    *                    5     c5 fd 10 7a 10                vmovupd	16(%rdx), %ymm7
 2      9     1.00    *                    7     c4 e3 45 06 7a 40 31          vperm2f128	$49, 64(%rdx), %ymm7, %ymm7
 1      3     1.00                         4     c5 1d 58 e6                   vaddpd	%ymm6, %ymm12, %ymm12
 1      6     0.50    *                    5     c5 fd 10 71 10                vmovupd	16(%rcx), %ymm6
 1      3     1.00                         6     c4 63 fd 01 ee ee             vpermpd	$238, %ymm6, %ymm13
 1      1     1.00                         4     c5 7f 12 f7                   vmovddup	%ymm7, %ymm14
 1      1     1.00                         6     c4 63 7d 05 ff 0f             vpermilpd	$15, %ymm7, %ymm15
 1      3     1.00                         6     c4 e3 fd 01 fe bb             vpermpd	$187, %ymm6, %ymm7
 1      3     0.50                         4     c5 85 59 ff                   vmulpd	%ymm7, %ymm15, %ymm7
 1      5     0.50                         5     c4 c2 8d b6 fd                vfmaddsub231pd	%ymm13, %ymm14, %ymm7
 1      3     1.00                         4     c5 9d 58 ff                   vaddpd	%ymm7, %ymm12, %ymm7
 1      3     0.50                         4     c5 2d 59 d4                   vmulpd	%ymm4, %ymm10, %ymm10
 1      5     0.50                         5     c4 42 ed b6 d0                vfmaddsub231pd	%ymm8, %ymm2, %ymm10
 1      3     0.50                         4     c5 25 59 c4                   vmulpd	%ymm4, %ymm11, %ymm8
 1      5     0.50                         5     c4 42 ed b6 c1                vfmaddsub231pd	%ymm9, %ymm2, %ymm8
 1      3     1.00                         6     c4 43 2d 18 c8 01             vinsertf128	$1, %xmm8, %ymm10, %ymm9
 1      3     1.00                         6     c4 43 2d 06 c0 31             vperm2f128	$49, %ymm8, %ymm10, %ymm8
 1      3     1.00                         5     c4 41 35 58 c0                vaddpd	%ymm8, %ymm9, %ymm8
 1      6     0.50    *                    6     c4 41 7d 10 48 10             vmovupd	16(%r8), %ymm9
 1      3     1.00                         6     c4 43 fd 01 d1 ee             vpermpd	$238, %ymm9, %ymm10
 1      3     1.00                         6     c4 43 fd 01 d9 bb             vpermpd	$187, %ymm9, %ymm11
 1      3     0.50                         5     c4 41 05 59 db                vmulpd	%ymm11, %ymm15, %ymm11
 1      5     0.50                         5     c4 42 8d b6 da                vfmaddsub231pd	%ymm10, %ymm14, %ymm11
 1      3     1.00                         5     c4 41 3d 58 c3                vaddpd	%ymm11, %ymm8, %ymm8
 1      3     0.50                         4     c5 f5 59 ed                   vmulpd	%ymm5, %ymm1, %ymm5
 1      5     0.50                         5     c4 e2 fd b6 eb                vfmaddsub231pd	%ymm3, %ymm0, %ymm5
 1      3     0.50                         4     c5 f5 59 cc                   vmulpd	%ymm4, %ymm1, %ymm1
 1      5     0.50                         5     c4 e2 fd b6 ca                vfmaddsub231pd	%ymm2, %ymm0, %ymm1
 1      3     1.00                         6     c4 e3 55 18 c1 01             vinsertf128	$1, %xmm1, %ymm5, %ymm0
 1      3     1.00                         6     c4 e3 55 06 c9 31             vperm2f128	$49, %ymm1, %ymm5, %ymm1
 1      3     1.00                         4     c5 fd 58 c1                   vaddpd	%ymm1, %ymm0, %ymm0
 1      6     0.50    *                    9     c4 e2 7d 19 8a 80 00 00 00    vbroadcastsd	128(%rdx), %ymm1
 1      6     0.50    *                    9     c4 e2 7d 19 92 88 00 00 00    vbroadcastsd	136(%rdx), %ymm2
 1      3     1.00                         6     c4 c3 4d 06 d9 31             vperm2f128	$49, %ymm9, %ymm6, %ymm3
 1      1     1.00                         6     c4 e3 7d 05 e3 05             vpermilpd	$5, %ymm3, %ymm4
 1      3     0.50                         4     c5 dd 59 d2                   vmulpd	%ymm2, %ymm4, %ymm2
 1      5     0.50                         5     c4 e2 e5 b6 d1                vfmaddsub231pd	%ymm1, %ymm3, %ymm2
 1      3     1.00                         4     c5 fd 58 c2                   vaddpd	%ymm2, %ymm0, %ymm0
 2      1     1.00           *             4     c5 fd 29 3f                   vmovapd	%ymm7, (%rdi)
 2      1     1.00           *             5     c5 f9 29 47 20                vmovapd	%xmm0, 32(%rdi)
 2      1     1.00           *             4     c5 7d 29 06                   vmovapd	%ymm8, (%rsi)
 2      1     1.00           *             7     c4 e3 7d 19 46 20 01          vextractf128	$1, %ymm0, 32(%rsi)
 2      6     0.50    *                    1     5d                            popq	%rbp
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 3      7     1.00                  U      1     c3                            retq
 3      2     1.00           *             1     55                            pushq	%rbp
 1      1     0.25                         3     48 89 e5                      movq	%rsp, %rbp
 1      6     0.50    *                    4     c5 fd 28 06                   vmovapd	(%rsi), %ymm0
 1      1     1.00                         4     c5 ff 12 c8                   vmovddup	%ymm0, %ymm1
 1      1     1.00                         6     c4 e3 7d 05 c0 0f             vpermilpd	$15, %ymm0, %ymm0
 1      6     0.50    *                    5     c5 fd 10 56 10                vmovupd	16(%rsi), %ymm2
 1      6     0.50    *                    5     c5 fd 10 5e 30                vmovupd	48(%rsi), %ymm3
 1      1     1.00                         4     c5 ff 12 e3                   vmovddup	%ymm3, %ymm4
 1      1     1.00                         6     c4 e3 7d 05 db 0f             vpermilpd	$15, %ymm3, %ymm3
 1      6     0.50    *                    5     c5 fd 28 6e 60                vmovapd	96(%rsi), %ymm5
 1      1     1.00                         4     c5 ff 12 f5                   vmovddup	%ymm5, %ymm6
 1      1     1.00                         6     c4 e3 7d 05 ed 0f             vpermilpd	$15, %ymm5, %ymm5
 1      6     0.50    *                    4     c5 fd 28 3a                   vmovapd	(%rdx), %ymm7
 1      1     1.00                         6     c4 63 7d 05 c7 05             vpermilpd	$5, %ymm7, %ymm8
 1      3     0.50                         4     c5 bd 59 c0                   vmulpd	%ymm0, %ymm8, %ymm0
 1      5     0.50                         5     c4 e2 c5 b6 c1                vfmaddsub231pd	%ymm1, %ymm7, %ymm0
 1      3     0.50                         4     c5 bd 59 cb                   vmulpd	%ymm3, %ymm8, %ymm1
 1      5     0.50                         5     c4 e2 c5 b6 cc                vfmaddsub231pd	%ymm4, %ymm7, %ymm1
 1      3     1.00                         6     c4 e3 7d 18 d9 01             vinsertf128	$1, %xmm1, %ymm0, %ymm3
 1      3     1.00                         6     c4 e3 7d 06 c1 31             vperm2f128	$49, %ymm1, %ymm0, %ymm0
 1      3     1.00                         4     c5 e5 58 c0                   vaddpd	%ymm0, %ymm3, %ymm0
 2      9     1.00    *                    7     c4 e3 6d 06 4e 40 31          vperm2f128	$49, 64(%rsi), %ymm2, %ymm1
 1      6     0.50    *                    6     c4 e2 7d 1a 52 20             vbroadcastf128	32(%rdx), %ymm2
 1      1     1.00                         4     c5 ff 12 d9                   vmovddup	%ymm1, %ymm3
 1      1     1.00                         6     c4 e3 7d 05 c9 0f             vpermilpd	$15, %ymm1, %ymm1
 1      1     1.00                         6     c4 e3 7d 05 e2 05             vpermilpd	$5, %ymm2, %ymm4
 1      3     0.50                         4     c5 f5 59 cc                   vmulpd	%ymm4, %ymm1, %ymm1
 1      5     0.50                         5     c4 e2 ed b6 cb                vfmaddsub231pd	%ymm3, %ymm2, %ymm1
 1      3     1.00                         4     c5 f5 58 c0                   vaddpd	%ymm0, %ymm1, %ymm0
 1      3     0.50                         4     c5 bd 59 cd                   vmulpd	%ymm5, %ymm8, %ymm1
 1      5     0.50                         5     c4 e2 c5 b6 ce                vfmaddsub231pd	%ymm6, %ymm7, %ymm1
 1      3     1.00                         6     c4 e3 7d 19 cb 01             vextractf128	$1, %ymm1, %xmm3
 1      6     0.50    *                    9     c4 e2 7d 19 ae 80 00 00 00    vbroadcastsd	128(%rsi), %ymm5
 1      6     0.50    *                    9     c4 e2 7d 19 b6 88 00 00 00    vbroadcastsd	136(%rsi), %ymm6
 1      3     0.50                         4     c5 dd 59 e6                   vmulpd	%ymm6, %ymm4, %ymm4
 1      5     0.50                         5     c4 e2 ed b6 e5                vfmaddsub231pd	%ymm5, %ymm2, %ymm4
 1      3     1.00                         4     c5 f1 58 cb                   vaddpd	%xmm3, %xmm1, %xmm1
 1      3     1.00                         4     c5 f1 58 cc                   vaddpd	%xmm4, %xmm1, %xmm1
 2      1     1.00           *             4     c5 fd 29 07                   vmovapd	%ymm0, (%rdi)
 2      1     1.00           *             5     c5 f9 29 4f 20                vmovapd	%xmm1, 32(%rdi)
 2      6     0.50    *                    1     5d                            popq	%rbp
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 3      7     1.00                  U      1     c3                            retq
 3      2     1.00           *             1     55                            pushq	%rbp
 1      1     0.25                         3     48 89 e5                      movq	%rsp, %rbp
 1      6     0.50    *                    8     c5 fd 28 05 00 00 00 00       vmovapd	mask(%rip), %ymm0
 2      9     0.50    *                    4     c5 fd 59 0e                   vmulpd	(%rsi), %ymm0, %ymm1
 2      9     0.50    *                    5     c5 fd 59 56 30                vmulpd	48(%rsi), %ymm0, %ymm2
 1      3     1.00                         6     c4 e3 75 18 da 01             vinsertf128	$1, %xmm2, %ymm1, %ymm3
 1      3     1.00                         6     c4 e3 75 06 ca 31             vperm2f128	$49, %ymm2, %ymm1, %ymm1
 1      1     1.00                         6     c4 e3 7d 05 d3 05             vpermilpd	$5, %ymm3, %ymm2
 1      1     1.00                         6     c4 e3 7d 05 e1 05             vpermilpd	$5, %ymm1, %ymm4
 1      6     0.50    *                    4     c5 fd 28 2a                   vmovapd	(%rdx), %ymm5
 1      1     1.00                         4     c5 ff 12 f5                   vmovddup	%ymm5, %ymm6
 1      1     1.00                         6     c4 e3 7d 05 ed 0f             vpermilpd	$15, %ymm5, %ymm5
 1      3     0.50                         4     c5 d5 59 d2                   vmulpd	%ymm2, %ymm5, %ymm2
 1      5     0.50                         5     c4 e2 cd b6 d3                vfmaddsub231pd	%ymm3, %ymm6, %ymm2
 1      3     0.50                         4     c5 d5 59 dc                   vmulpd	%ymm4, %ymm5, %ymm3
 1      5     0.50                         5     c4 e2 cd b6 d9                vfmaddsub231pd	%ymm1, %ymm6, %ymm3
 1      3     1.00                         6     c4 e3 6d 18 cb 01             vinsertf128	$1, %xmm3, %ymm2, %ymm1
 1      3     1.00                         6     c4 e3 6d 06 d3 31             vperm2f128	$49, %ymm3, %ymm2, %ymm2
 1      3     1.00                         4     c5 f5 58 ca                   vaddpd	%ymm2, %ymm1, %ymm1
 1      6     0.50    *                    6     c4 e2 7d 19 52 20             vbroadcastsd	32(%rdx), %ymm2
 1      6     0.50    *                    6     c4 e2 7d 19 5a 28             vbroadcastsd	40(%rdx), %ymm3
 2      9     0.50    *                    5     c5 fd 59 66 60                vmulpd	96(%rsi), %ymm0, %ymm4
 1      1     1.00                         6     c4 e3 7d 05 fc 05             vpermilpd	$5, %ymm4, %ymm7
 1      3     0.50                         4     c5 e5 59 ff                   vmulpd	%ymm7, %ymm3, %ymm7
 1      5     0.50                         5     c4 e2 ed b6 fc                vfmaddsub231pd	%ymm4, %ymm2, %ymm7
 2      9     0.50    *                    5     c5 fd 59 66 10                vmulpd	16(%rsi), %ymm0, %ymm4
 1      3     1.00                         4     c5 f5 58 cf                   vaddpd	%ymm7, %ymm1, %ymm1
 2      9     0.50    *                    5     c5 fd 59 7e 40                vmulpd	64(%rsi), %ymm0, %ymm7
 1      3     1.00                         6     c4 e3 5d 06 e7 31             vperm2f128	$49, %ymm7, %ymm4, %ymm4
 1      1     1.00                         6     c4 e3 7d 05 fc 05             vpermilpd	$5, %ymm4, %ymm7
 1      3     0.50                         4     c5 d5 59 ef                   vmulpd	%ymm7, %ymm5, %ymm5
 1      5     0.50                         5     c4 e2 cd b6 ec                vfmaddsub231pd	%ymm4, %ymm6, %ymm5
 1      3     1.00                         6     c4 e3 7d 19 ec 01             vextractf128	$1, %ymm5, %xmm4
 2      9     0.50    *                    5     c5 fd 59 46 70                vmulpd	112(%rsi), %ymm0, %ymm0
 1      3     1.00                         6     c4 e3 fd 01 f0 ee             vpermpd	$238, %ymm0, %ymm6
 1      3     1.00                         6     c4 e3 fd 01 c0 bb             vpermpd	$187, %ymm0, %ymm0
 1      3     0.50                         4     c5 e5 59 c0                   vmulpd	%ymm0, %ymm3, %ymm0
 1      5     0.50                         5     c4 e2 ed b6 c6                vfmaddsub231pd	%ymm6, %ymm2, %ymm0
 1      3     1.00                         4     c5 d1 58 d4                   vaddpd	%xmm4, %xmm5, %xmm2
 1      3     1.00                         4     c5 e9 58 c0                   vaddpd	%xmm0, %xmm2, %xmm0
 2      1     1.00           *             4     c5 fd 29 0f                   vmovapd	%ymm1, (%rdi)
 2      1     1.00           *             5     c5 f9 29 47 20                vmovapd	%xmm0, 32(%rdi)
 2      6     0.50    *                    1     5d                            popq	%rbp
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 3      7     1.00                  U      1     c3                            retq
 3      2     1.00           *             1     55                            pushq	%rbp
 1      1     0.25                         3     48 89 e5                      movq	%rsp, %rbp
 1      6     0.50    *                    8     c5 fd 28 05 00 00 00 00       vmovapd	mask(%rip), %ymm0
 2      9     0.50    *                    4     c5 fd 59 0a                   vmulpd	(%rdx), %ymm0, %ymm1
 2      9     0.50    *                    5     c5 fd 59 52 30                vmulpd	48(%rdx), %ymm0, %ymm2
 1      3     1.00                         6     c4 63 75 18 c2 01             vinsertf128	$1, %xmm2, %ymm1, %ymm8
 1      3     1.00                         6     c4 e3 75 06 fa 31             vperm2f128	$49, %ymm2, %ymm1, %ymm7
 1      1     1.00                         6     c4 43 7d 05 c8 05             vpermilpd	$5, %ymm8, %ymm9
 1      1     1.00                         6     c4 63 7d 05 d7 05             vpermilpd	$5, %ymm7, %ymm10
 1      6     0.50    *                    4     c5 fd 28 11                   vmovapd	(%rcx), %ymm2
 1      1     1.00                         4     c5 ff 12 ca                   vmovddup	%ymm2, %ymm1
 1      1     1.00                         6     c4 e3 7d 05 da 0f             vpermilpd	$15, %ymm2, %ymm3
 1      6     0.50    *                    5     c4 c1 7d 28 20                vmovapd	(%r8), %ymm4
 1      1     1.00                         4     c5 ff 12 d4                   vmovddup	%ymm4, %ymm2
 1      1     1.00                         6     c4 e3 7d 05 e4 0f             vpermilpd	$15, %ymm4, %ymm4
 1      3     0.50                         4     c5 b5 59 eb                   vmulpd	%ymm3, %ymm9, %ymm5
 1      5     0.50                         5     c4 c2 f5 b6 e8                vfmaddsub231pd	%ymm8, %ymm1, %ymm5
 1      3     0.50                         4     c5 ad 59 f3                   vmulpd	%ymm3, %ymm10, %ymm6
 1      5     0.50                         5     c4 e2 f5 b6 f7                vfmaddsub231pd	%ymm7, %ymm1, %ymm6
 1      3     1.00                         6     c4 63 55 18 de 01             vinsertf128	$1, %xmm6, %ymm5, %ymm11
 1      3     1.00                         6     c4 e3 55 06 ee 31             vperm2f128	$49, %ymm6, %ymm5, %ymm5
 1      3     1.00                         4     c5 a5 58 ed                   vaddpd	%ymm5, %ymm11, %ymm5
 1      6     0.50    *                    5     c5 fd 10 71 10                vmovupd	16(%rcx), %ymm6
 1      3     1.00                         6     c4 63 fd 01 de aa             vpermpd	$170, %ymm6, %ymm11
 1      3     1.00                         6     c4 63 fd 01 e6 ff             vpermpd	$255, %ymm6, %ymm12
 2      9     0.50    *                    5     c5 7d 59 6a 60                vmulpd	96(%rdx), %ymm0, %ymm13
 1      1     1.00                         6     c4 43 7d 05 f5 05             vpermilpd	$5, %ymm13, %ymm14
 1      3     0.50                         5     c4 41 1d 59 e6                vmulpd	%ymm14, %ymm12, %ymm12
 1      5     0.50                         5     c4 42 95 b6 e3                vfmaddsub231pd	%ymm11, %ymm13, %ymm12
 1      3     1.00                         4     c5 9d 58 ed                   vaddpd	%ymm5, %ymm12, %ymm5
 1      3     0.50                         4     c5 35 59 cc                   vmulpd	%ymm4, %ymm9, %ymm9
 1      5     0.50                         5     c4 42 ed b6 c8                vfmaddsub231pd	%ymm8, %ymm2, %ymm9
 1      3     0.50                         4     c5 2d 59 c4                   vmulpd	%ymm4, %ymm10, %ymm8
 1      5     0.50                         5     c4 62 ed b6 c7                vfmaddsub231pd	%ymm7, %ymm2, %ymm8
 1      3     1.00                         6     c4 c3 35 18 f8 01             vinsertf128	$1, %xmm8, %ymm9, %ymm7
 1      3     1.00                         6     c4 43 35 06 c0 31             vperm2f128	$49, %ymm8, %ymm9, %ymm8
 1      3     1.00                         4     c5 bd 58 ff                   vaddpd	%ymm7, %ymm8, %ymm7
 1      6     0.50    *                    6     c4 42 7d 19 40 20             vbroadcastsd	32(%r8), %ymm8
 1      6     0.50    *                    6     c4 42 7d 19 48 28             vbroadcastsd	40(%r8), %ymm9
 1      3     0.50                         5     c4 41 0d 59 c9                vmulpd	%ymm9, %ymm14, %ymm9
 1      5     0.50                         5     c4 42 95 b6 c8                vfmaddsub231pd	%ymm8, %ymm13, %ymm9
 1      3     1.00                         4     c5 b5 58 ff                   vaddpd	%ymm7, %ymm9, %ymm7
 2      9     0.50    *                    5     c5 7d 59 42 10                vmulpd	16(%rdx), %ymm0, %ymm8
 2      9     0.50    *                    5     c5 7d 59 4a 40                vmulpd	64(%rdx), %ymm0, %ymm9
 1      3     1.00                         6     c4 43 3d 06 c1 31             vperm2f128	$49, %ymm9, %ymm8, %ymm8
 1      1     1.00                         6     c4 43 7d 05 c8 05             vpermilpd	$5, %ymm8, %ymm9
 1      3     0.50                         4     c5 b5 59 db                   vmulpd	%ymm3, %ymm9, %ymm3
 1      5     0.50                         5     c4 e2 bd b6 d9                vfmaddsub231pd	%ymm1, %ymm8, %ymm3
 1      3     0.50                         4     c5 b5 59 cc                   vmulpd	%ymm4, %ymm9, %ymm1
 1      5     0.50                         5     c4 c2 ed b6 c8                vfmaddsub231pd	%ymm8, %ymm2, %ymm1
 1      3     1.00                         6     c4 e3 65 18 d1 01             vinsertf128	$1, %xmm1, %ymm3, %ymm2
 1      3     1.00                         6     c4 e3 65 06 c9 31             vperm2f128	$49, %ymm1, %ymm3, %ymm1
 1      3     1.00                         4     c5 ed 58 c9                   vaddpd	%ymm1, %ymm2, %ymm1
 2      9     1.00    *                    7     c4 c3 4d 06 50 10 31          vperm2f128	$49, 16(%r8), %ymm6, %ymm2
 1      1     1.00                         4     c5 ff 12 da                   vmovddup	%ymm2, %ymm3
 1      1     1.00                         6     c4 e3 7d 05 d2 0f             vpermilpd	$15, %ymm2, %ymm2
 2      9     0.50    *                    5     c5 fd 59 42 70                vmulpd	112(%rdx), %ymm0, %ymm0
 1      3     1.00                         6     c4 e3 fd 01 e0 ee             vpermpd	$238, %ymm0, %ymm4
 1      3     1.00                         6     c4 e3 fd 01 c0 bb             vpermpd	$187, %ymm0, %ymm0
 1      3     0.50                         4     c5 ed 59 c0                   vmulpd	%ymm0, %ymm2, %ymm0
 1      5     0.50                         5     c4 e2 e5 b6 c4                vfmaddsub231pd	%ymm4, %ymm3, %ymm0
 1      3     1.00                         4     c5 f5 58 c0                   vaddpd	%ymm0, %ymm1, %ymm0
 2      1     1.00           *             4     c5 fd 29 2f                   vmovapd	%ymm5, (%rdi)
 2      1     1.00           *             5     c5 f9 11 47 20                vmovupd	%xmm0, 32(%rdi)
 2      1     1.00           *             4     c5 fd 29 3e                   vmovapd	%ymm7, (%rsi)
 2      1     1.00           *             7     c4 e3 7d 19 46 20 01          vextractf128	$1, %ymm0, 32(%rsi)
 2      6     0.50    *                    1     5d                            popq	%rbp
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 3      7     1.00                  U      1     c3                            retq
 3      2     1.00           *             1     55                            pushq	%rbp
 1      1     0.25                         3     48 89 e5                      movq	%rsp, %rbp
 1      6     0.50    *                    4     c5 fd 28 06                   vmovapd	(%rsi), %ymm0
 1      1     1.00                         4     c5 ff 12 c8                   vmovddup	%ymm0, %ymm1
 1      1     1.00                         6     c4 e3 7d 05 c0 0f             vpermilpd	$15, %ymm0, %ymm0
 1      6     0.50    *                    5     c5 fd 10 56 30                vmovupd	48(%rsi), %ymm2
 1      1     1.00                         4     c5 ff 12 da                   vmovddup	%ymm2, %ymm3
 1      1     1.00                         6     c4 e3 7d 05 d2 0f             vpermilpd	$15, %ymm2, %ymm2
 1      6     0.50    *                    4     c5 fd 28 22                   vmovapd	(%rdx), %ymm4
 1      1     1.00                         6     c4 e3 7d 05 ec 05             vpermilpd	$5, %ymm4, %ymm5
 1      3     0.50                         4     c5 fd 59 c5                   vmulpd	%ymm5, %ymm0, %ymm0
 1      5     0.50                         5     c4 e2 dd b6 c1                vfmaddsub231pd	%ymm1, %ymm4, %ymm0
 1      3     0.50                         4     c5 ed 59 cd                   vmulpd	%ymm5, %ymm2, %ymm1
 1      5     0.50                         5     c4 e2 dd b6 cb                vfmaddsub231pd	%ymm3, %ymm4, %ymm1
 1      3     1.00                         6     c4 e3 7d 18 d1 01             vinsertf128	$1, %xmm1, %ymm0, %ymm2
 1      3     1.00                         6     c4 e3 7d 06 c1 31             vperm2f128	$49, %ymm1, %ymm0, %ymm0
 1      3     1.00                         4     c5 ed 58 c0                   vaddpd	%ymm0, %ymm2, %ymm0
 2      1     1.00           *             4     c5 fd 29 07                   vmovapd	%ymm0, (%rdi)
 2      6     0.50    *                    1     5d                            popq	%rbp
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 3      7     1.00                  U      1     c3                            retq
 3      2     1.00           *             1     55                            pushq	%rbp
 1      1     0.25                         3     48 89 e5                      movq	%rsp, %rbp
 1      6     0.50    *                    4     c5 fd 28 02                   vmovapd	(%rdx), %ymm0
 1      6     0.50    *                    5     c5 fd 10 4a 30                vmovupd	48(%rdx), %ymm1
 1      6     0.50    *                    4     c5 fd 28 11                   vmovapd	(%rcx), %ymm2
 1      1     1.00                         6     c4 e3 7d 05 da 05             vpermilpd	$5, %ymm2, %ymm3
 1      6     0.50    *                    5     c4 c1 7d 28 20                vmovapd	(%r8), %ymm4
 1      1     1.00                         6     c4 e3 7d 05 ec 05             vpermilpd	$5, %ymm4, %ymm5
 1      1     1.00                         4     c5 ff 12 f0                   vmovddup	%ymm0, %ymm6
 1      1     1.00                         6     c4 e3 7d 05 c0 0f             vpermilpd	$15, %ymm0, %ymm0
 1      3     0.50                         4     c5 fd 59 fb                   vmulpd	%ymm3, %ymm0, %ymm7
 1      5     0.50                         5     c4 e2 cd b6 fa                vfmaddsub231pd	%ymm2, %ymm6, %ymm7
 1      1     1.00                         4     c5 7f 12 c1                   vmovddup	%ymm1, %ymm8
 1      1     1.00                         6     c4 e3 7d 05 c9 0f             vpermilpd	$15, %ymm1, %ymm1
 1      3     0.50                         4     c5 f5 59 db                   vmulpd	%ymm3, %ymm1, %ymm3
 1      5     0.50                         5     c4 e2 bd b6 da                vfmaddsub231pd	%ymm2, %ymm8, %ymm3
 1      3     1.00                         6     c4 e3 45 18 d3 01             vinsertf128	$1, %xmm3, %ymm7, %ymm2
 1      3     1.00                         6     c4 e3 45 06 db 31             vperm2f128	$49, %ymm3, %ymm7, %ymm3
 1      3     1.00                         4     c5 ed 58 d3                   vaddpd	%ymm3, %ymm2, %ymm2
 1      3     0.50                         4     c5 fd 59 c5                   vmulpd	%ymm5, %ymm0, %ymm0
 1      5     0.50                         5     c4 e2 dd b6 c6                vfmaddsub231pd	%ymm6, %ymm4, %ymm0
 1      3     0.50                         4     c5 f5 59 cd                   vmulpd	%ymm5, %ymm1, %ymm1
 1      5     0.50                         5     c4 e2 bd b6 cc                vfmaddsub231pd	%ymm4, %ymm8, %ymm1
 1      3     1.00                         6     c4 e3 7d 18 d9 01             vinsertf128	$1, %xmm1, %ymm0, %ymm3
 1      3     1.00                         6     c4 e3 7d 06 c1 31             vperm2f128	$49, %ymm1, %ymm0, %ymm0
 1      3     1.00                         4     c5 e5 58 c0                   vaddpd	%ymm0, %ymm3, %ymm0
 2      1     1.00           *             4     c5 fd 29 17                   vmovapd	%ymm2, (%rdi)
 2      1     1.00           *             4     c5 fd 29 06                   vmovapd	%ymm0, (%rsi)
 2      6     0.50    *                    1     5d                            popq	%rbp
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 3      7     1.00                  U      1     c3                            retq
 3      2     1.00           *             1     55                            pushq	%rbp
 1      1     0.25                         3     48 89 e5                      movq	%rsp, %rbp
 1      6     0.50    *                    8     c5 fd 28 05 00 00 00 00       vmovapd	mask(%rip), %ymm0
 2      9     0.50    *                    4     c5 fd 59 0e                   vmulpd	(%rsi), %ymm0, %ymm1
 2      9     0.50    *                    5     c5 fd 59 46 30                vmulpd	48(%rsi), %ymm0, %ymm0
 1      3     1.00                         6     c4 e3 75 18 d0 01             vinsertf128	$1, %xmm0, %ymm1, %ymm2
 1      3     1.00                         6     c4 e3 75 06 c0 31             vperm2f128	$49, %ymm0, %ymm1, %ymm0
 1      1     1.00                         6     c4 e3 7d 05 ca 05             vpermilpd	$5, %ymm2, %ymm1
 1      1     1.00                         6     c4 e3 7d 05 d8 05             vpermilpd	$5, %ymm0, %ymm3
 1      6     0.50    *                    4     c5 fd 28 22                   vmovapd	(%rdx), %ymm4
 1      1     1.00                         4     c5 ff 12 ec                   vmovddup	%ymm4, %ymm5
 1      1     1.00                         6     c4 e3 7d 05 e4 0f             vpermilpd	$15, %ymm4, %ymm4
 1      3     0.50                         4     c5 dd 59 c9                   vmulpd	%ymm1, %ymm4, %ymm1
 1      5     0.50                         5     c4 e2 d5 b6 ca                vfmaddsub231pd	%ymm2, %ymm5, %ymm1
 1      3     0.50                         4     c5 dd 59 d3                   vmulpd	%ymm3, %ymm4, %ymm2
 1      5     0.50                         5     c4 e2 d5 b6 d0                vfmaddsub231pd	%ymm0, %ymm5, %ymm2
 1      3     1.00                         6     c4 e3 75 18 c2 01             vinsertf128	$1, %xmm2, %ymm1, %ymm0
 1      3     1.00                         6     c4 e3 75 06 ca 31             vperm2f128	$49, %ymm2, %ymm1, %ymm1
 1      3     1.00                         4     c5 fd 58 c1                   vaddpd	%ymm1, %ymm0, %ymm0
 2      1     1.00           *             4     c5 fd 29 07                   vmovapd	%ymm0, (%rdi)
 2      6     0.50    *                    1     5d                            popq	%rbp
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 3      7     1.00                  U      1     c3                            retq
 3      2     1.00           *             1     55                            pushq	%rbp
 1      1     0.25                         3     48 89 e5                      movq	%rsp, %rbp
 1      6     0.50    *                    8     c5 fd 28 05 00 00 00 00       vmovapd	mask(%rip), %ymm0
 2      9     0.50    *                    4     c5 fd 59 0a                   vmulpd	(%rdx), %ymm0, %ymm1
 2      9     0.50    *                    5     c5 fd 59 42 30                vmulpd	48(%rdx), %ymm0, %ymm0
 1      3     1.00                         6     c4 e3 75 18 d0 01             vinsertf128	$1, %xmm0, %ymm1, %ymm2
 1      3     1.00                         6     c4 e3 75 06 c0 31             vperm2f128	$49, %ymm0, %ymm1, %ymm0
 1      1     1.00                         6     c4 e3 7d 05 ca 05             vpermilpd	$5, %ymm2, %ymm1
 1      1     1.00                         6     c4 e3 7d 05 d8 05             vpermilpd	$5, %ymm0, %ymm3
 1      6     0.50    *                    4     c5 fd 28 21                   vmovapd	(%rcx), %ymm4
 1      1     1.00                         4     c5 ff 12 ec                   vmovddup	%ymm4, %ymm5
 1      1     1.00                         6     c4 e3 7d 05 e4 0f             vpermilpd	$15, %ymm4, %ymm4
 1      6     0.50    *                    5     c4 c1 7d 28 30                vmovapd	(%r8), %ymm6
 1      1     1.00                         4     c5 ff 12 fe                   vmovddup	%ymm6, %ymm7
 1      1     1.00                         6     c4 e3 7d 05 f6 0f             vpermilpd	$15, %ymm6, %ymm6
 1      3     0.50                         4     c5 55 59 c2                   vmulpd	%ymm2, %ymm5, %ymm8
 1      3     0.50                         4     c5 5d 59 c9                   vmulpd	%ymm1, %ymm4, %ymm9
 1      3     1.00                         5     c4 41 3d d0 c1                vaddsubpd	%ymm9, %ymm8, %ymm8
 1      3     0.50                         4     c5 d5 59 e8                   vmulpd	%ymm0, %ymm5, %ymm5
 1      3     0.50                         4     c5 dd 59 e3                   vmulpd	%ymm3, %ymm4, %ymm4
 1      3     1.00                         4     c5 d5 d0 e4                   vaddsubpd	%ymm4, %ymm5, %ymm4
 1      3     1.00                         6     c4 e3 3d 18 ec 01             vinsertf128	$1, %xmm4, %ymm8, %ymm5
 1      3     1.00                         6     c4 e3 3d 06 e4 31             vperm2f128	$49, %ymm4, %ymm8, %ymm4
 1      3     1.00                         4     c5 d5 58 e4                   vaddpd	%ymm4, %ymm5, %ymm4
 1      3     0.50                         4     c5 ed 59 d7                   vmulpd	%ymm7, %ymm2, %ymm2
 1      3     0.50                         4     c5 cd 59 c9                   vmulpd	%ymm1, %ymm6, %ymm1
 1      3     1.00                         4     c5 ed d0 c9                   vaddsubpd	%ymm1, %ymm2, %ymm1
 1      3     0.50                         4     c5 fd 59 c7                   vmulpd	%ymm7, %ymm0, %ymm0
 1      3     0.50                         4     c5 cd 59 d3                   vmulpd	%ymm3, %ymm6, %ymm2
 1      3     1.00                         4     c5 fd d0 c2                   vaddsubpd	%ymm2, %ymm0, %ymm0
 1      3     1.00                         6     c4 e3 75 18 d0 01             vinsertf128	$1, %xmm0, %ymm1, %ymm2
 1      3     1.00                         6     c4 e3 75 06 c0 31             vperm2f128	$49, %ymm0, %ymm1, %ymm0
 1      3     1.00                         4     c5 ed 58 c0                   vaddpd	%ymm0, %ymm2, %ymm0
 2      1     1.00           *             4     c5 fd 29 27                   vmovapd	%ymm4, (%rdi)
 2      1     1.00           *             4     c5 fd 29 06                   vmovapd	%ymm0, (%rsi)
 2      6     0.50    *                    1     5d                            popq	%rbp
 4      0     1.00                  U      3     c5 f8 77                      vzeroupper
 3      7     1.00                  U      1     c3                            retq


Resources:
[0]   - BWDivider
[1]   - BWFPDivider
[2]   - BWPort0
[3]   - BWPort1
[4]   - BWPort2
[5]   - BWPort3
[6]   - BWPort4
[7]   - BWPort5
[8]   - BWPort6
[9]   - BWPort7


Resource pressure per iteration:
[0]    [1]    [2]    [3]    [4]    [5]    [6]    [7]    [8]    [9]    
 -     56.00  744.00 859.99 613.01 620.01 464.00 669.02 357.98 364.98 

Resource pressure by instruction:
[0]    [1]    [2]    [3]    [4]    [5]    [6]    [7]    [8]    [9]    Instructions:
 -      -      -      -      -      -     1.00   1.00    -     1.00   pushq	%rbp
 -      -     1.00    -      -      -      -      -      -      -     movq	%rsp, %rbp
 -      -      -      -      -      -     1.00    -     1.00   1.00   pushq	%r15
 -      -      -      -      -      -     1.00   1.00    -     1.00   pushq	%r14
 -      -     1.00    -      -      -     1.00    -      -     1.00   pushq	%r13
 -      -      -      -      -     1.00   1.00    -     1.00    -     pushq	%r12
 -      -      -      -     1.00    -     1.00   1.00    -      -     pushq	%rbx
 -      -     1.00    -      -      -      -      -      -      -     andq	$-32, %rsp
 -      -      -      -      -      -      -      -     1.00    -     subq	$320, %rsp
 -      -      -      -      -     1.00    -      -      -      -     vmovaps	.LCPI0_0(%rip), %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovaps	%ymm0, mask(%rip)
 -      -      -      -      -      -      -      -     1.00    -     movl	$144, %edi
 -      -      -      -      -      -      -      -     1.00    -     movl	$8, %esi
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	amalloc
 -      -      -      -      -      -      -      -     1.00    -     movq	%rax, %r12
 -      -      -      -      -      -      -     1.00    -      -     movl	$48, %edi
 -      -     1.00    -      -      -      -      -      -      -     movl	$8, %esi
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	amalloc
 -      -      -      -      -      -      -      -     1.00    -     movq	%rax, %r14
 -      -     1.00    -      -      -      -      -      -      -     movl	$48, %edi
 -      -      -      -      -      -      -      -     1.00    -     movl	$8, %esi
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	amalloc
 -      -      -      -      -      -      -     1.00    -      -     movq	%rax, %r15
 -      -      -     1.00    -      -      -      -      -      -     movl	$48, %edi
 -      -     1.00    -      -      -      -      -      -      -     movl	$8, %esi
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	amalloc
 -      -      -      -     1.00    -     1.00    -      -      -     movq	%rax, (%rsp)
 -      -     1.00    -      -      -      -      -      -      -     movl	$48, %edi
 -      -      -      -      -      -      -      -     1.00    -     movl	$8, %esi
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	amalloc
 -      -      -      -      -      -      -      -     1.00    -     movq	%rax, %rbx
 -      -      -      -      -      -      -     1.00    -      -     movl	$48, %edi
 -      -      -     1.00    -      -      -      -      -      -     movl	$8, %esi
 -      -     1.00   1.00    -     1.00   1.00    -      -      -     callq	amalloc
 -      -      -      -      -      -     1.00    -      -     1.00   movq	%rax, 120(%rsp)
 -      -     1.00    -      -      -      -      -      -      -     movl	$48, %edi
 -      -      -      -      -      -      -      -     1.00    -     movl	$8, %esi
 -      -      -     1.00    -     1.00   1.00    -     1.00    -     callq	amalloc
 -      -      -      -     1.00    -      -      -      -      -     vmovaps	.LCPI0_1(%rip), %ymm0
 -      -      -      -     1.00    -     1.00    -      -      -     vmovups	%ymm0, (%r14)
 -      -      -      -      -     1.00    -      -      -      -     vmovaps	.LCPI0_2(%rip), %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovups	%xmm0, 32(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovaps	.LCPI0_3(%rip), %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovups	%ymm0, (%r15)
 -      -      -      -      -     1.00    -      -      -      -     vmovaps	.LCPI0_4(%rip), %xmm1
 -      -      -      -     1.00    -     1.00    -      -      -     vmovups	%xmm1, 32(%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovups	%ymm0, (%r12)
 -      -      -      -     1.00    -      -      -      -      -     vmovaps	.LCPI0_5(%rip), %ymm0
 -      -      -      -     1.00    -     1.00    -      -      -     vmovups	%ymm0, 32(%r12)
 -      -      -      -      -     1.00    -      -      -      -     vmovaps	.LCPI0_6(%rip), %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovups	%ymm0, 64(%r12)
 -      -      -      -     1.00    -      -      -      -      -     vmovaps	.LCPI0_7(%rip), %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovups	%ymm0, 96(%r12)
 -      -      -     1.00    -      -      -      -      -      -     movq	%rax, %r13
 -      -      -      -      -     1.00    -      -      -      -     vmovaps	.LCPI0_8(%rip), %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovups	%xmm0, 128(%r12)
 -      -      -      -      -      -      -      -     1.00    -     movq	%r14, %rdi
 -      -      -      -      -      -      -     1.00    -      -     movq	%r15, %rsi
 -      -      -     1.00    -      -      -      -      -      -     movq	%r12, %rdx
 -      -     1.00    -      -      -      -      -      -      -     movl	$5, %ecx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	my_init
 -      -      -     1.00    -      -      -      -      -      -     movq	%rbx, %rdx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%r12), %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm0, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm0, %ymm8
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	48(%r12), %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm0, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm0, %ymm9
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	96(%r12), %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm1
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%r14), %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm2, %ymm3
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm8, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm2, %ymm6, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm3, %ymm9, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm2, %ymm7, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm5, %ymm4, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm5, %ymm4, %ymm4
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%r12), %ymm5
 -      -      -      -      -     1.00    -     1.00    -      -     vperm2f128	$49, 64(%r12), %ymm5, %ymm5
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm4, %ymm10, %ymm10
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%r14), %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm4, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm5, %ymm12
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm5, %ymm13
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm4, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm13, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm11, %ymm12, %ymm5
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%r15), %ymm11
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm5, %ymm10, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm11, %ymm10
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm10, %ymm8, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm6, %ymm11, %ymm8
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm10, %ymm9, %ymm6
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm7, %ymm11, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm6, %ymm8, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm6, %ymm8, %ymm6
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm6, %ymm7, %ymm6
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%r15), %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm7, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm7, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm9, %ymm13, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm8, %ymm12, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm6, %ymm9, %ymm6
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm1, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm2, %ymm0, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm1, %ymm10, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm11, %ymm0, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm1, %ymm3, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm1, %ymm3, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm0, %ymm0
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	128(%r12), %ymm1
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	136(%r12), %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm7, %ymm4, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm3, %ymm4
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm2, %ymm4, %ymm2
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm1, %ymm3, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm2, %ymm0, %ymm0
 -      -      -      -      -     1.00    -      -      -      -     movq	120(%rsp), %rax
 -      -      -      -     1.00    -     1.00    -      -      -     vmovapd	%ymm5, (%rax)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%xmm0, 32(%rax)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovapd	%ymm6, (%r13)
 -      -      -      -      -      -     1.00    -      -     1.00   movq	%r13, 144(%rsp)
 -      -      -      -      -     1.00   1.00    -      -      -     vextractf128	$1, %ymm0, 32(%r13)
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	(%r12), %ymm0
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r12), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	48(%r12), %ymm4
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	96(%r12), %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm0, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm0, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm4, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm4, %ymm6
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	(%r14), %ymm4
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r14), %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm4, %ymm8
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	(%r15), %ymm7
 -      -      -      -      -     1.00    -     1.00    -      -     vperm2f128	$49, 64(%r12), %ymm9, %ymm10
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r15), %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm0, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm10, %ymm12
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm10, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm0, %ymm13
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm13, %ymm10, %ymm13
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm11, %ymm12, %ymm13
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm9, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm11, %ymm10, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm9, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm11, %ymm12, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm7, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm8, %ymm12
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm2, %ymm12
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm11, %ymm5
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm2, %ymm7, %ymm5
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm6, %ymm8, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm3, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm6, %ymm11, %ymm6
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm7, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm1, %ymm8, %ymm8
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm3, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm1, %ymm11, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm7, %ymm3, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm2, %ymm12, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm2, %ymm12, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm2, %ymm3, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm2, %ymm13, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm6, %ymm5, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm6, %ymm5, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm4, %ymm3, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm10, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm1, %ymm8, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm1, %ymm8, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm4, %ymm1
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	128(%r12), %ymm4
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	136(%r12), %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm9, %ymm0, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm0, %ymm6
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm6, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm0, %ymm5
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm5, %ymm1, %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm2, (%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm0, 32(%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm3, (%rbx)
 -      -      -      -      -      -     1.00    -      -     1.00   vextractf128	$1, %ymm0, 32(%rbx)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r12), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r12), %xmm1
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm0, %xmm4
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm1, %xmm5
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm5, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm0, %xmm4
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm2, %xmm1, %xmm5
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm4, %xmm5, %xmm8
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -      -      -      -      -     1.00    -      -     1.00   movq	%rbx, 8(%rsp)
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_1
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_4
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm8, %xmm8
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm7, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm8, %xmm8
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm7, %xmm7
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 248(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 256(%rsp)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	48(%r12), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	56(%r12), %xmm1
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm0, %xmm4
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm1, %xmm5
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm5, %xmm4, %xmm9
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm0, %xmm4
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm1, %xmm5
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm4, %xmm5, %xmm10
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm9, %xmm9
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_10
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	64(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	72(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r14), %xmm3
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_13
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm10, %xmm10
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm9, %xmm9
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	80(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	88(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_16
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm10, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm9, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 264(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 272(%rsp)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	96(%r12), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	104(%r12), %xmm1
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm0, %xmm4
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm1, %xmm5
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm5, %xmm4, %xmm9
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm0, %xmm4
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm1, %xmm5
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm4, %xmm5, %xmm10
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm9, %xmm9
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_19
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	112(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	120(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_22
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm10, %xmm10
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm9, %xmm9
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	128(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	136(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_25
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm10, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm9, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 280(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 288(%rsp)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r12), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r12), %xmm1
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm0, %xmm4
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm1, %xmm5
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm5, %xmm4, %xmm9
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm0, %xmm4
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm1, %xmm5
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm4, %xmm5, %xmm10
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm9, %xmm9
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_28
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_31
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm10, %xmm10
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm9, %xmm9
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_34
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm10, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm9, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 200(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 80(%rsp)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm1, 208(%rsp)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	48(%r12), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	56(%r12), %xmm1
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm0, %xmm4
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm1, %xmm5
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm5, %xmm4, %xmm9
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm0, %xmm4
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm1, %xmm5
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm4, %xmm5, %xmm10
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm9, %xmm9
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_37
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	64(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	72(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_40
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm10, %xmm10
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm9, %xmm9
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	80(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	88(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_43
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm10, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm9, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 216(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 224(%rsp)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	96(%r12), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	104(%r12), %xmm1
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm0, %xmm4
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm1, %xmm5
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm5, %xmm4, %xmm9
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm0, %xmm4
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm1, %xmm5
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm4, %xmm5, %xmm10
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm9, %xmm9
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_46
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	112(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	120(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     jp	.LBB0_49
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm10, %xmm10
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm9, %xmm9
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	128(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	136(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_52
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm10, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm9, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 232(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 240(%rsp)
 -      -      -      -      -      -      -      -      -      -     xorl	%ebx, %ebx
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	.LCPI0_9(%rip), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	.LCPI0_10(%rip), %xmm3
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%rcx,%rbx), %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 16(%rsp)
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm0, %xmm1
 -     4.00   1.00    -      -      -      -      -      -      -     vdivsd	%xmm0, %xmm1, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vandpd	%xmm2, %xmm0, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     movb	$1, %r13b
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm3, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     movb	$1, %al
 -      -     1.00    -      -      -      -      -      -      -     ja	.LBB0_57
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%rcx,%rbx), %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm8, %xmm0, %xmm1
 -     4.00   1.00    -      -      -      -      -      -      -     vdivsd	%xmm0, %xmm1, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vandpd	%xmm2, %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm3, %xmm0
 -      -      -     1.00    -      -      -      -     1.00    -     seta	%al
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%rdx,%rbx), %xmm0
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, 176(%rsp)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%rdx,%rbx), %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 152(%rsp)
 -      -      -      -      -     1.00    -      -      -      -     movq	120(%rsp), %rcx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%rcx,%rbx), %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 88(%rsp)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%rcx,%rbx), %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 160(%rsp)
 -      -      -      -     1.00    -      -      -      -      -     movq	144(%rsp), %rcx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%rcx,%rbx), %xmm0
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm0, 96(%rsp)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%rcx,%rbx), %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 168(%rsp)
 -      -      -     1.00    -      -      -      -      -      -     movzbl	%al, %edi
 -      -      -      -      -      -      -     1.00    -      -     movl	$.L.str, %edx
 -      -      -      -      -      -      -     1.00    -      -     movl	$.L.str.1, %ecx
 -      -     1.00    -      -      -      -      -      -      -     movl	$1, %esi
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	error
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	.LCPI0_10(%rip), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	.LCPI0_9(%rip), %xmm1
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	176(%rsp), %xmm3
 -      -      -     1.00   1.00    -      -      -      -      -     vsubsd	32(%rsp), %xmm3, %xmm0
 -     4.00   1.00    -      -      -      -      -      -      -     vdivsd	%xmm3, %xmm0, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vandpd	%xmm1, %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm2, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     ja	.LBB0_59
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	152(%rsp), %xmm3
 -      -      -     1.00    -     1.00    -      -      -      -     vsubsd	80(%rsp), %xmm3, %xmm0
 -     4.00   1.00    -      -      -      -      -      -      -     vdivsd	%xmm3, %xmm0, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vandpd	%xmm1, %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm2, %xmm0
 -      -      -      -      -      -      -     1.00   1.00    -     seta	%r13b
 -      -      -     1.00    -      -      -      -      -      -     movzbl	%r13b, %edi
 -      -      -      -      -      -      -     1.00    -      -     movl	$.L.str.2, %edx
 -      -     1.00    -      -      -      -      -      -      -     movl	$.L.str.3, %ecx
 -      -      -      -      -      -      -      -     1.00    -     movl	$1, %esi
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	error
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	.LCPI0_10(%rip), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	.LCPI0_9(%rip), %xmm1
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	88(%rsp), %xmm3
 -      -      -     1.00    -     1.00    -      -      -      -     vsubsd	16(%rsp), %xmm3, %xmm0
 -     4.00   1.00    -      -      -      -      -      -      -     vdivsd	%xmm3, %xmm0, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vandpd	%xmm1, %xmm0, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     movb	$1, %r13b
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm2, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     movb	$1, %al
 -      -      -      -      -      -      -      -     1.00    -     ja	.LBB0_61
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	160(%rsp), %xmm3
 -      -      -     1.00   1.00    -      -      -      -      -     vsubsd	24(%rsp), %xmm3, %xmm0
 -     4.00   1.00    -      -      -      -      -      -      -     vdivsd	%xmm3, %xmm0, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vandpd	%xmm1, %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm2, %xmm0
 -      -      -      -      -      -      -     1.00   1.00    -     seta	%al
 -      -      -      -      -      -      -      -     1.00    -     movzbl	%al, %edi
 -      -      -      -      -      -      -     1.00    -      -     movl	$.L.str.4, %edx
 -      -      -      -      -      -      -      -     1.00    -     movl	$.L.str.1, %ecx
 -      -     1.00    -      -      -      -      -      -      -     movl	$1, %esi
 -      -     1.00    -      -     1.00   1.00    -     1.00    -     callq	error
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	.LCPI0_10(%rip), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_9(%rip), %xmm1
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	96(%rsp), %xmm3
 -      -      -     1.00    -     1.00    -      -      -      -     vsubsd	32(%rsp), %xmm3, %xmm0
 -     4.00   1.00    -      -      -      -      -      -      -     vdivsd	%xmm3, %xmm0, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vandpd	%xmm1, %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm2, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     ja	.LBB0_63
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	168(%rsp), %xmm3
 -      -      -     1.00    -     1.00    -      -      -      -     vsubsd	80(%rsp), %xmm3, %xmm0
 -     4.00   1.00    -      -      -      -      -      -      -     vdivsd	%xmm3, %xmm0, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vandpd	%xmm1, %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm2, %xmm0
 -      -      -      -      -      -      -     1.00   1.00    -     seta	%r13b
 -      -      -      -      -      -      -      -     1.00    -     movzbl	%r13b, %edi
 -      -      -      -      -      -      -      -     1.00    -     movl	$.L.str.5, %edx
 -      -      -      -      -      -      -     1.00    -      -     movl	$.L.str.3, %ecx
 -      -      -     1.00    -      -      -      -      -      -     movl	$1, %esi
 -      -      -     1.00   1.00    -     1.00    -     1.00    -     callq	error
 -      -      -      -      -      -      -     1.00    -      -     cmpq	$32, %rbx
 -      -      -      -      -      -      -      -     1.00    -     je	.LBB0_65
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	264(%rsp,%rbx), %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	272(%rsp,%rbx), %xmm8
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	216(%rsp,%rbx), %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%rsp)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	224(%rsp,%rbx), %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 80(%rsp)
 -      -     1.00    -      -      -      -      -      -      -     addq	$16, %rbx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_55
 -      -      -      -      -      -      -     1.00    -      -     movl	$1000, %eax
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	.LCPI0_11(%rip), %ymm14
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm15
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	(%r12), %ymm0
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%r12), %ymm8
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	48(%r12), %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm0, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm0, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm3
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	(%r14), %ymm4
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r14), %ymm0
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	(%r15), %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm7
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r15), %ymm1
 -      -      -      -     1.00    -      -     1.00    -      -     vperm2f128	$49, 64(%r12), %ymm8, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm4, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm5, %ymm9, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm0, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm8, %ymm12
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm2, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm8, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm0, %ymm13
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm13, %ymm8, %ymm13
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm11, %ymm12, %ymm13
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm1, %ymm11
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm11, %ymm8, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm1, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm11, %ymm12, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm9, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm3, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm11, %ymm10, %ymm12
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm11, %ymm10, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm6, %ymm11
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm5, %ymm11, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm2, %ymm6, %ymm5
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm10, %ymm12, %ymm2
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	96(%r12), %ymm10
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm11, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm6, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm7, %ymm5, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm7, %ymm5, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm10, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm10, %ymm10
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm9, %ymm10, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm7, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm11, %ymm10, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm6, %ymm7, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm5, %ymm3, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm4, %ymm9, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm4, %ymm9, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm4, %ymm5, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm2, %ymm13, %ymm2
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	128(%r12), %ymm5
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	136(%r12), %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm1, %ymm0, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm8, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm1, %ymm3
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm6, %ymm3, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm1, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm4, %ymm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm2, (%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm1, 32(%rcx)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovupd	%ymm0, (%rdx)
 -      -      -      -      -      -     1.00    -      -     1.00   vextractf128	$1, %ymm1, 32(%rdx)
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	(%r12), %ymm1
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r12), %ymm7
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	48(%r12), %ymm2
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	96(%r12), %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm2, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm2, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm3, %ymm2
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	(%rcx), %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm3, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm4, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm0, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm6, %ymm8, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm9, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm8, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm9, %ymm0, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm6, %ymm11, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm10, %ymm9
 -      -      -      -     1.00    -      -     1.00    -      -     vperm2f128	$49, 64(%r12), %ymm7, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm11, %ymm11
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm10, %ymm0, %ymm11
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%rcx), %ymm10
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm6, %ymm3, %ymm6
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm2, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm10, %ymm4
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm5, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm7, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm7, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm0, %ymm2, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm10, %ymm0
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm0, %ymm7, %ymm0
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%rdx), %ymm2
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm5, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm2, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm4, %ymm7, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm2, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm7, %ymm5, %ymm4
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	136(%r12), %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm2, %ymm10, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm2, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm7, %ymm5
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	128(%r12), %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm7, %ymm2, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm9, %ymm1, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm9, %ymm1, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm11, %ymm8, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm11, %ymm8, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm0, %ymm1, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm7, %ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm3, %ymm6, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm3, %ymm6, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm4, %ymm1, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm2, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm5, %ymm2, %ymm2
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm0, (%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm2, 32(%r14)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovupd	%ymm1, (%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vextractf128	$1, %ymm2, 32(%r15)
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	(%r14), %ymm14, %ymm0
 -      -      -      -      -     1.00   1.00    -      -      -     vmovupd	%ymm0, (%r14)
 -      -      -     1.00   1.00    -      -      -      -      -     vmulpd	32(%r14), %xmm15, %xmm0
 -      -      -      -     1.00    -     1.00    -      -      -     vmovupd	%xmm0, 32(%r14)
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	(%r15), %ymm14, %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm0, (%r15)
 -      -     1.00    -     1.00    -      -      -      -      -     vmulpd	32(%r15), %xmm15, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm0, 32(%r15)
 -      -      -      -      -      -      -      -     1.00    -     decl	%eax
 -      -      -      -      -      -      -      -     1.00    -     jne	.LBB0_66
 -      -      -      -      -      -      -     1.00    -      -     leaq	128(%rsp), %rdi
 -      -      -      -      -      -      -      -      -      -     xorl	%esi, %esi
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm14, 32(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	gettimeofday
 -      -      -     1.00    -      -      -      -      -      -     movl	$100000000, %r13d
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	clock
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm15
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm14
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -      -     1.00    -      -     1.00   movq	%rax, 16(%rsp)
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	(%r12), %ymm0
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r12), %ymm8
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	48(%r12), %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm0, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm0, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm3
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	(%r14), %ymm4
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r14), %ymm0
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	(%r15), %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm7
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r15), %ymm1
 -      -      -      -     1.00    -      -     1.00    -      -     vperm2f128	$49, 64(%r12), %ymm8, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm4, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm5, %ymm9, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm0, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm8, %ymm12
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm2, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm8, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm0, %ymm13
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm13, %ymm8, %ymm13
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm11, %ymm12, %ymm13
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm1, %ymm11
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm11, %ymm8, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm1, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm11, %ymm12, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm9, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm3, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm11, %ymm10, %ymm12
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm11, %ymm10, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm6, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm11, %ymm5
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm2, %ymm6, %ymm5
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm10, %ymm12, %ymm2
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	96(%r12), %ymm10
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm7, %ymm11, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm6, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm7, %ymm5, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm7, %ymm5, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm10, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm10, %ymm10
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm9, %ymm10, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm7, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm11, %ymm10, %ymm4
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm6, %ymm7, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm5, %ymm3, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm4, %ymm9, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm4, %ymm9, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm4, %ymm5, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm2, %ymm13, %ymm2
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	128(%r12), %ymm5
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	136(%r12), %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm1, %ymm0, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm8, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm1, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm6, %ymm3, %ymm3
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm1, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm4, %ymm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm2, (%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm1, 32(%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm0, (%rdx)
 -      -      -      -      -     1.00   1.00    -      -      -     vextractf128	$1, %ymm1, 32(%rdx)
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	(%r12), %ymm1
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r12), %ymm7
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	48(%r12), %ymm2
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	96(%r12), %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm2, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm2, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm3, %ymm2
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	(%rcx), %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm3, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm4, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm0, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm6, %ymm8, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm9, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm8, %ymm8
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm9, %ymm0, %ymm8
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm6, %ymm11, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm10, %ymm9
 -      -      -      -     1.00    -      -     1.00    -      -     vperm2f128	$49, 64(%r12), %ymm7, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm5, %ymm11, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm10, %ymm0, %ymm11
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%rcx), %ymm10
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm6, %ymm3, %ymm6
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm2, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm10, %ymm4
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm5, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm7, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm7, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm0, %ymm2, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm10, %ymm0
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm0, %ymm7, %ymm0
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%rdx), %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm5, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm2, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm4, %ymm7, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm2, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm7, %ymm5, %ymm4
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	136(%r12), %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm2, %ymm10, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm2, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm7, %ymm5
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	128(%r12), %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm7, %ymm2, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm9, %ymm1, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm9, %ymm1, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm11, %ymm8, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm11, %ymm8, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm0, %ymm1, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm7, %ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm3, %ymm6, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm3, %ymm6, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm4, %ymm1, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm2, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm5, %ymm2, %ymm2
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm0, (%r14)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovupd	%xmm2, 32(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm1, (%r15)
 -      -      -      -      -     1.00   1.00    -      -      -     vextractf128	$1, %ymm2, 32(%r15)
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	(%r14), %ymm14, %ymm0
 -      -      -      -     1.00    -     1.00    -      -      -     vmovupd	%ymm0, (%r14)
 -      -      -     1.00   1.00    -      -      -      -      -     vmulpd	32(%r14), %xmm15, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm0, 32(%r14)
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	(%r15), %ymm14, %ymm0
 -      -      -      -      -     1.00   1.00    -      -      -     vmovupd	%ymm0, (%r15)
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	32(%r15), %xmm15, %xmm0
 -      -      -      -     1.00    -     1.00    -      -      -     vmovupd	%xmm0, 32(%r15)
 -      -      -      -      -      -      -      -     1.00    -     decl	%r13d
 -      -      -      -      -      -      -      -     1.00    -     jne	.LBB0_68
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	clock
 -      -      -      -      -      -      -      -     1.00    -     movq	%rax, %rbx
 -      -      -     1.00    -      -      -      -      -      -     leaq	184(%rsp), %r13
 -      -      -      -      -      -      -      -     1.00    -     movq	%r13, %rdi
 -      -      -      -      -      -      -      -      -      -     xorl	%esi, %esi
 -      -      -     1.00    -     1.00   1.00    -     1.00    -     callq	gettimeofday
 -      -      -      -      -      -      -     1.00    -      -     leaq	104(%rsp), %rdi
 -      -      -     1.00    -      -      -      -      -      -     leaq	128(%rsp), %rdx
 -      -      -      -      -      -      -     1.00    -      -     movq	%r13, %rsi
 -      -     1.00    -     1.00    -     1.00    -     1.00    -     callq	timeval_subtract
 -      -      -      -     1.00    -      -      -     1.00    -     subq	16(%rsp), %rbx
 -      -      -     1.00    -      -      -     1.00    -      -     vcvtsi2sd	%rbx, %xmm14, %xmm0
 -     8.00   1.00    -     1.00    -      -      -      -      -     vdivsd	.LCPI0_13(%rip), %xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     movl	$.L.str.6, %edi
 -      -      -      -      -      -      -     1.00    -      -     movl	$.L.str.7, %edx
 -      -      -      -      -      -      -      -      -      -     xorl	%esi, %esi
 -      -      -     1.00    -      -      -      -      -      -     movb	$1, %al
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	lprintf
 -      -      -     1.00   1.00    -      -      -      -      -     vcvtsi2sdq	104(%rsp), %xmm13, %xmm1
 -      -      -     1.00    -     1.00    -      -      -      -     vcvtsi2sdq	112(%rsp), %xmm13, %xmm0
 -      -     1.00    -     1.00    -      -      -      -      -     vfmadd132sd	.LCPI0_14(%rip), %xmm1, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     movl	$.L.str.6, %edi
 -      -     1.00    -      -      -      -      -      -      -     movl	$.L.str.8, %edx
 -      -      -      -      -      -      -      -      -      -     xorl	%esi, %esi
 -      -      -      -      -      -      -      -     1.00    -     movb	$1, %al
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	lprintf
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm15
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	32(%rsp), %ymm14
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rcx
 -      -      -     1.00    -      -      -      -      -      -     movl	$1000, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%r12), %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm2
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	48(%r12), %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm3, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm3, %ymm4
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%r14), %ymm3
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%r15), %ymm5
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r12), %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm3, %ymm7
 -      -      -      -     1.00    -      -     1.00    -      -     vperm2f128	$49, 64(%r12), %ymm6, %ymm8
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r14), %ymm6
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm2, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm6, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm8, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm8, %ymm12
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm0, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm6, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm8, %ymm12, %ymm8
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%r15), %ymm13
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm10, %ymm11, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm13, %ymm10
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm10, %ymm12, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm13, %ymm12
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm12, %ymm11, %ymm10
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm7, %ymm4, %ymm11
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm1, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm11, %ymm9, %ymm12
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm11, %ymm9, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm5, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm2, %ymm11, %ymm2
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm0, %ymm5, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm9, %ymm12, %ymm0
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	96(%r12), %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm4, %ymm11, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm1, %ymm5, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm4, %ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm4, %ymm2, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm9, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm9, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm9, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm4, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm11, %ymm9, %ymm3
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm4, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm2, %ymm1, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm3, %ymm7, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm3, %ymm7, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm2, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm0, %ymm8, %ymm3
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	128(%r12), %ymm4
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	136(%r12), %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm13, %ymm6, %ymm6
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm10, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm6, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm1, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm6, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm2, %ymm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm3, (%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%xmm1, 32(%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm0, (%rdx)
 -      -      -      -      -      -     1.00    -      -     1.00   vextractf128	$1, %ymm1, 32(%rdx)
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%r12), %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm8
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	48(%r12), %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	96(%r12), %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm2, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm2, %ymm4
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%rcx), %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm5, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm0, %ymm6
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm8, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm11, %ymm2
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm9, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm6, %ymm8, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm9, %ymm0, %ymm8
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%r12), %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm10, %ymm2
 -      -      -      -      -     1.00    -     1.00    -      -     vperm2f128	$49, 64(%r12), %ymm9, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm6, %ymm11, %ymm11
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm10, %ymm0, %ymm11
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%rcx), %ymm10
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm7, %ymm4, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm3, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm10, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm4, %ymm6, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm9, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm9, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm0, %ymm3, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm10, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm0, %ymm9, %ymm0
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%rdx), %ymm3
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm6, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm3, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm9, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm3, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm9, %ymm6, %ymm5
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	136(%r12), %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm3, %ymm10, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm3, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm6, %ymm9, %ymm6
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	128(%r12), %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm9, %ymm3, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm2, %ymm1, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm2, %ymm1, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm3, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm11, %ymm8, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm11, %ymm8, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm0, %ymm1, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm4, %ymm7, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm4, %ymm7, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm5, %ymm1, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm2, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm6, %ymm2, %ymm2
 -      -      -      -     1.00    -     1.00    -      -      -     vmovapd	%ymm0, (%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%xmm2, 32(%r14)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovapd	%ymm1, (%r15)
 -      -      -      -     1.00    -     1.00    -      -      -     vextractf128	$1, %ymm2, 32(%r15)
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	(%r14), %ymm14, %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm0, (%r14)
 -      -     1.00    -     1.00    -      -      -      -      -     vmulpd	32(%r14), %xmm15, %xmm0
 -      -      -      -      -     1.00   1.00    -      -      -     vmovupd	%xmm0, 32(%r14)
 -      -     1.00    -     1.00    -      -      -      -      -     vmulpd	(%r15), %ymm14, %ymm0
 -      -      -      -     1.00    -     1.00    -      -      -     vmovupd	%ymm0, (%r15)
 -      -      -     1.00    -     1.00    -      -      -      -     vmulpd	32(%r15), %xmm15, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm0, 32(%r15)
 -      -      -      -      -      -      -      -     1.00    -     decl	%eax
 -      -      -      -      -      -      -      -     1.00    -     jne	.LBB0_70
 -      -      -     1.00    -      -      -      -      -      -     leaq	128(%rsp), %rdi
 -      -      -      -      -      -      -      -      -      -     xorl	%esi, %esi
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	gettimeofday
 -      -      -      -      -      -      -      -     1.00    -     movl	$100000000, %r13d
 -      -     1.00    -      -     1.00   1.00    -     1.00    -     callq	clock
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm15
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	32(%rsp), %ymm14
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -     1.00   1.00    -      -      -     movq	%rax, 16(%rsp)
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%r12), %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm2
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	48(%r12), %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm3, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm3, %ymm4
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%r14), %ymm3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%r15), %ymm5
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%r12), %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm3, %ymm7
 -      -      -      -      -     1.00    -     1.00    -      -     vperm2f128	$49, 64(%r12), %ymm6, %ymm8
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%r14), %ymm6
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm2, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm6, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm8, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm8, %ymm12
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm0, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm6, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm8, %ymm12, %ymm8
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r15), %ymm13
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm10, %ymm11, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm13, %ymm10
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm10, %ymm12, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm13, %ymm12
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm12, %ymm11, %ymm10
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm7, %ymm4, %ymm11
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm1, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm11, %ymm9, %ymm12
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm11, %ymm9, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm5, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm2, %ymm11, %ymm2
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm0, %ymm5, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm9, %ymm12, %ymm0
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	96(%r12), %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm4, %ymm11, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm1, %ymm5, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm4, %ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm4, %ymm2, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm9, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm9, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm9, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm4, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm11, %ymm9, %ymm3
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm4, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm2, %ymm1, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm3, %ymm7, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm3, %ymm7, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm2, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm0, %ymm8, %ymm3
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	128(%r12), %ymm4
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	136(%r12), %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm13, %ymm6, %ymm6
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm10, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm6, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm1, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm6, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm2, %ymm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm3, (%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%xmm1, 32(%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm0, (%rdx)
 -      -      -      -      -     1.00   1.00    -      -      -     vextractf128	$1, %ymm1, 32(%rdx)
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%r12), %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm8
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	48(%r12), %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm10
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	96(%r12), %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm2, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm2, %ymm4
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%rcx), %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm5, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm0, %ymm6
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm8, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm11, %ymm2
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm9, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm6, %ymm8, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm9, %ymm0, %ymm8
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%r12), %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm10, %ymm2
 -      -      -      -     1.00    -      -     1.00    -      -     vperm2f128	$49, 64(%r12), %ymm9, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm6, %ymm11, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm10, %ymm0, %ymm11
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%rcx), %ymm10
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm7, %ymm4, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm3, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm10, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm4, %ymm6, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm9, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm9, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm0, %ymm3, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm10, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm0, %ymm9, %ymm0
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%rdx), %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm6, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm3, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm9, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm3, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm9, %ymm6, %ymm5
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	136(%r12), %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm3, %ymm10, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm3, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm6, %ymm9, %ymm6
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	128(%r12), %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm9, %ymm3, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm2, %ymm1, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm2, %ymm1, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm3, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm11, %ymm8, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm11, %ymm8, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm0, %ymm1, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm4, %ymm7, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm4, %ymm7, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm5, %ymm1, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm2, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm6, %ymm2, %ymm2
 -      -      -      -     1.00    -     1.00    -      -      -     vmovapd	%ymm0, (%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%xmm2, 32(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm1, (%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vextractf128	$1, %ymm2, 32(%r15)
 -      -     1.00    -     1.00    -      -      -      -      -     vmulpd	(%r14), %ymm14, %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm0, (%r14)
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	32(%r14), %xmm15, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm0, 32(%r14)
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	(%r15), %ymm14, %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm0, (%r15)
 -      -      -     1.00   1.00    -      -      -      -      -     vmulpd	32(%r15), %xmm15, %xmm0
 -      -      -      -      -     1.00   1.00    -      -      -     vmovupd	%xmm0, 32(%r15)
 -      -      -      -      -      -      -      -     1.00    -     decl	%r13d
 -      -      -      -      -      -      -      -     1.00    -     jne	.LBB0_72
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -     1.00    -     1.00    -     1.00    -     callq	clock
 -      -      -      -      -      -      -      -     1.00    -     movq	%rax, %rbx
 -      -      -     1.00    -      -      -      -      -      -     leaq	184(%rsp), %r13
 -      -      -      -      -      -      -      -     1.00    -     movq	%r13, %rdi
 -      -      -      -      -      -      -      -      -      -     xorl	%esi, %esi
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	gettimeofday
 -      -      -     1.00    -      -      -      -      -      -     leaq	104(%rsp), %rdi
 -      -      -      -      -      -      -     1.00    -      -     leaq	128(%rsp), %rdx
 -      -      -      -      -      -      -      -     1.00    -     movq	%r13, %rsi
 -      -     1.00    -     1.00    -     1.00    -     1.00    -     callq	timeval_subtract
 -      -     1.00    -      -     1.00    -      -      -      -     subq	16(%rsp), %rbx
 -      -      -     1.00    -      -      -     1.00    -      -     vcvtsi2sd	%rbx, %xmm14, %xmm0
 -     8.00   1.00    -      -     1.00    -      -      -      -     vdivsd	.LCPI0_13(%rip), %xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     movl	$.L.str.9, %edi
 -      -     1.00    -      -      -      -      -      -      -     movl	$.L.str.7, %edx
 -      -      -      -      -      -      -      -      -      -     xorl	%esi, %esi
 -      -      -      -      -      -      -      -     1.00    -     movb	$1, %al
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	lprintf
 -      -      -     1.00   1.00    -      -      -      -      -     vcvtsi2sdq	104(%rsp), %xmm13, %xmm1
 -      -      -     1.00   1.00    -      -      -      -      -     vcvtsi2sdq	112(%rsp), %xmm13, %xmm0
 -      -     1.00    -     1.00    -      -      -      -      -     vfmadd132sd	.LCPI0_14(%rip), %xmm1, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     movl	$.L.str.10, %edi
 -      -      -      -      -      -      -     1.00    -      -     movl	$.L.str.8, %edx
 -      -      -      -      -      -      -      -      -      -     xorl	%esi, %esi
 -      -     1.00    -      -      -      -      -      -      -     movb	$1, %al
 -      -      -      -      -     1.00   1.00   1.00   1.00    -     callq	lprintf
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -      -     1.00    -     movl	$1000, %ebx
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_75
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%rax)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%rax)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r14), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_78
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, (%rax)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 8(%rax)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_81
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%rax)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%rax)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	48(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	56(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_84
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 16(%rax)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%rax)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	64(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	72(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_87
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 16(%rax)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm7, 24(%rax)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	80(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	88(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_90
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm0, 16(%rax)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%rax)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	96(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	104(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_93
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, 32(%rax)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm1, 40(%rax)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	112(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	120(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     jp	.LBB0_96
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 32(%rax)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm7, 40(%rax)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	128(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	136(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r14), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_99
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%rax)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%rax)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_102
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, (%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%rcx)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_105
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, (%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 8(%rcx)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_108
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%rcx)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	48(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	56(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r15), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_111
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, 16(%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%rcx)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	64(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	72(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r15), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_114
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 16(%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 24(%rcx)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	80(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	88(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r15), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_117
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 16(%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%rcx)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	96(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	104(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r15), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_120
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%rcx)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	112(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	120(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_123
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 32(%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 40(%rcx)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	128(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	136(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_126
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%rcx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%rcx)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%rax), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%rax), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_129
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rax), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rax), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_132
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, (%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 8(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%rax), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%rax), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_135
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	48(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	56(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%rax), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%rax), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_138
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, 16(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	64(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	72(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rax), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rax), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_141
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 16(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 24(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	80(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	88(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%rax), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%rax), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_144
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 16(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	96(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	104(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%rax), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%rax), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_147
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	112(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	120(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rax), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rax), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_150
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 32(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 40(%r14)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	128(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	136(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%rax), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%rax), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_153
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%r14)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%rcx), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%rcx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_156
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, (%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%r15)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rcx), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rcx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_159
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, (%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 8(%r15)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%rcx), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%rcx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_162
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%r15)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	48(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	56(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%rcx), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%rcx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_165
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 16(%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%r15)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	64(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	72(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rcx), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rcx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_168
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 16(%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 24(%r15)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	80(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	88(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%rcx), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%rcx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_171
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, 16(%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%r15)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	96(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	104(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%rcx), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%rcx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_174
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, 32(%r15)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm1, 40(%r15)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	112(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	120(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rcx), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rcx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_177
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 32(%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 40(%r15)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	128(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	136(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%rcx), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%rcx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     jp	.LBB0_180
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%r15)
 -      -     1.00    -     1.00    -      -      -      -      -     vmulpd	(%r14), %ymm9, %ymm0
 -      -      -      -      -     1.00   1.00    -      -      -     vmovupd	%ymm0, (%r14)
 -      -     1.00    -     1.00    -      -      -      -      -     vmulpd	32(%r14), %xmm10, %xmm0
 -      -      -      -     1.00    -     1.00    -      -      -     vmovupd	%xmm0, 32(%r14)
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	(%r15), %ymm9, %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm0, (%r15)
 -      -     1.00    -     1.00    -      -      -      -      -     vmulpd	32(%r15), %xmm10, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm0, 32(%r15)
 -      -      -      -      -      -      -     1.00    -      -     decl	%ebx
 -      -      -      -      -      -      -      -     1.00    -     jne	.LBB0_74
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_183
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_77
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_77
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_80
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%rax), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%rax), %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_80
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_83
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%rax), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%rax), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_83
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_86
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_86
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_89
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rax), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rax), %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_89
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_92
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rax), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rax), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_92
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_95
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_95
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_98
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%rax), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%rax), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_98
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_101
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%rax), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%rax), %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_101
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_104
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_104
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_107
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%rcx), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%rcx), %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_107
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_110
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%rcx), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%rcx), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_110
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_113
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_113
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_116
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rcx), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rcx), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_116
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_119
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rcx), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rcx), %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_119
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_122
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_122
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_125
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%rcx), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%rcx), %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_125
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_128
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%rcx), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%rcx), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_128
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_131
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_131
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_134
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r14), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r14), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_134
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_137
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r14), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r14), %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_137
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_140
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_140
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_143
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r14), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r14), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_143
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_146
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r14), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r14), %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_146
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_149
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_149
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_152
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r14), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r14), %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_152
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_155
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r14), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r14), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_155
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_158
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_158
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_161
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r15), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r15), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_161
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_164
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r15), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r15), %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_164
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_167
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_167
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_170
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r15), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r15), %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_170
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_173
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r15), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r15), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_173
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_176
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_176
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_179
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r15), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r15), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_179
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_182
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rcx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r15), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r15), %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_182
 -      -      -      -      -      -      -     1.00    -      -     leaq	128(%rsp), %rdi
 -      -      -      -      -      -      -      -      -      -     xorl	%esi, %esi
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	gettimeofday
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	clock
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -     1.00    -      -     1.00   movq	%rax, 16(%rsp)
 -      -      -      -      -      -      -     1.00    -      -     movl	$100000000, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r14), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r14), %xmm3
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_185
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%rbx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%rbx)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r14), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_188
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, (%rbx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 8(%rbx)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r14), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_191
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%rbx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%rbx)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	48(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	56(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r14), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_194
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, 16(%rbx)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm1, 24(%rbx)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	64(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	72(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r14), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_197
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 16(%rbx)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm7, 24(%rbx)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	80(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	88(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r14), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_200
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm0, 16(%rbx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%rbx)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	96(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	104(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r14), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_203
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%rbx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%rbx)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	112(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	120(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r14), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_206
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 32(%rbx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 40(%rbx)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	128(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	136(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r14), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r14), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_209
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%rbx)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%rbx)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r15), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_212
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%r13)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%r13)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r15), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_215
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, (%r13)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 8(%r13)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r15), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_218
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%r13)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%r13)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	48(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	56(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r15), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_221
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, 16(%r13)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%r13)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	64(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	72(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r15), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_224
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 16(%r13)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 24(%r13)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	80(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	88(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r15), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_227
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 16(%r13)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%r13)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	96(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	104(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r15), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_230
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%r13)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%r13)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	112(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	120(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_233
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 32(%r13)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 40(%r13)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	128(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	136(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r15), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r15), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_236
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%r13)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%r13)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%rbx), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%rbx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_239
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rbx), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rbx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_242
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, (%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 8(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%rbx), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%rbx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_245
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	48(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	56(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%rbx), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%rbx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_248
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, 16(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	64(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	72(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rbx), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rbx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_251
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 16(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 24(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	80(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	88(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%rbx), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%rbx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_254
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 16(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	96(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	104(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%rbx), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%rbx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_257
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%r14)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	112(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	120(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rbx), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rbx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_260
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 32(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 40(%r14)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	128(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	136(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%rbx), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%rbx), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_263
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%r14)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%r14)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r13), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r13), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_266
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, (%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%r15)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r13), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r13), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_269
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, (%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 8(%r15)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r13), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r13), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_272
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, (%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 8(%r15)
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	48(%r12), %xmm4
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	56(%r12), %xmm5
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r13), %xmm2
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r13), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_275
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 16(%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%r15)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	64(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	72(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r13), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r13), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_278
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 16(%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 24(%r15)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	80(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	88(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r13), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r13), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_281
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, 16(%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 24(%r15)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	96(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	104(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r13), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r13), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_284
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm0, 32(%r15)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm1, 40(%r15)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	112(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	120(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r13), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r13), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm6
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm7, %xmm6, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm6, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_287
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm7, %xmm7
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm8
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 32(%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 40(%r15)
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	128(%r12), %xmm4
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	136(%r12), %xmm5
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r13), %xmm2
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r13), %xmm3
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm4, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vsubsd	%xmm1, %xmm0, %xmm0
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm3, %xmm4, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     vmulsd	%xmm2, %xmm5, %xmm6
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm1, %xmm6, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm0, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     jp	.LBB0_290
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm7, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsd	%xmm0, %xmm8, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm0, 32(%r15)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm1, 40(%r15)
 -      -     1.00    -     1.00    -      -      -      -      -     vmulpd	(%r14), %ymm9, %ymm0
 -      -      -      -      -     1.00   1.00    -      -      -     vmovupd	%ymm0, (%r14)
 -      -     1.00    -     1.00    -      -      -      -      -     vmulpd	32(%r14), %xmm10, %xmm0
 -      -      -      -     1.00    -     1.00    -      -      -     vmovupd	%xmm0, 32(%r14)
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	(%r15), %ymm9, %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%ymm0, (%r15)
 -      -     1.00    -     1.00    -      -      -      -      -     vmulpd	32(%r15), %xmm10, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm0, 32(%r15)
 -      -      -      -      -      -      -     1.00    -      -     decl	%eax
 -      -      -      -      -      -      -      -     1.00    -     jne	.LBB0_184
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_293
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_187
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -     1.00    -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	__muldc3
 -      -      -      -      -      -      -     1.00    -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_187
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_190
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -      -      -     1.00    -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%rbx), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%rbx), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_190
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_193
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -     1.00    -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%rbx), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%rbx), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_193
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_196
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	__muldc3
 -      -     1.00    -      -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_196
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_199
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -      -      -     1.00    -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rbx), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rbx), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_199
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_202
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -     1.00    -      -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rbx), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rbx), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_202
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_205
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	__muldc3
 -      -      -     1.00    -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_205
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_208
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -      -      -     1.00    -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%rbx), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%rbx), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_208
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_211
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -     1.00    -      -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%rbx), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%rbx), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_211
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_214
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	__muldc3
 -      -      -     1.00    -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_214
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_217
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -     1.00    -      -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r13), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r13), %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_217
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_220
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -     1.00    -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r13), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r13), %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_220
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_223
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	__muldc3
 -      -      -     1.00    -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_223
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_226
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -      -      -      -     1.00    -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r13), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r13), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_226
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_229
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -     1.00    -      -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r13), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r13), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_229
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_232
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	__muldc3
 -      -      -     1.00    -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_232
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_235
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -      -      -     1.00    -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r13), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r13), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_235
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_238
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -     1.00    -      -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r13), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r13), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_238
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_241
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	__muldc3
 -      -      -     1.00    -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_241
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_244
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -     1.00    -      -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r14), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r14), %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_244
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_247
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -      -      -      -     1.00    -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r14), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r14), %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_247
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_250
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -      -      -     1.00    -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_250
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_253
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -     1.00    -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r14), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r14), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_253
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_256
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -      -      -      -     1.00    -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r14), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r14), %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_256
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_259
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	__muldc3
 -      -      -     1.00    -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_259
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_262
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -      -      -      -     1.00    -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r14), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r14), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_262
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_265
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -     1.00    -      -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r14), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r14), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_265
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_268
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -      -      -     1.00    -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_268
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_271
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -     1.00    -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	(%r15), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	8(%r15), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_271
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_274
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -     1.00    -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	(%r15), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	8(%r15), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_274
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_277
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -      -      -      -     1.00    -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_277
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_280
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -      -      -     1.00    -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%r15), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%r15), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_280
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_283
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -     1.00    -      -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%r15), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%r15), %xmm7
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_283
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_286
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -      -      -     1.00    -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_286
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm7, %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_289
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -     1.00    -      -      -      -      -      -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm8
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%r15), %xmm0
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	40(%r15), %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_289
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_292
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     movl	%eax, %ebx
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -      -      -      -     1.00    -     movl	%ebx, %eax
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	.LCPI0_12(%rip), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	32(%rsp), %ymm9
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %r13
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rbx
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%r15), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	40(%r15), %xmm7
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_292
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	clock
 -      -      -     1.00    -      -      -      -      -      -     movq	%rax, %r13
 -      -      -      -      -      -      -     1.00    -      -     leaq	184(%rsp), %rbx
 -      -      -      -      -      -      -      -     1.00    -     movq	%rbx, %rdi
 -      -      -      -      -      -      -      -      -      -     xorl	%esi, %esi
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	gettimeofday
 -      -      -      -      -      -      -     1.00    -      -     leaq	104(%rsp), %rdi
 -      -      -     1.00    -      -      -      -      -      -     leaq	128(%rsp), %rdx
 -      -      -      -      -      -      -      -     1.00    -     movq	%rbx, %rsi
 -      -     1.00    -      -     1.00   1.00    -     1.00    -     callq	timeval_subtract
 -      -      -      -     1.00    -      -     1.00    -      -     subq	16(%rsp), %r13
 -      -      -     1.00    -      -      -     1.00    -      -     vcvtsi2sd	%r13, %xmm11, %xmm0
 -     8.00   1.00    -      -     1.00    -      -      -      -     vdivsd	.LCPI0_13(%rip), %xmm0, %xmm0
 -      -      -     1.00    -      -      -      -      -      -     movl	$.L.str.11, %edi
 -      -     1.00    -      -      -      -      -      -      -     movl	$.L.str.7, %edx
 -      -      -      -      -      -      -      -      -      -     xorl	%esi, %esi
 -      -      -      -      -      -      -      -     1.00    -     movb	$1, %al
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	lprintf
 -      -      -     1.00    -     1.00    -      -      -      -     vcvtsi2sdq	104(%rsp), %xmm11, %xmm1
 -      -      -     1.00   1.00    -      -      -      -      -     vcvtsi2sdq	112(%rsp), %xmm11, %xmm0
 -      -      -     1.00   1.00    -      -      -      -      -     vfmadd132sd	.LCPI0_14(%rip), %xmm1, %xmm0
 -      -      -      -      -      -      -      -     1.00    -     movl	$.L.str.11, %edi
 -      -      -      -      -      -      -     1.00    -      -     movl	$.L.str.8, %edx
 -      -      -      -      -      -      -      -      -      -     xorl	%esi, %esi
 -      -      -      -      -      -      -      -     1.00    -     movb	$1, %al
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	lprintf
 -      -      -      -      -      -      -     1.00    -      -     movq	%r12, %rdi
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	afree
 -      -      -      -      -      -      -     1.00    -      -     movq	%r14, %rdi
 -      -     1.00   1.00    -     1.00   1.00    -      -      -     callq	afree
 -      -      -      -      -      -      -      -     1.00    -     movq	%r15, %rdi
 -      -     1.00    -     1.00    -     1.00   1.00    -      -     callq	afree
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rdi
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	afree
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdi
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	afree
 -      -      -      -      -      -      -      -      -      -     xorl	%eax, %eax
 -      -      -     1.00    -      -      -      -      -      -     leaq	-40(%rbp), %rsp
 -      -      -      -      -     1.00    -      -     1.00    -     popq	%rbx
 -      -     1.00    -      -     1.00    -      -      -      -     popq	%r12
 -      -      -     1.00   1.00    -      -      -      -      -     popq	%r13
 -      -     1.00    -      -     1.00    -      -      -      -     popq	%r14
 -      -      -      -     1.00    -      -     1.00    -      -     popq	%r15
 -      -      -     1.00    -     1.00    -      -      -      -     popq	%rbp
 -      -      -      -     1.00    -      -     1.00   1.00    -     retq
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm8, %xmm8
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_3
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm7
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm8
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_3
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_6
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 32(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 16(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	__muldc3
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rsp), %xmm8
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%rsp), %xmm7
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_6
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_9
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 32(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 16(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rsp), %xmm8
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%rsp), %xmm7
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_9
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm10, %xmm10
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_12
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	__muldc3
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm9
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm10
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_12
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_15
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm9, 32(%rsp)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm10, 80(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	80(%rsp), %xmm10
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%rsp), %xmm9
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_15
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_18
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm8, 24(%rsp)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm9, 32(%rsp)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm10, 80(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -     1.00    -     1.00   1.00   1.00    -     callq	__muldc3
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	80(%rsp), %xmm10
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%rsp), %xmm9
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_18
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm10, %xmm10
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_21
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	__muldc3
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm9
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm10
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_21
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_24
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm7, 16(%rsp)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm9, 32(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm10, 80(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -     1.00   1.00    -     1.00    -     callq	__muldc3
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	80(%rsp), %xmm10
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%rsp), %xmm9
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_24
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_27
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm9, 32(%rsp)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm10, 80(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	80(%rsp), %xmm10
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	32(%rsp), %xmm9
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_27
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm10, %xmm10
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_30
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -      -     1.00   1.00    -     1.00   callq	__muldc3
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -     1.00    -      -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -      -     1.00    -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm9
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm10
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_30
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_33
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm7, 16(%rsp)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm9, 32(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm10, 80(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	80(%rsp), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%rsp), %xmm9
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rcx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_33
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_36
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm9, 32(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm10, 80(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	80(%rsp), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	32(%rsp), %xmm9
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rcx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_36
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm10, %xmm10
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_39
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -     1.00   1.00   1.00   1.00    -     callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm9
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm10
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_39
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_42
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm9, 96(%rsp)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm10, 88(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -      -     1.00    -     1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	88(%rsp), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	96(%rsp), %xmm9
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rcx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_42
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_45
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm9, 96(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm10, 88(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	88(%rsp), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	96(%rsp), %xmm9
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rcx
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_45
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm10, %xmm10
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_48
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm8, 24(%rsp)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -      -      -     1.00   1.00   1.00   1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm0, %xmm9
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm1, %xmm10
 -      -     1.00    -      -      -      -      -      -      -     jmp	.LBB0_48
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -      -      -      -      -      -      -     1.00    -     jnp	.LBB0_51
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -     1.00   1.00    -      -      -     vmovsd	%xmm9, 96(%rsp)
 -      -      -      -     1.00    -     1.00    -      -      -     vmovsd	%xmm10, 88(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	88(%rsp), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	96(%rsp), %xmm9
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_51
 -      -      -     1.00    -      -      -      -      -      -     vucomisd	%xmm1, %xmm1
 -      -     1.00    -      -      -      -      -      -      -     jnp	.LBB0_54
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm4, %xmm0
 -      -      -      -      -      -      -     1.00    -      -     vmovapd	%xmm5, %xmm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm8, 24(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm7, 16(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm9, 96(%rsp)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovsd	%xmm10, 88(%rsp)
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00   1.00    -      -     1.00    -      -     1.00   callq	__muldc3
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	88(%rsp), %xmm10
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	96(%rsp), %xmm9
 -      -      -      -      -     1.00    -      -      -      -     vmovsd	16(%rsp), %xmm7
 -      -      -      -     1.00    -      -      -      -      -     vmovsd	24(%rsp), %xmm8
 -      -      -      -      -     1.00    -      -      -      -     movq	8(%rsp), %rdx
 -      -      -      -     1.00    -      -      -      -      -     movq	(%rsp), %rcx
 -      -      -      -      -      -      -      -     1.00    -     jmp	.LBB0_54
 -      -      -      -      -     1.00   1.00    -     1.00    -     pushq	%rbp
 -      -      -      -      -      -      -     1.00    -      -     movq	%rsp, %rbp
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%rdx), %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm0, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm0, %ymm10
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	48(%rdx), %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm0, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm0, %ymm11
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	96(%rdx), %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm1
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%rcx), %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm3, %ymm5
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%r8), %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm2, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm5, %ymm10, %ymm6
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm8, %ymm6
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm11, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm9, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm7, %ymm6, %ymm12
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm7, %ymm6, %ymm6
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%rdx), %ymm7
 -      -      -      -     1.00    -      -     1.00    -      -     vperm2f128	$49, 64(%rdx), %ymm7, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm6, %ymm12, %ymm12
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%rcx), %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm6, %ymm13
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm7, %ymm14
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm7, %ymm15
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm6, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm15, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm13, %ymm14, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm7, %ymm12, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm4, %ymm10, %ymm10
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm8, %ymm2, %ymm10
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm4, %ymm11, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm9, %ymm2, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm8, %ymm10, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm8, %ymm10, %ymm8
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm8, %ymm9, %ymm8
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%r8), %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm9, %ymm10
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm9, %ymm11
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm11, %ymm15, %ymm11
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm10, %ymm14, %ymm11
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm11, %ymm8, %ymm8
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm5, %ymm1, %ymm5
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm0, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm4, %ymm1, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm2, %ymm0, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm1, %ymm5, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm1, %ymm5, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm0, %ymm0
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	128(%rdx), %ymm1
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	136(%rdx), %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm9, %ymm6, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm3, %ymm4
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm2, %ymm4, %ymm2
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm1, %ymm3, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm2, %ymm0, %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm7, (%rdi)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%xmm0, 32(%rdi)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm8, (%rsi)
 -      -      -      -      -     1.00   1.00    -      -      -     vextractf128	$1, %ymm0, 32(%rsi)
 -      -      -      -      -     1.00    -      -     1.00    -     popq	%rbp
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00   1.00    -      -      -     1.00    -     retq
 -      -      -      -     1.00    -     1.00    -     1.00    -     pushq	%rbp
 -      -      -      -      -      -      -      -     1.00    -     movq	%rsp, %rbp
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%rsi), %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm0, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm0, %ymm0
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	16(%rsi), %ymm2
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	48(%rsi), %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm3, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm3, %ymm3
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	96(%rsi), %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm5, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm5, %ymm5
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%rdx), %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm7, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm0, %ymm8, %ymm0
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm1, %ymm7, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm3, %ymm8, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm7, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm1, %ymm0, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm1, %ymm0, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm0, %ymm3, %ymm0
 -      -      -      -     1.00    -      -     1.00    -      -     vperm2f128	$49, 64(%rsi), %ymm2, %ymm1
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastf128	32(%rdx), %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm2, %ymm4
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm4, %ymm1, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm2, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm0, %ymm1, %ymm0
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm8, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm6, %ymm7, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vextractf128	$1, %ymm1, %xmm3
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	128(%rsi), %ymm5
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	136(%rsi), %ymm6
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm6, %ymm4, %ymm4
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm5, %ymm2, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm3, %xmm1, %xmm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm4, %xmm1, %xmm1
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm0, (%rdi)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%xmm1, 32(%rdi)
 -      -      -     1.00    -     1.00    -      -      -      -     popq	%rbp
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -     1.00    -      -     1.00   1.00    -     retq
 -      -      -      -      -     1.00   1.00    -     1.00    -     pushq	%rbp
 -      -      -      -      -      -      -      -     1.00    -     movq	%rsp, %rbp
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	mask(%rip), %ymm0
 -      -      -     1.00   1.00    -      -      -      -      -     vmulpd	(%rsi), %ymm0, %ymm1
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	48(%rsi), %ymm0, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm2, %ymm1, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm2, %ymm1, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm3, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm1, %ymm4
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%rdx), %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm5, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm5, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm2, %ymm5, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm6, %ymm2
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm4, %ymm5, %ymm3
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm1, %ymm6, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm3, %ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm3, %ymm2, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm2, %ymm1, %ymm1
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	32(%rdx), %ymm2
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	40(%rdx), %ymm3
 -      -      -     1.00   1.00    -      -      -      -      -     vmulpd	96(%rsi), %ymm0, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm4, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm3, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm2, %ymm7
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	16(%rsi), %ymm0, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm7, %ymm1, %ymm1
 -      -     1.00    -     1.00    -      -      -      -      -     vmulpd	64(%rsi), %ymm0, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm7, %ymm4, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm4, %ymm7
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm7, %ymm5, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm6, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vextractf128	$1, %ymm5, %xmm4
 -      -      -     1.00    -     1.00    -      -      -      -     vmulpd	112(%rsi), %ymm0, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm0, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm0, %ymm0
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm0, %ymm3, %ymm0
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm6, %ymm2, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm4, %xmm5, %xmm2
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%xmm0, %xmm2, %xmm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm1, (%rdi)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%xmm0, 32(%rdi)
 -      -      -      -     1.00    -      -      -     1.00    -     popq	%rbp
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -      -     1.00    -      -     1.00    -     retq
 -      -      -      -      -      -     1.00    -     1.00   1.00   pushq	%rbp
 -      -      -      -      -      -      -      -     1.00    -     movq	%rsp, %rbp
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	mask(%rip), %ymm0
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	(%rdx), %ymm0, %ymm1
 -      -      -     1.00   1.00    -      -      -      -      -     vmulpd	48(%rdx), %ymm0, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm2, %ymm1, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm2, %ymm1, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm8, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm7, %ymm10
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%rcx), %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm2, %ymm3
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%r8), %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm4, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm4, %ymm4
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm9, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm8, %ymm1, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm10, %ymm6
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm7, %ymm1, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm6, %ymm5, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm6, %ymm5, %ymm5
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm5, %ymm11, %ymm5
 -      -      -      -      -     1.00    -      -      -      -     vmovupd	16(%rcx), %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$170, %ymm6, %ymm11
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$255, %ymm6, %ymm12
 -      -      -     1.00   1.00    -      -      -      -      -     vmulpd	96(%rdx), %ymm0, %ymm13
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm13, %ymm14
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm14, %ymm12, %ymm12
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm11, %ymm13, %ymm12
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm5, %ymm12, %ymm5
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm4, %ymm9, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm8, %ymm2, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm4, %ymm10, %ymm8
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm7, %ymm2, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm8, %ymm9, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm8, %ymm9, %ymm8
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm7, %ymm8, %ymm7
 -      -      -      -      -     1.00    -      -      -      -     vbroadcastsd	32(%r8), %ymm8
 -      -      -      -     1.00    -      -      -      -      -     vbroadcastsd	40(%r8), %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm9, %ymm14, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm8, %ymm13, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm7, %ymm9, %ymm7
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	16(%rdx), %ymm0, %ymm8
 -      -      -     1.00   1.00    -      -      -      -      -     vmulpd	64(%rdx), %ymm0, %ymm9
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm9, %ymm8, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm8, %ymm9
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm9, %ymm3
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm1, %ymm8, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm4, %ymm9, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm8, %ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm1, %ymm3, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm1, %ymm3, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm2, %ymm1
 -      -      -      -     1.00    -      -     1.00    -      -     vperm2f128	$49, 16(%r8), %ymm6, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm2, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm2, %ymm2
 -      -      -     1.00    -     1.00    -      -      -      -     vmulpd	112(%rdx), %ymm0, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$238, %ymm0, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermpd	$187, %ymm0, %ymm0
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm0, %ymm2, %ymm0
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm3, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm0, %ymm1, %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm5, (%rdi)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovupd	%xmm0, 32(%rdi)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm7, (%rsi)
 -      -      -      -     1.00    -     1.00    -      -      -     vextractf128	$1, %ymm0, 32(%rsi)
 -      -      -      -      -     1.00    -      -     1.00    -     popq	%rbp
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -      -     1.00    -      -     1.00   1.00    -     retq
 -      -      -      -      -      -     1.00    -     1.00   1.00   pushq	%rbp
 -      -     1.00    -      -      -      -      -      -      -     movq	%rsp, %rbp
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%rsi), %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm0, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm0, %ymm0
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	48(%rsi), %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm2, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm2, %ymm2
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%rdx), %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm4, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm0, %ymm0
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm1, %ymm4, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm5, %ymm2, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm3, %ymm4, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm1, %ymm0, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm1, %ymm0, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm0, %ymm2, %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm0, (%rdi)
 -      -      -      -     1.00    -      -      -     1.00    -     popq	%rbp
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -     1.00    -     1.00    -      -      -     1.00    -     retq
 -      -      -      -      -      -     1.00    -     1.00   1.00   pushq	%rbp
 -      -     1.00    -      -      -      -      -      -      -     movq	%rsp, %rbp
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%rdx), %ymm0
 -      -      -      -     1.00    -      -      -      -      -     vmovupd	48(%rdx), %ymm1
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%rcx), %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm2, %ymm3
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%r8), %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm4, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm0, %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm0, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm3, %ymm0, %ymm7
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm2, %ymm6, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm1, %ymm8
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm1, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm1, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm2, %ymm8, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm3, %ymm7, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm3, %ymm7, %ymm3
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm3, %ymm2, %ymm2
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm5, %ymm0, %ymm0
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm6, %ymm4, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm5, %ymm1, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm4, %ymm8, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm1, %ymm0, %ymm3
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm1, %ymm0, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm0, %ymm3, %ymm0
 -      -      -      -      -     1.00   1.00    -      -      -     vmovapd	%ymm2, (%rdi)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm0, (%rsi)
 -      -      -      -     1.00    -      -      -     1.00    -     popq	%rbp
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -     1.00    -      -     1.00    -     retq
 -      -     1.00    -      -     1.00   1.00    -      -      -     pushq	%rbp
 -      -      -      -      -      -      -      -     1.00    -     movq	%rsp, %rbp
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	mask(%rip), %ymm0
 -      -      -     1.00    -     1.00    -      -      -      -     vmulpd	(%rsi), %ymm0, %ymm1
 -      -      -     1.00    -     1.00    -      -      -      -     vmulpd	48(%rsi), %ymm0, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm0, %ymm1, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm0, %ymm1, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm0, %ymm3
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%rdx), %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm4, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm4, %ymm4
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm1, %ymm4, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vfmaddsub231pd	%ymm2, %ymm5, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm4, %ymm2
 -      -     1.00    -      -      -      -      -      -      -     vfmaddsub231pd	%ymm0, %ymm5, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm2, %ymm1, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm2, %ymm1, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm1, %ymm0, %ymm0
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm0, (%rdi)
 -      -      -      -     1.00    -      -     1.00    -      -     popq	%rbp
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00    -     1.00    -      -     1.00    -     retq
 -      -      -      -      -      -     1.00    -     1.00   1.00   pushq	%rbp
 -      -      -     1.00    -      -      -      -      -      -     movq	%rsp, %rbp
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	mask(%rip), %ymm0
 -      -      -     1.00   1.00    -      -      -      -      -     vmulpd	(%rdx), %ymm0, %ymm1
 -      -     1.00    -      -     1.00    -      -      -      -     vmulpd	48(%rdx), %ymm0, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm0, %ymm1, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm0, %ymm1, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm2, %ymm1
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$5, %ymm0, %ymm3
 -      -      -      -     1.00    -      -      -      -      -     vmovapd	(%rcx), %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm4, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm4, %ymm4
 -      -      -      -      -     1.00    -      -      -      -     vmovapd	(%r8), %ymm6
 -      -      -      -      -      -      -     1.00    -      -     vmovddup	%ymm6, %ymm7
 -      -      -      -      -      -      -     1.00    -      -     vpermilpd	$15, %ymm6, %ymm6
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm2, %ymm5, %ymm8
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm1, %ymm4, %ymm9
 -      -      -     1.00    -      -      -      -      -      -     vaddsubpd	%ymm9, %ymm8, %ymm8
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm0, %ymm5, %ymm5
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm4, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vaddsubpd	%ymm4, %ymm5, %ymm4
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm4, %ymm8, %ymm5
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm4, %ymm8, %ymm4
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm4, %ymm5, %ymm4
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm2, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vmulpd	%ymm1, %ymm6, %ymm1
 -      -      -     1.00    -      -      -      -      -      -     vaddsubpd	%ymm1, %ymm2, %ymm1
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm7, %ymm0, %ymm0
 -      -     1.00    -      -      -      -      -      -      -     vmulpd	%ymm3, %ymm6, %ymm2
 -      -      -     1.00    -      -      -      -      -      -     vaddsubpd	%ymm2, %ymm0, %ymm0
 -      -      -      -      -      -      -     1.00    -      -     vinsertf128	$1, %xmm0, %ymm1, %ymm2
 -      -      -      -      -      -      -     1.00    -      -     vperm2f128	$49, %ymm0, %ymm1, %ymm0
 -      -      -     1.00    -      -      -      -      -      -     vaddpd	%ymm0, %ymm2, %ymm0
 -      -      -      -      -     1.00   1.00    -      -      -     vmovapd	%ymm4, (%rdi)
 -      -      -      -      -      -     1.00    -      -     1.00   vmovapd	%ymm0, (%rsi)
 -      -     1.00    -     1.00    -      -      -      -      -     popq	%rbp
 -      -      -      -      -      -      -      -      -      -     vzeroupper
 -      -      -     1.00   1.00    -      -      -     1.00    -     retq
